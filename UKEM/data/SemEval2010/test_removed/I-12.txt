sharing experiences to learn user characteristics in 
dynamic environments with sparse data 
david sarne barbara j grosz 
school of engineering and applied sciences 
harvard university cambridge ma usa 
 sarned grosz  eecs harvard edu 
abstract 
this paper investigates the problem of estimating the value of 
probabilistic parameters needed for decision making in environments 
in which an agent operating within a multi-agent system has no 
a priori information about the structure of the distribution of 
parameter values the agent must be able to produce estimations 
even when it may have made only a small number of direct 
observations and thus it must be able to operate with sparse data 
the paper describes a mechanism that enables the agent to 
significantly improve its estimation by augmenting its direct observations 
with those obtained by other agents with which it is coordinating 
to avoid undesirable bias in relatively heterogeneous environments 
while effectively using relevant data to improve its estimations the 
mechanism weighs the contributions of other agents observations 
based on a real-time estimation of the level of similarity between 
each of these agents and itself the coordination autonomy 
module of a coordination-manager system provided an empirical setting 
for evaluation simulation-based evaluations demonstrated that the 
proposed mechanism outperforms estimations based exclusively on 
an agent s own observations as well as estimations based on an 
unweighted aggregate of all other agents observations 
categories and subject descriptors 
i artificial intelligence learning-parameter learning i 
 artificial intelligence distributed artificial 
intelligence-intelligent agents multiagent systems g mathematics of 
computing probability and statistics-distribution functions 
general terms 
algorithms experimentation 
 introduction 
for many real-world scenarios autonomous agents need to 
operate in dynamic uncertain environments in which they have only 
incomplete information about the results of their actions and 
characteristics of other agents or people with whom they need to 
cooperate or collaborate in such environments agents can benefit 
from sharing information they gather pooling their individual 
experiences to improve their estimations of unknown parameters 
required for reasoning about actions under uncertainty 
this paper addresses the problem of learning the distribution of 
the values of a probabilistic parameter that represents a 
characteristic of a person who is interacting with a computer agent the 
characteristic to be learned is or is clearly related to an important 
factor in the agent s decision making 
the basic setting we consider 
is one in which an agent accumulates observations about a 
specific user characteristic and uses them to produce a timely estimate 
of some measure that depends on that characteristic s distribution 
the mechanisms we develop are designed to be useful in a range of 
application domains such as disaster rescue that are characterized 
by environments in which conditions may be rapidly changing 
actions whether of autonomous agents or of people and the overall 
operations occur at a fast pace and decisions must be made within 
tightly constrained time frames typically agents must make 
decisions in real time concurrent with task execution and in the midst 
of great uncertainty in the remainder of this paper we use the term 
fast-paced to refer to such environments in fast-paced 
environments information gathering may be limited and it is not possible 
to learn offline or to wait until large amounts of data are collected 
before making decisions 
fast-paced environments impose three constraints on any 
mechanism for learning a distribution function including the large range 
of bayesian update techniques a the no structure constraint 
no a priori information about the structure of the estimated 
parameter s distribution nor any initial data from which such structure 
can be inferred is available b the limited use constraint agents 
typically need to produce only a small number of estimations in 
total for this parameter c the early use constraint high 
accuracy is a critical requirement even in the initial stages of learning 
thus the goal of the estimation methods presented in this paper is 
to minimize the average error over time rather than to determine 
an accurate value at the end of a long period of interaction that 
is the agent is expected to work with the user for a limited time 
and it attempts to minimize the overall error in its estimations in 
such environments an agent s individually acquired data its own 
observations are too sparse for it to obtain good estimations in the 
requisite time frame given the no-structure-constraint of the 
environment approaches that depend on structured distributions may 
result in a significantly high estimation bias 
we consider this problem in the context of a multi-agent 
distributed system in which computer agents support people who are 
carrying out complex tasks in a dynamic environment the fact that 
agents are part of a multi-agent setting in which other agents may 
 
learning the distribution rather than just determining some value in the 
distribution is important whenever the overall shape of the distribution and 
not just such individual features as mean are important 
also be gathering data to estimate a similar characteristic of their 
users offers the possibility for an agent to augment its own 
observations with those of other agents thus improving the accuracy of 
its learning process furthermore in the environments we consider 
agents are usually accumulating data at a relatively similar rate 
nonetheless the extent to which the observations of other agents 
will be useful to a given agent depends on the extent to which their 
users characteristics distributions are correlated with that of this 
agent s user there is no guarantee that the distribution for two 
different agents is highly positively correlated let alone that they 
are the same therefore to use a data-sharing approach a 
learning mechanism must be capable of effectively identifying the level 
of correlation between the data collected by different agents and to 
weigh shared data depending on the level of correlation 
the design of a coordination autonomy ca module within a 
coordination-manager system as part of the darpa coordinators 
project in which agents support a distributed scheduling task 
provided the initial motivation and a conceptual setting for this 
work however the mechanisms themselves are general and can 
be applied not only to other fast-paced domains but also in other 
multi-agent settings in which agents are collecting data that 
overlaps to some extent at approximately similar rates and in which 
the environment imposes the no-structure limited- and early-use 
constraints defined above e g exploration of remote planets in 
particular our techniques would be useful in any setting in which a 
group of agents undertakes a task in a new environment with each 
agent obtaining observations at a similar rate of individual 
parameters they need for their decision-making 
in this paper we present a mechanism that was used for 
learning key user characteristics in fast-paced environments the 
mechanism provides relatively accurate estimations within short time 
frames by augmenting an individual agent s direct observations with 
observations obtained by other agents with which it is 
coordinating in particular we focus on the related problems of estimating 
the cost of interrupting a person and estimating the probability that 
that person will have the information required by the system our 
adaptive approach which we will refer to throughout the paper as 
selective-sharing allows our ca to improve the accuracy of its 
distribution-based estimations in comparison to relying only on the 
interactions with a specific user subsequently self-learning or 
pooling all data unconditionally average all in particular when 
the number of available observations is relatively small 
the mechanism was successfully tested using a system that 
simulates a coordinators environment the next section of the paper 
describes the problem of estimating user-related parameters in 
fastpaced domains section provides an overview of the methods we 
developed the implementation empirical setting and results are 
given in sections and a comparison with related methods is 
given in section and conclusions in section 
 parameter estimation in 
fastpaced domains 
the ca module and algorithms we describe in this paper were 
developed and tested in the coordinators domain in this 
domain autonomous agents called coordinators are intended to 
help maximize an overall team objective by handling changes in 
the task schedule as conditions of operation change each agent 
operates on behalf of its owner e g the team leader of a 
firstresponse team or a unit commander whose schedule it manages 
thus the actual tasks being scheduled are executed either by 
owners or by units they oversee and the agent s responsibility is limited 
to maintaining the scheduling of these tasks and coordinating with 
the agents of other human team members i e other owners in 
this domain scheduling information and constraints are distributed 
each agent receives a different view of the tasks and structures that 
constitute the full multi-agent problem-typically only a partial 
local one schedule revisions that affect more than one agent must 
be coordinated so agents thus must share certain kinds of 
information in a team context they may be designed to share other types 
as well however the fast-paced nature of the domain constrains 
the amount of information they can share precluding a centralized 
solution scheduling problems must be solved distributively 
the agent-owner relationship is a collaborative one with the 
agent needing to interact with its owner to obtain task and 
environment information relevant to scheduling the ca module is 
responsible for deciding intelligently when and how to interact with 
the owner for improving the agent s scheduling as a result the ca 
must estimate the expected benefit of any such interaction and the 
cost associated with it in general the net benefit of a potential 
interaction is pv − c where v is the value of the information the 
user may have p is the probability that the user has this 
information and c is the cost associated with an interaction the values of 
p v and c are time-varying and the ca estimates their value at 
the intended time of initiating the interaction with its owner this 
paper focuses on the twin problems of estimating the parameters p 
and c both of which are user-centric in the sense of being 
determined by characteristics of the owner and the environment in which 
the owner is operating it presumes a mechanism for determining 
v 
 estimating interruption costs 
the cost of interrupting owners derives from the potential 
degradation in performance of tasks they are doing caused by the 
disruption inter alia research on interaction management has 
deployed sensor-based statistical models of human interruptibility to 
infer the degree of distraction likely to be caused by an interruption 
this work aims to reduce interruption costs by delaying 
interruptions to times that are convenient it typically uses bayesian models 
to learn a user s current or likely future focus of attention from an 
ongoing stream of actions by using sensors to provide continuous 
incoming indications of the user s attentional state these models 
attempt to provide a means for computing probability distributions 
over a user s attention and intentions work which examines 
such interruptibility-cost factors as user frustration and 
distractability includes work on the cost of repeatedly bothering the user 
which takes into account the fact that recent interruptions and 
difficult questions should carry more weight than interruptions in the 
distant past or straightforward questions 
although this prior work uses interruptibility estimates to 
balance the interaction s estimated importance against the degree of 
distraction likely to be caused it differs from the fast-paced 
environments problem we address in three ways that fundamentally 
change the nature of the problem and hence alter the possible 
solutions first it considers settings in which the computer system 
has information that may be relevant to its user rather than the 
user owner having information needed by the system which is 
the complement of the information exchange situation we consider 
second the interruptibility-estimation models are task-based lastly 
it relies on continuous monitoring of a user s activities 
in fast-paced environments there usually is no single task 
structure and some of the activities themselves may have little internal 
structure as a result it is difficult to determine the actual 
attentional state of agent-owners in such settings owners must 
make complex decisions that typically involve a number of other 
members of their units while remaining reactive to events that 
diverge from expectations for instance during disaster 
rescue a first-response unit may begin rescuing survivors trapped in a 
burning house when a wall collapses suddenly forcing the unit to 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
retract and re-plan their actions 
prior work has tracked users focus of attention using a range of 
devices including those able to monitor gestures and track 
eyegaze to identify focus of visual attention thus enabling 
estimations of cognitive load and physical indicators of performance 
degradation the mechanisms described in this paper also presume 
the existence of such sensors however in contrast to prior work 
which relies on these devices operating continuously our 
mechanism presumes that fast-paced environments only allow for the 
activation of sensors for short periods of time on an ad-hoc basis 
because agents resources are severely limited 
methods that depend on predicting what a person will do next 
based only on what the user is currently doing e g mdps are not 
appropriate for modeling focus of attention in fast-paced domains 
because an agent cannot rely on a person s attentional state being 
well structured and monitoring can only be done on a sporadic 
non-continuous basis thus at any given time the cost of 
interaction with the user is essentially probabilistic as reflected over a 
single random monitoring event and can be assigned a probability 
distribution function consequently in fast-paced environments 
an agent needs a sampling strategy by which the ca samples its 
owner s interruptibility level with some cost and decides whether 
to initiate an interaction at this specific time or to delay until a lower 
cost is observed in future samplings the method we describe in 
the remainder of this subsection applies concepts from economic 
search theory to this problem the ca s cost estimation uses 
a mechanism that integrates the distribution of an owner s 
interruptibility level as estimated by the ca into an economic search 
strategy in a way that the overall combined cost of sensor costs and 
interaction costs is minimized 
in its most basic form the economic search problem aims to 
identify an opportunity that will minimize expected cost or 
maximize expected utility the search process itself is associated with 
a cost and opportunities in our case interruption opportunities 
are associated with a stationary distribution function we use a 
sequential search strategy in which one observation is drawn at 
a time over multiple search stages the dominating strategy in 
this model is a reservation-value based strategy which determines a 
lower bound and keeps drawing samples as long as no opportunity 
above the bound was drawn 
in particular we consider the situation in which an agent s owner 
has an interruption cost described by a probability distribution 
function pdf f x and a cumulative distribution function cdf f x 
the agent can activate sensing devices to get an estimation of the 
interruption cost x at the current time but there is a cost c of 
operating the sensing devices for a single time unit the ca module 
sets a reservation value and as long as the sensor-based 
observation x is greater than this reservation value the ca will wait and 
re-sample the user for a new estimation 
the expected cost v xrv using such a strategy with 
reservation value xrv is described by equation 
v xrv 
c 
r xrv 
y 
yf y 
f xrv 
 
which decomposes into two parts the first part c divided by 
f xrv represents the expected sampling cost the second the 
integral divided by f xrv represents the expected cost of 
interruption because the expected number of search cycles is 
 random geometric and the probability of success is f xrv taking 
the derivative of the left-hand-side of equation and equating it 
to zero yields the characteristics of the optimal reservation value 
namely x 
rv must satisfy 
v x 
rv x 
rv 
substituting in equation yields equation after integration 
by parts from which the optimal reservation value x 
rv and 
consequently from equation v x 
rv can be computed 
c 
z x 
rv 
y 
f y 
this method which depends on extracting the optimal sequence 
of sensor-based user sampling relies heavily on the structure of the 
distribution function f x however we need only a portion of 
the distribution function namely from the origin to the reservation 
value see equation and figure thus when we consider 
sharing data it is not necessary to rely on complete similarity in 
the distribution function of different users for some parameters 
including the user s interruptibility level it is enough to rely on 
similarity in the relevant portion of the distribution function the 
implementation described in sections - relies on this fact 
figure the distribution structure affecting the expected 
cost s calculation 
 estimating the probability of having 
information 
one way an agent can estimate the probability a user will have 
information it needs e g will know at a specific interruption time 
with some level of reliability the actual outcome of a task currently 
being executed is to rely on prior interactions with this user 
calculating the ratio between the number of times the user had the 
information and the total number of interactions alternatively the 
agent can attempt to infer this probability from measurable 
characteristics of the user s behavior which it can assess without 
requiring an interruption this indirect approach which does not require 
interrupting the user is especially useful in fast-paced domains 
the ca module we designed uses such an indirect method 
ownerenvironment interactions are used as a proxy for measuring whether 
the owner has certain information for instance in 
coordinatorslike scenarios owners may obtain a variety of information through 
occasional coordination meetings of all owners direct 
communication with other individual owners participating in the execution 
of a joint task through which they may learn informally about the 
existence or status of other actions they are executing open 
communications they overhear e g if commanders leave their radios 
open they can listen to messages associated with other teams in 
their area and other formal or informal communication channels 
 thus owners levels of communication with others which 
can be obtained without interrupting them provide some indication 
of the frequency with which they obtain new information given 
occasional updates about its owner s level of communication the 
ca can estimate the probability that a random interaction with the 
owner will yield the information it needs denoting the 
probability distribution function of the amount of communication the user 
generally maintains with its environment by g x and using the 
transformation function z x mapping from a level of 
communication x to a probability of having the information the expected 
probability of getting the information that is needed from the owner 
when interrupting at a given time can be calculated from 
p 
z ∞ 
 
z x g x dy 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
the more observations an agent can accumulate about the 
distribution of the frequency of an owner s interaction with the 
environment at a given time the better it can estimate the probability the 
owner has the information needed by the system 
 the selective-sharing mechanism 
this section presents the selective-sharing mechanism by which 
the ca learns the distribution function of a probabilistic parameter 
by taking advantage of data collected by other cas in its 
environment we first explain the need for increasing the number of 
observations used as the basis of estimation and then present a method 
for determining how much data to adopt from other agents 
the most straightforward method for the ca to learn the 
distribution functions associated with the different parameters 
characterizing an owner is by building a histogram based on the 
observations it has accumulated up to the estimation point based on 
this histogram the ca can estimate the parameter either by 
taking into account the entire range of values e g to estimate the 
mean or a portion of it e g to find the expected cost when using 
a reservation-value-based strategy the accuracy of the estimation 
will vary widely if it is based on only a small number of 
observations 
for example figure illustrates the reservation-value-based cost 
calculated according to observations received from an owner with 
a uniform interruption cost distribution u as a function of 
the number of accumulated observations used for generating the 
distribution histogram in this simulation device activation cost 
was taken to be c 
figure the convergence of a single ca to its optimal strategy 
these deviations from the actual true value which is in this 
case according to equation is because the sample used in each 
stage cannot accurately capture the actual structure of the 
distribution function eventually this method yields a very accurate 
estimation for the expected interruption cost however in the 
initial stages of the process its estimation deviates significantly from 
the true value this error could seriously degrade the ca s 
decision making process underestimating the cost may result in 
initiating costly non-beneficial interactions and overestimating the cost 
might result in missing opportunities for valuable interactions any 
improvement that can be achieved in predicting the cost values 
especially in the initial stages of learning can make a significant 
difference in performance especially because the agent is severely 
limited in the number of times it can interact with its owner in 
fastpaced domains 
one way to decrease the deviation from the actual value is by 
augmenting the data the ca acquires by observing its owner with 
observations made by other owners agents such an approach 
depends on identifying other owners with distribution functions for 
the characteristic of interest similar to the ca s owner this 
dataaugmentation idea is simple different owners may exhibit 
similar basic behaviors or patterns in similar fast-paced task scenarios 
since they are all coordinating on a common overall task and are 
operating in the same environment it is reasonable to assume some 
level of similarity in the distribution function of their modeled 
parameters people vary in their behavior so obviously there may 
be different types of owners some will emphasize communication 
with their teams and some will spend more time on map-based 
planning some will dislike being disturbed while trying to evaluate 
their team s progress while others may be more open to 
interruptions consequently an owner s ca is likely to be able to find some 
cas that are working with owners who are similar to its owner 
when adopting data collected by other agents the two main 
questions are which agents the ca should rely on and to what 
extent it should rely on each of them the selective-sharing 
mechanism relies on a statistical measure of similarity that allows the ca 
of any specific user to identify the similarity between its owner and 
other owners dynamically based on this similarity level the ca 
decides if and to what degree to import other cas data in order to 
augment its direct observations and thus to enable better modeling 
of its owner s characteristics 
it is notable that the cost of transferring observations between 
different ca modules of different agents is relatively small this 
information can be transferred as part of regular negotiation 
communication between agents the volume of such communication 
is negligible it involves just the transmission of new observations 
values 
in our learning mechanism the ca constantly updates its 
estimation of the level of similarity between its owner and the owners 
represented by other cas in the environment each new 
observation obtained either by that ca or any of the other cas updates this 
estimation the similarity level is determined using the wilcoxon 
rank-sum test subsection 
whenever it is necessary to produce a parameter estimate the 
ca decides on the number of additional observations it intends to 
rely on for extracting its estimation the number of additional 
observations to be taken from each other agent is a function of the 
number of observations it currently has from former interactions 
with its owner and the level of confidence the ca has in the 
similarity between its owner and other owners in most cases the 
number of observations the ca will want to take from another agent is 
smaller than the overall number of observations the other agent has 
thus it randomly samples without repetitions the required 
number of observations from this other agent s database the additional 
observations the ca takes from other agents are used only to model 
its owner s characteristics future similarity level determination is 
not affected by this information augmentation procedure 
 the wilcoxon test 
we use a nonparametric method i e one that makes no 
assumptions about the parametric form of the distributions each set is 
drawn from because user characteristics in fast-paced domains do 
not have the structure needed for parametric approaches two 
additional advantages of a non-parametric approach are their usefulness 
for dealing with unexpected outlying observations possibly 
problematic for a parametric approach and the fact that non-parametric 
approaches are computationally very simple and thus ideal for 
settings in which computational resources are scarce 
the wilcoxon rank-sum test we use is a nonparametric 
alternative to the two-sample t-test 
 while the t-test 
compares means the wilcoxon test can be used to test the null 
hypothesis that two populations x and y have the same continuous 
distribution we assume that we have independent random 
samples x x xm and y y yn of sizes m and n 
respectively from each population we then merge the data and rank 
each measurement from lowest to highest all sequences of ties are 
assigned an average rank from the sum of the ranks of the smaller 
 
chi-square goodness-of-fit test is for a single sample and thus not 
suitable 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
sample we calculate the test statistic and extract the level of 
confidence for rejecting the null hypothesis this level of confidence 
becomes the measure for the level of similarity between the two 
owners the wilcoxon test does not require that the data originates 
from a normally distributed population or that the distribution is 
characterized by a finite set of parameters 
 determining required information 
correctly identifying the right number of additional observations 
to gather is a key determinant of success of the selective-sharing 
mechanism obviously if the ca can identify another owner who 
has identical characteristics to the owner it represents then it should 
use all of the observations collected by that owner s agent 
however cases of identical matches are likely to be very uncommon 
furthermore even to establish that another user is identical to its 
own the ca would need substantial sample sizes to have a 
relatively high level of confidence thus usually the ca needs to 
decide how much to rely on another agent s data while estimating 
various levels of similarity with a changing level of confidence 
at the beginning of its process the selective-sharing mechanism 
has almost no data to rely on and thus no similarity measure can 
be used in this case the ca module relies heavily on other agents 
in the expectation that all owners have some basic level of 
similarity in their distribution see section as the number of its 
direct observations increases the ca module refines the number of 
additional observations required again there are two conflicting 
effects on one hand the more data the ca has the better it can 
determine its level of confidence in the similarity ratings it has for 
other owners on the other hand assuming there is some difference 
among owners even if not noticed yet as the number of its direct 
observations increases the owner s own data should gain weight in 
its analysis therefore when cai decides how many additional 
observations oi 
j should be adopted from caj s database it 
calculates oi 
j as follows 
oi 
j n − αi j 
√ 
n 
 
 ln n 
n 
 
where n is the number of observations cai already has which is 
similar in magnitude to the number of observations caj has and 
αi j is the confidence of rejecting the wilcoxon null hypothesis 
the function in equation ensures that the number of additional 
observations to be taken from another ca module increases as the 
confidence in the similarity with the source for these additional 
observations increases at the same time it ensures that the level of 
dependency on external observations decreases as the number of 
direct observations increases when calculating the parameter αi j 
we always perform the test over the interval relevant to the 
originating ca s distribution function for example when estimating the 
cost of interrupting the user we apply the wilcoxon test only for 
observations in the interval that starts from zero and ends slightly 
to the right of the formerly estimated rv see figure 
 empirical setting 
we tested the selective-sharing mechanism in a system that 
simulates a distributed coordinators-like mas this testbed 
environment includes a variable number of agents each corresponding to a 
single ca module each agent is assigned an external source 
 simulating an owner which it periodically samples to obtain a value 
from the distribution being estimated the simulation system 
enabled us to avoid unnecessary inter-agent scheduling and 
communication overhead which are an inherent part of the coordinators 
environment and thus to better isolate the performance and 
effectiveness of the estimation and decision-making mechanisms 
the distribution functions used in the experiments i e the 
distribution functions assigned to each user in the simulated 
environment are multi-rectangular shaped this type of function is ideal 
for representing empirical distribution functions it is composed 
of k rectangles where each rectangle i is defined over the interval 
 xi− xi and represents a probability pi 
pk 
i pi for any 
value x in rectangle i we can formulate f x and f x as 
f x 
pi 
xi − xi− 
f x 
i− x 
j 
pj 
 x − xi− pi 
xi − xi− 
 
for example the multi-rectangular function in figure depicts a 
possible interruption cost distribution for a specific user each 
rectangle is associated with one of the user s typical activities 
characterized by a set of typical interruption costs we assume the 
distribution of cost within each activity is uniform the 
rectangular area represents the probability of the user being engaged in 
this type of activity when she is randomly interrupted any overlap 
between the interruption costs of two or more activities results in 
a new rectangle for the overlapped interval the user associated 
with the above distribution function spends most of her time in 
reporting notice that this is the largest rectangle in terms of area an 
activity associated with a relatively high cost of interruption the 
user also spends a large portion of her time in planning associated 
with a very high cost of interruption monitoring his team with a 
relatively small interruption cost and receiving reports mid-level 
cost of interruption the user spends a relatively small portion 
of her time in scouting the enemy associated with relatively high 
interruption cost and resting 
figure representing interruption cost distribution using a 
multi-rectangular function 
multi-rectangular functions are modular and allow the 
representation of any distribution shape by controlling the number and 
dimensions of the rectangles used furthermore these functions have 
computational advantages mostly due to the ability to re-use many 
of their components when calculating the optimal reservation value 
in economical search models they also fit well the parameters 
the ca is trying to estimate in fast-paced domains because these 
parameters are mostly influenced by activities in which the user is 
engaged 
the testbed system enabled us to define either hand-crafted or 
automatically generated multi-rectangular distribution functions at 
each step of a simulation each of the cas samples its owner i e 
all cas in the system collect data at a similar rate and then 
estimates the parameter either the expected cost when using the 
sequential interruption technique described in section or the 
probability that the owner will have the required information using one 
of the following methods a relying solely on direct observation 
 self-learning data b relying on the combined data of all other 
agents average all and c relying on its own data and 
selective portions of the other agents data based on the selective-sharing 
mechanism described in section 
 results 
we present the results in two parts using a specific 
sample environment for illustrating the basic behavior of the 
selectivesharing mechanism and using general environments that were 
automatically generated 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
 sample environment 
to illustrate the gain obtained by using the selective-sharing 
mechanism we used an environment of agents associated with 
different interruptibility cost distribution function types the table in 
figure details the division of the agents into types the 
dimensions of the rectangles that form the distribution functions and 
the theoretical mean and reservation value rv following 
equation with a cost c for sensing the interruption cost even 
though the means of the five types are relatively similar the use 
of a reservation-value based interruption strategy yields relatively 
different expected interruption costs rv following equation 
the histogram in this figure depicts the number of observations 
obtained for each bin of size out of a sample of observations 
taken from each type s distribution function 
type agents rect range prob mean rv 
i - 
 - 
 - 
ii - 
 - 
 - 
iii - 
 - 
iv - 
 - 
v - 
 
 
 
 
 
 
 
type i type ii type iii type iv type v 
 ofobservations 
range 
figure users interruptibility cost distribution functions 
types 
figure gives ca performance in estimating the expected cost 
of interruption when using the reservation-value based interruption 
initiation technique each graph presents the average prediction 
accuracy in terms of the absolute deviation from the theoretical 
value so the lower the curve the better the performance of a 
different type based on simulation runs the three curves in 
each graph represent the methods being compared self-learning 
average all and selective-sharing the data is given as a function 
of the accumulated number of observations collected the sixth 
graph in the figure is the average for all types weighted according 
to the number of agents of each type similarly the following table 
summarizes the overall average performance in terms of the 
absolute deviation from the theoretical value of each of the different 
methods 
iterations self-learning averaging-all selective-sharing improvement 
 
 
 
table average absolute error along time 
several observations may be made from figure first 
although the average-all method may produce relatively good results 
it quickly reaches stagnation while the other two methods exhibit 
continuous improvement as a function of the amount of 
accumulated data for the figure environment average-all is a good 
strategy for agents of type ii iv and v because the theoretical 
reservation value of each of these types is close to the one obtained based 
on the aggregated distribution function i e 
however for 
types i and iii for which the optimal rv differs from that value the 
average-all method performs significantly worse overall the sixth 
graph and the table above show that while in this specific 
environment the average-all method works well in the first interactions it 
 
the improvement is measured in percentages relative to the self-learning 
method 
 
the value is obtained by constructing the weighted aggregated distributed 
function according to the different agents types and extracting the optimal 
rv using equation 
 
 
 
 
 
 
 
type i 
 
 
 
 
 
 
 
selective sharing self-learning average all 
 
 
 
 
 
 
 
type ii 
 
 
 
 
 
 
 
type iii 
 
 
 
 
 
 
 
type iv 
 
 
 
 
 
 
 
type v 
 
 
 
 
 
 
 
weighted average 
figure average absolute deviation from the theoretical rv 
in each method runs 
is quickly outperformed by the selective-sharing mechanism 
furthermore the more user observations the agents accumulate i e as 
we extend the horizontal axis the better the other two methods are 
in comparison to average-all in the long run and as shown in the 
following subsection for the general case the average-all method 
exhibits the worst performance 
second the selective-sharing mechanism starts with a significant 
improvement in comparison to relying on the agent s own 
observations and then this improvement gradually decreases until finally 
its performance curve coincides with the self-learning method s 
curve the selective-sharing mechanism performs better or worse 
depending on the type because the wilcoxon test cannot guarantee 
an exact identification of similarity different combinations of 
distribution function can result in an inability to exactly identify the 
similar users for some of the specific types for example for type i 
agents the selective-sharing mechanism actually performs worse 
than self-learning in the short term in the long run the two 
methods performance converge nevertheless for the other types in 
our example the selective-sharing mechanism is the most efficient 
one and outperforms the other two methods overall 
third it is notable that for agents that have a unique type e g 
agent iii the selective-sharing mechanism quickly converges 
towards relying on self-collected data this behavior guarantees that 
even in scenarios in which users are completely different the method 
exhibits a graceful initial degradation but manages within a few 
time steps to adopt the proper behavior of counting exclusively on 
self-generated data 
last despite the difference in their overall distribution function 
agents of type iv and v exhibit similar performance because the 
relevant portion of their distribution functions i e the effective 
parts that affect the rv calculation as explained in figure is 
identical thus the selective-sharing mechanism enables the agent 
of type v despite its unique distribution function to adopt 
relevant information collected by agents of types iv which improves 
its estimation of the expected interruption cost 
 general evaluation 
to evaluate selective-sharing we ran a series of simulations in 
which the environment was randomly generated these 
experiments focused on the cas estimations of the probability that the 
user would have the required information if interrupted they used 
a multi-rectangular probability distribution function to represent 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
the amount of communication the user is engaged in with its 
environment we models the growth of the probability the user has 
the required information as a function of the amount of 
communication using the logistic function 
g x 
 e 
−x 
 
 e 
−x 
 
 
the expected mean value of the parameter representing the 
probability the user has the required information is thus 
μ 
z ∞ 
y 
g y f y dy 
kx 
i 
hx ln e 
x 
 pi 
 xi − xi− 
ixi 
xi− 
 
where k is the number of rectangles used we ran simulation 
runs for each simulation a new -agent environment was 
automatically generated by the system and the agents were randomly 
divided into a random number of different types 
for each type 
a random -rectangle distribution function was generated each 
simulation ran time steps at each time step each one of the 
agents accumulated one additional observation each ca 
calculated an estimate of the probability its user had the necessary 
information according to the three methods and the absolute error 
 difference from the theoretical value calculated according to 
equation was recorded the following table summarizes the average 
performance of the three mechanisms along different time horizons 
 measured at and time steps 
iterations self-learning averaging-all selective-sharing improvement 
 
 
 
table average absolute error along time steps 
as can be seen in the table above the proposed selective-sharing 
method outperforms the two other methods over any execution in 
which more than observations are collected by each of the agents 
as in the sample environment the average-all method performs 
well in the initial few time steps but does not exhibit further 
improvement thus the more data collected the greater the difference 
between this latter method and the two other methods the average 
difference between selective-sharing and self-learning decreases as 
more data is collected 
finally we measured the effect of the number of types in the 
environment for this purpose we used the same self-generation 
method but controlled the number of types generated for each run 
the number of types is a good indication for the level of 
heterogeneity in the environment for each number of types we ran 
 simulations figure depicts the performance of the 
different methods for a -observation collection period for each agent 
since all simulation runs used for generating figure are based 
on the same seed the performance of the self-learning mechanism 
is constant regardless of the number of types in the environment as 
expected the average-all mechanism performs best when all agents 
are of the same type however its performance deteriorates as the 
number of types increases similarly the selective-sharing 
mechanism exhibits good results when all agents are of the same type 
and as the number of types increases its performance deteriorates 
however the performance decrease is significantly more modest in 
comparison to the one experienced in the average-all mechanism 
 
the specific coefficients used guarantee an s-like curve of growth along 
the interval where the initial stage of growth is approximately 
exponential followed by asymptotically slowing growth 
 
in this suggested environment-generation scheme there is no guarantee 
that every agent will have a potential similar agent to share information 
with in those non-rare scenarios where the ca is the only one of its type 
it will rapidly need to stop relying on others 
 
 
 
 
 
 
 
 
 
self learning average all selective sharing 
number of types 
averageabsoluteerror 
figure average absolute deviation from actual value in 
agent scenarios as a function of the agents heterogeneity level 
overall the selective-sharing mechanism outperforms both other 
methods for any number of types greater than one 
 related work 
in addition to the interruption management literature reviewed 
in section several other areas of prior work are relevant to the 
selective-sharing mechanism described in this paper 
collaborative filtering which makes predictions filtering about 
the interests of a user operates similarly to selective-sharing 
however collaborative filtering systems exhibit poor performance 
when there is not sufficient information about the users and when 
there is not sufficient information about a new user whose taste the 
system attempts to predict 
selective-sharing relies on the ability to find similarity between 
specific parts of the probability distribution function associated with 
a characteristic of different users this capability is closely related 
to clustering and classification an area widely studied in machine 
learning given space considerations our review of this area is 
restricted to some representative approaches for clustering in spite of 
the richness of available clustering algorithms such as the famous 
k-means clustering algorithm hierarchical methods bayesian 
classifiers and maximum entropy various characteristics of 
fast-paced domains do not align well with the features of 
attributesbased clustering mechanisms suggesting these mechanisms would 
not perform well in such domains of particular importance is that 
the ca needs to find similarity between functions defined over a 
continuous interval with no distinct pre-defined attributes an 
additional difficulty is defining the distance measure 
many clustering techniques have been used in data mining 
with particular focus on incremental updates of the clustering due 
to the very large size of the databases however the 
applicability of these to fast-paced domains is quite limited because they rely 
on a large set of existing data similarly clustering algorithms 
designed for the task of class identification in spatial databases e g 
relying on a density-based notion are not useful for our case 
because our data has no spatial attributes 
the most relevant method for our purposes is the kullback-leibler 
relative entropy index that is used in probability theory and 
information theory this measure which can also be applied on 
continuous random variables relies on a natural distance measure 
from a true probability distribution either observation-based or 
calculated to an arbitrary probability distribution however the 
method will perform poorly in scenarios in which the functions 
alternate between different levels while keeping the general 
structure and moments for example consider the two functions f x 
 x mod and g x x mod defined over the 
interval while these two functions are associated with 
almost identical reservation values for any sampling cost and mean 
the kullback-leibler method will assign a poor correlation between 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
them while our wilcoxon-based approach will give them the 
highest rank in terms of similarity 
while the wilcoxon test is a widely used statistical procedure 
 it is usually used for comparing two sets of single-variate 
data to our knowledge no attempt has been made yet to 
extend its properties as an infrastructure for determining with whom 
and to what extent information should be shared as presented in 
this paper typical use of this non-parametric tool includes 
detection of rare events in time series e g a hard drive failure 
prediction and bioinformatics applications e g finding informative 
genes from microarray data in these applications it is used 
primarily as an identification tool and ranking criterion 
 discussion and conclusions 
the selective-sharing mechanism presented in this paper does 
not make any assumptions about the format of the data used or 
about the structure of the distribution function of the parameter to 
be estimated it is computationally lightweight and very simple to 
execute selective-sharing allows an agent to benefit from other 
agents observations in scenarios in which data sources of the same 
type are available it also guarantees as a fallback performance 
equivalent to that of a self-learner when the information source is 
unique furthermore selective-sharing does not require any prior 
knowledge about the types of information sources available in the 
environment or of the number of agents associated with each type 
the results of our simulations demonstrate the selective-sharing 
mechanism s effectiveness in improving the estimation produced 
for probabilistic parameters based on a limited set of observations 
furthermore most of the improvement is achieved in initial 
interactions which is of great importance for agents operating in 
fast-paced environments although we tested the selective-sharing 
mechanism in the context of the coordinators project it is 
applicable in any mas environment having the characteristics of a 
fast-paced environment e g rescue environments evidence for 
its general effectiveness is given in the general evaluation section 
where environments were continuously randomly generated 
the wilcoxon statistic used as described in this paper to provide 
a classifier for similarity between users provides high flexibility 
with low computational costs and is applicable for any 
characteristic being learned its use provides a good measure of similarity 
which an agent can use to decide how much external information 
to adopt for its assessments 
 acknowledgement 
the research reported in this paper was supported in part by 
contract number - a subcontract to sri international s 
darpa contract no fa - -c- any opinions findings 
and conclusions or recommendations expressed in this material 
are those of the authors and do not necessarily reflect the views of 
darpa or the u s government we are grateful to an anonymous 
aamas reviewer for an exceptionally comprehensive review of 
this paper 
 references 
 p adamczyk s iqbal and b bailey a method system and 
tools for intelligent interruption management in tamodia 
 pages - new york ny usa acm press 
 p berkhin survey of clustering data mining techniques 
technical report accrue software san jose ca 
 m ester h kriegel j sander m wimmer and x xu 
incremental clustering for mining in a data warehousing 
environment in proc th int conf very large data bases 
vldb pages - - 
 m ester h kriegel j sander and x xu a density-based 
algorithm for discovering clusters in large spatial databases 
with noise in kdd- pages - 
 m fleming and r cohen a decision procedure for 
autonomous agents to reason about interaction with humans 
in aaai spring symp on interaction between humans and 
autonomous systems over extended operation 
 n friedman d geiger and m goldszmidt bayesian 
network classifiers machine learning - 
 n good j ben schafer j konstan a borchers b sarwar 
j herlocker and j riedl combining collaborative filtering 
with personal agents for better recommendations in 
aaai iaai pages - 
 k hinckley j pierce m sinclair and e horvitz sensing 
techniques for mobile interaction in uist pages 
 - new york ny usa acm press 
 e horvitz c kadie t paek and d hovel models of 
attention in computing and communication from principles 
to applications commun acm - 
 b hui and c boutilier who s asking for help a bayesian 
approach to intelligent assistance in iui 
 j jang c sun and e mizutani neuro-fuzzy and soft 
computing a computational approach to learning and 
machine intelligence prentice hall 
 s kullback and r leibler on information and sufficiency 
ann math statist - 
 p maglio t matlock c campbell s zhai and b smith 
gaze and speech in attentive user interfaces in icmi pages 
 - 
 h mann and d whitney on a test of whether one of 
random variables is stochastically larger than the other 
annals of mathematical statistics - 
 w mcclure technology and command implications for 
military operations in the twenty-first century maxwell air 
force base center for strategy and technology 
 j mcmillan and m rothschild search in robert j aumann 
and amsterdam sergiu hart editors handbook of game 
theory with economic applications pages - 
 j murray g hughes and k kreutz-delgado machine 
learning methods for predicting failures in hard drives a 
multiple-instance application j mach learn res 
 - 
 d sarne and b j grosz estimating information value in 
collaborative multi-agent planning systems in aamas 
page to appear 
 d sarne and b j grosz timing interruptions for better 
human-computer coordinated planning in aaai spring 
symp on distributed plan and schedule management 
 r vertegaal the gaze groupware system mediating joint 
attention in multiparty communication and collaboration in 
chi pages - 
 t wagner j phelps v guralnik and r vanriper an 
application view of coordinators coordination managers for 
first responders in aaai pages - 
 f wilcoxon individual comparisons by ranking methods 
biometrics - 
 d zeng and k sycara bayesian learning in negotiation in 
aaai symposium on adaptation co-evolution and learning 
in multiagent systems pages - 
 y zhang k biggers l he s reddy d sepulvado j yen 
and t ioerger a distributed intelligent agent architecture for 
simulating aggregate-level behavior and interactions on the 
battlefield in sci- pages - 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
