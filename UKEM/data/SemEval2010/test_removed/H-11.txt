laplacian optimal design for image retrieval 
xiaofei he 
yahoo 
burbank ca 
hex yahoo-inc com 
wanli min 
ibm 
yorktown heights ny 
wanlimin us ibm com 
deng cai 
cs dept uiuc 
urbana il 
dengcai  cs uiuc edu 
kun zhou 
microsoft research asia 
beijing china 
kunzhou microsoft com 
abstract 
relevance feedback is a powerful technique to enhance 
contentbased image retrieval cbir performance it solicits the 
user s relevance judgments on the retrieved images returned 
by the cbir systems the user s labeling is then used to 
learn a classifier to distinguish between relevant and 
irrelevant images however the top returned images may not be 
the most informative ones the challenge is thus to 
determine which unlabeled images would be the most informative 
 i e improve the classifier the most if they were labeled 
and used as training samples in this paper we propose 
a novel active learning algorithm called laplacian 
optimal design lod for relevance feedback image retrieval 
our algorithm is based on a regression model which 
minimizes the least square error on the measured or labeled 
images and simultaneously preserves the local geometrical 
structure of the image space specifically we assume that 
if two images are sufficiently close to each other then their 
measurements or labels are close as well by constructing 
a nearest neighbor graph the geometrical structure of the 
image space can be described by the graph laplacian we 
discuss how results from the field of optimal experimental 
design may be used to guide our selection of a subset of 
images which gives us the most amount of information 
experimental results on corel database suggest that the proposed 
approach achieves higher precision in relevance feedback 
image retrieval 
categories and subject descriptors 
h information storage and retrieval information 
search and retrieval-relevance feedback g mathematics 
of computing probability and statistics-experimental 
design 
general terms 
algorithms performance theory 
 introduction 
in many machine learning and information retrieval tasks 
there is no shortage of unlabeled data but labels are 
expensive the challenge is thus to determine which unlabeled 
samples would be the most informative i e improve the 
classifier the most if they were labeled and used as training 
samples this problem is typically called active learning 
here the task is to minimize an overall cost which depends 
both on the classifier accuracy and the cost of data 
collection many real world applications can be casted into active 
learning framework particularly we consider the problem 
of relevance feedback driven content-based image retrieval 
 cbir 
content-based image retrieval has attracted substantial 
interests in the last decade it is motivated by the fast 
growth of digital image databases which in turn require 
efficient search schemes rather than describe an image 
using text in these systems an image query is described using 
one or more example images the low level visual features 
 color texture shape etc are automatically extracted to 
represent the images however the low level features may 
not accurately characterize the high level semantic concepts 
to narrow down the semantic gap relevance feedback is 
introduced into cbir 
in many of the current relevance feedback driven cbir 
systems the user is required to provide his her relevance 
judgments on the top images returned by the system the 
labeled images are then used to train a classifier to separate 
images that match the query concept from those that do 
not however in general the top returned images may not 
be the most informative ones in the worst case all the 
top images labeled by the user may be positive and thus 
the standard classification techniques can not be applied 
due to the lack of negative examples unlike the standard 
classification problems where the labeled samples are 
pregiven in relevance feedback image retrieval the system can 
actively select the images to label thus active learning can 
be naturally introduced into image retrieval 
despite many existing active learning techniques support 
vector machine svm active learning and regression 
based active learning have received the most interests 
based on the observation that the closer to the svm 
boundary an image is the less reliable its classification is svm 
active learning selects those unlabeled images closest to the 
boundary to solicit user feedback so as to achieve maximal 
refinement on the hyperplane between the two classes the 
major disadvantage of svm active learning is that the 
estimated boundary may not be accurate enough moreover it 
may not be applied at the beginning of the retrieval when 
there is no labeled images some other svm based active 
learning algorithms can be found in 
in statistics the problem of selecting samples to label is 
typically referred to as experimental design the sample 
x is referred to as experiment and its label y is referred 
to as measurement the study of optimal experimental 
design oed is concerned with the design of experiments 
that are expected to minimize variances of a parameterized 
model the intent of optimal experimental design is 
usually to maximize confidence in a given model minimize 
parameter variances for system identification or minimize the 
model s output variance classical experimental design 
approaches include a-optimal design d-optimal design and 
e-optimal design all of these approaches are based on a 
least squares regression model comparing to svm based 
active learning algorithms experimental design approaches 
are much more efficient in computation however this kind 
of approaches takes only measured or labeled data into 
account in their objective function while the unmeasured 
 or unlabeled data is ignored 
benefit from recent progresses on optimal experimental 
design and semi-supervised learning in this paper we 
propose a novel active learning algorithm for image retrieval 
called laplacian optimal design lod unlike 
traditional experimental design methods whose loss functions are 
only defined on the measured points the loss function of 
our proposed lod algorithm is defined on both measured 
and unmeasured points specifically we introduce a locality 
preserving regularizer into the standard least-square-error 
based loss function the new loss function aims to find a 
classifier which is locally as smooth as possible in other 
words if two points are sufficiently close to each other in 
the input space then they are expected to share the same 
label once the loss function is defined we can select the 
most informative data points which are presented to the user 
for labeling it would be important to note that the most 
informative images may not be the top returned images 
the rest of the paper is organized as follows in section 
 we provide a brief description of the related work our 
proposed laplacian optimal design algorithm is introduced 
in section in section we compare our algorithm with 
the state-or-the-art algorithms and present the experimental 
results on image retrieval finally we provide some 
concluding remarks and suggestions for future work in section 
 related work 
since our proposed algorithm is based on regression 
framework the most related work is optimal experimental design 
 including a-optimal design d-optimal design and 
eoptimal design in this section we give a brief description 
of these approaches 
 the active learning problem 
the generic problem of active learning is the following 
given a set of points a x x · · · xm in rd 
 find a 
subset b z z · · · zk ⊂ a which contains the most 
informative points in other words the points zi i · · · k 
can improve the classifier the most if they are labeled and 
used as training points 
 optimal experimental design 
we consider a linear regression model 
y wt 
x 
where y is the observation x is the independent variable 
w is the weight vector and is an unknown error with zero 
mean different observations have errors that are 
independent but with equal variances σ 
 we define f x wt 
x 
to be the learner s output given input x and the weight 
vector w suppose we have a set of labeled sample points 
 z y · · · zk yk where yi is the label of zi thus the 
maximum likelihood estimate for the weight vector ˆw is 
that which minimizes the sum squared error 
jsse w 
k 
i 
wt 
zi − yi 
 
 
the estimate ˆw gives us an estimate of the output at a novel 
input ˆy ˆwt 
x 
by gauss-markov theorem we know that ˆw − w has a 
zero mean and a covariance matrix given by σ 
h− 
sse where 
hsse is the hessian of jsse w 
hsse 
∂ 
jsse 
∂w 
 
k 
i 
zizt 
i zzt 
where z z z · · · zk 
the three most common scalar measures of the size of the 
parameter covariance matrix in optimal experimental design 
are 
 d-optimal design determinant of hsse 
 a-optimal design trace of hsse 
 e-optimal design maximum eigenvalue of hsse 
since the computation of the determinant and eigenvalues 
of a matrix is much more expensive than the computation 
of matrix trace a-optimal design is more efficient than the 
other two some recent work on experimental design can be 
found in 
 laplacian optimal design 
since the covariance matrix hsse used in traditional 
approaches is only dependent on the measured samples i e 
zi s these approaches fail to evaluate the expected errors 
on the unmeasured samples in this section we introduce 
a novel active learning algorithm called laplacian optimal 
design lod which makes efficient use of both measured 
 labeled and unmeasured unlabeled samples 
 the objective function 
in many machine learning problems it is natural to 
assume that if two points xi xj are sufficiently close to each 
other then their measurements f xi f xj are close as 
well let s be a similarity matrix thus a new loss function 
which respects the geometrical structure of the data space 
can be defined as follows 
j w 
k 
i 
f zi −yi 
 
 
λ 
 
m 
i j 
f xi −f xj 
 
sij 
where yi is the measurement or label of zi note that 
the loss function is essentially the same as the one used 
in laplacian regularized regression lrr however 
lrr is a passive learning algorithm where the training data 
is given in this paper we are focused on how to select the 
most informative data for training the loss function with 
our choice of symmetric weights sij sij sji incurs a 
heavy penalty if neighboring points xi and xj are mapped 
far apart therefore minimizing j w is an attempt to 
ensure that if xi and xj are close then f xi and f xj are 
close as well there are many choices of the similarity matrix 
s a simple definition is as follows 
sij 
⎧ 
⎨ 
⎩ 
 if xi is among the p nearest neighbors of xj 
or xj is among the p nearest neighbors of xi 
 otherwise 
 
let d be a diagonal matrix dii j sij and l d−s 
the matrix l is called graph laplacian in spectral graph 
theory let y y · · · yk t 
and x x · · · xm 
following some simple algebraic steps we see that 
j w 
 
k 
i 
wt 
zi − yi 
 
 
λ 
 
m 
i j 
wt 
xi − wt 
xj 
 
sij 
 y − zt 
w 
t 
y − zt 
w λwt 
m 
i 
diixixt 
i 
− 
m 
i j 
sijxixt 
j w 
 yt 
y − wt 
zy wt 
zzt 
w 
 λwt 
xdxt 
− xsxt 
w 
 yt 
y − wt 
zy wt 
zzt 
 λxlxt 
w 
the hessian of j w can be computed as follows 
h 
∂ 
j 
∂w 
 zzt 
 λxlxt 
in some cases the matrix zzt 
 λxlxt 
is singular e g if 
m d thus there is no stable solution to the optimization 
problem eq a common way to deal with this ill-posed 
problem is to introduce a tikhonov regularizer into our loss 
function 
j w 
 
k 
i 
wt 
zi − yi 
 
 
λ 
 
m 
i j 
wt 
xi − wt 
xj 
 
sij 
 λ w 
 
the hessian of the new loss function is given by 
h 
∂ 
j 
∂w 
 zzt 
 λ xlxt 
 λ i 
 zzt 
 λ 
where i is an identity matrix and λ λ xlxt 
 λ i 
clearly h is of full rank requiring that the gradient of 
j w with respect to w vanish gives the optimal estimate 
ˆw 
ˆw h− 
zy 
the following proposition states the bias and variance 
properties of the estimator for the coefficient vector w 
proposition e ˆw − w −h− 
λw cov ˆw 
σ 
 h− 
− h− 
λh− 
 
proof since y zt 
w and e it follows that 
e ˆw − w 
 h− 
zzt 
w − w 
 h− 
 zzt 
 λ − λ w − w 
 i − h− 
λ w − w 
 −h− 
λw 
notice cov y σ 
i the covariance matrix of ˆw has the 
expression 
cov ˆw h− 
zcov y zt 
h− 
 σ 
h− 
zzt 
h− 
 σ 
h− 
 h − λ h− 
 σ 
 h− 
− h− 
λh− 
 
therefore mean squared error matrix for the coefficients w 
is 
e w − ˆw w − ˆw t 
 
 h− 
λwwt 
λh− 
 σ 
 h− 
− h− 
λh− 
 
for any x let ˆy ˆwt 
x be its predicted observation the 
expected squared prediction error is 
e y − ˆy 
 e wt 
x − ˆwt 
x 
 σ 
 xt 
 e w − ˆw w − ˆw t 
 x 
 σ 
 xt 
 h− 
λwwt 
λh− 
 σ 
h− 
− σ 
h− 
λh− 
 x 
clearly the expected square prediction error depends on the 
explanatory variable x therefore average expected square 
predictive error over the complete data set a is 
 
m 
m 
i 
e yi − ˆwt 
xi 
 
 
m 
m 
i 
xt 
i h− 
λwwt 
λh− 
 σ 
h− 
− σ 
h− 
λh− 
 xi 
 σ 
 
 
m 
tr xt 
 σ 
h− 
 h− 
λwwt 
λh− 
− σ 
h− 
λh− 
 x 
 σ 
since 
tr xt 
 h− 
λwwt 
λh− 
− σ 
h− 
λh− 
 x 
tr σ 
xt 
h− 
x 
our laplacian optimality criterion is thus formulated by 
minimizing the trace of xt 
h− 
x 
definition laplacian optimal design 
min 
z z ··· zk 
tr xt 
zzt 
 λ xlxt 
 λ i 
− 
x 
where z · · · zk are selected from x · · · xm 
 kernel laplacian optimal design 
canonical experimental design approaches e g a-optimal 
design d-optimal design and e-optimal only consider 
linear functions they fail to discover the intrinsic geometry 
in the data when the data space is highly nonlinear in this 
section we describe how to perform laplacian 
experimental design in reproducing kernel hilbert space rkhs 
which gives rise to kernel laplacian experimental design 
 klod 
for given data points x · · · xm ∈ x with a positive 
definite mercer kernel k x ×x → r there exists a unique 
rkhs hk of real valued functions on x let kt s be the 
function of s obtained by fixing t and letting kt s 
 
 k s t 
hk consists of all finite linear combinations of the form 
l 
i αikti with ti ∈ x and limits of such functions as the 
ti become dense in x we have ks kt hk k s t 
 derivation of lod in reproducing 
kernel hilbert space 
consider the optimization problem in rkhs thus 
we seek a function f ∈ hk such that the following objective 
function is minimized 
min 
f∈hk 
k 
i 
f zi −yi 
 
 
λ 
 
m 
i j 
f xi −f xj 
 
sij λ f 
hk 
 
we have the following proposition 
proposition let h m 
i αik · xi αi ∈ r be 
a subspace of hk the solution to the problem is in h 
proof let h⊥ 
be the orthogonal complement of h i e 
hk h ⊕ h⊥ 
 thus for any function f ∈ hk it has 
orthogonal decomposition as follows 
f fh fh⊥ 
now let s evaluate f at xi 
f xi f kxi hk 
 fh fh⊥ kxi hk 
 fh kxi hk fh⊥ kxi hk 
notice that kxi ∈ h while fh⊥ ∈ h⊥ 
 this implies that 
fh⊥ kxi hk therefore 
f xi fh kxi hk fh xi 
this completes the proof 
proposition tells us the minimizer of problem admits 
a representation f 
 m 
i αik · xi please see for the 
details 
let φ rd 
→ h be a feature map from the input space 
rd 
to h and k xi xj φ xi φ xj let x denote 
the data matrix in rkhs x φ x φ x · · · φ xm 
similarly we define z φ z φ z · · · φ zk thus 
the optimization problem in rkhs can be written as follows 
min 
z 
tr xt 
zzt 
 λ xlxt 
 λ i 
− 
x 
since the mapping function φ is generally unknown there 
is no direct way to solve problem in the following we 
apply kernel tricks to solve this optimization problem let 
x− 
be the moore-penrose inverse also known as pseudo 
inverse of x thus we have 
xt 
zzt 
 λ xlxt 
 λ i 
− 
x 
 xt 
xx− 
zzt 
 λ xlxt 
 λ i 
− 
 xt 
 − 
xt 
x 
 xt 
x zzt 
x λ xlxt 
x λ x 
− 
 xt 
 − 
xt 
x 
 xt 
x xt 
zzt 
x λ xt 
xlxt 
x λ xt 
x 
− 
xt 
x 
 kxx kxzkzx λ kxxlkxx λ kxx 
− 
kxx 
where kxx is a m × m matrix kxx ij k xi xj kxz 
is a m×k matrix kxz ij k xi zj and kzx is a k×m 
matrix kzx ij k zi xj thus the kernel laplacian 
optimal design can be defined as follows 
definition kernel laplacian optimal design 
minz z ··· zk tr kxx kxzkzx λ kxxlkxx 
λ kxx 
− 
kxx 
 optimization scheme 
in this subsection we discuss how to solve the 
optimization problems and particularly if we select a 
linear kernel for klod then it reduces to lod therefore 
we will focus on problem in the following 
it can be shown that the optimization problem is 
np-hard in this subsection we develop a simple sequential 
greedy approach to solve suppose n points have been 
selected denoted by a matrix zn 
 z · · · zn the n 
 -th point zn can be selected by solving the following 
optimization problem 
max 
zn zn zn 
tr kxx kxzn kzn x 
λ kxxlkxx λ kxx 
− 
kxx 
the kernel matrices kxzn and kzn x can be rewritten 
as follows 
kxzn kxzn kxzn kzn x 
kznx 
kzn x 
thus we have 
kxzn kzn x kxzn kznx kxzn kzn x 
we define 
a kxzn kznx λ kxxlkxx λ kxx 
a is only dependent on x and zn 
 thus the n -th 
point zn is given by 
zn arg min 
zn 
tr kxx a kxzn kzn x 
− 
kxx 
 
each time we select a new point zn the matrix a is 
updated by 
a ← a kxzn kzn x 
if the kernel function is chosen as inner product k x y 
x y then hk is a linear functional space and the 
algorithm reduces to lod 
 content-based image retrieval 
using laplacian optimal design 
in this section we describe how to apply laplacian 
optimal design to cbir we begin with a brief description of 
image representation using low level visual features 
 low-level image representation 
low-level image representation is a crucial problem in 
cbir general visual features includes color texture shape 
etc color and texture features are the most extensively used 
visual features in cbir compared with color and texture 
features shape features are usually described after images 
have been segmented into regions or objects since robust 
and accurate image segmentation is difficult to achieve the 
use of shape features for image retrieval has been limited 
to special applications where objects or regions are readily 
available 
in this work we combine -dimensional color histogram 
and -dimensional color texture moment ctm to 
represent the images the color histogram is calculated 
using × × bins in hsv space the color texture 
moment is proposed by yu et al which integrates the 
color and texture characteristics of the image in a compact 
form ctm adopts local fourier transform as a texture 
representation scheme and derives eight characteristic maps to 
describe different aspects of co-occurrence relations of 
image pixels in each channel of the svcosh svsinh v color 
space then ctm calculates the first and second moment 
of these maps as a representation of the natural color image 
pixel distribution please see for details 
 relevance feedback image retrieval 
relevance feedback is one of the most important 
techniques to narrow down the gap between low level visual 
features and high level semantic concepts 
traditionally the user s relevance feedbacks are used to update the 
query vector or adjust the weighting of different dimensions 
this process can be viewed as an on-line learning process in 
which the image retrieval system acts as a learner and the 
user acts as a teacher they typical retrieval process is 
outlined as follows 
 the user submits a query image example to the 
system the system ranks the images in database 
according to some pre-defined distance metric and presents 
to the user the top ranked images 
 the system selects some images from the database and 
request the user to label them as relevant or 
irrelevant 
 the system uses the user s provided information to 
rerank the images in database and returns to the user 
the top images go to step until the user is satisfied 
our laplacian optimal design algorithm is applied in the 
second step for selecting the most informative images once 
we get the labels for the images selected by lod we apply 
laplacian regularized regression lrr to solve the 
optimization problem and build the classifier the 
classifier is then used to re-rank the images in database note 
that in order to reduce the computational complexity we 
do not use all the unlabeled images in the database but only 
those within top returns of previous iteration 
 experimental results 
in this section we evaluate the performance of our 
proposed algorithm on a large image database to demonstrate 
the effectiveness of our proposed lod algorithm we 
compare it with laplacian regularized regression lrr 
support vector machine svm support vector machine 
active learning svmactive and a-optimal design 
 aod both svmactive aod and lod are active 
learning algorithms while lrr and svm are standard 
classification algorithms svm only makes use of the labeled 
images while lrr is a semi-supervised learning algorithm 
which makes use of both labeled and unlabeled images for 
svmactive aod and lod training images are selected 
by the algorithms themselves at each iteration while for 
lrr and svm we use the top images as training data 
it would be important to note that svmactive is based on 
the ordinary svm lod is based on lrr and aod is based 
on the ordinary regression the parameters λ and λ in our 
lod algorithm are empirically set to be and 
for both lrr and lod algorithms we use the same graph 
structure see eq and set the value of p number of 
nearest neighbors to be we begin with a simple synthetic 
example to give some intuition about how lod works 
 simple synthetic example 
a simple synthetic example is given in figure the data 
set contains two circles eight points are selected by aod 
and lod as can be seen all the points selected by aod 
are from the big circle while lod selects four points from 
the big circle and four from the small circle the numbers 
beside the selected points denote their orders to be selected 
clearly the points selected by our lod algorithm can better 
represent the original data set we did not compare our 
algorithm with svmactive because svmactive can not be 
applied in this case due to the lack of the labeled points 
 image retrieval experimental design 
the image database we used consists of images of 
 semantic categories from corel data set it is a large 
and heterogeneous image set each image is represented as 
a -dimensional vector as described in section figure 
 shows some sample images 
to exhibit the advantages of using our algorithm we need 
a reliable way of evaluating the retrieval performance and 
the comparisons with other algorithms we list different 
aspects of the experimental design below 
 evaluation metrics 
we use precision-scope curve and precision rate to 
evaluate the effectiveness of the image retrieval algorithms 
the scope is specified by the number n of top-ranked 
images presented to the user the precision is the ratio of 
the number of relevant images presented to the user to the 
 a data set 
 
 
 
 
 
 
 
 
 b aod 
 
 
 
 
 
 
 
 
 c lod 
figure data selection by active learning algorithms the numbers beside the selected points denote their 
orders to be selected clearly the points selected by our lod algorithm can better represent the original 
data set note that the svmactive algorithm can not be applied in this case due to the lack of labeled points 
 a b c 
figure sample images from category bead elephant and ship 
scope n the precision-scope curve describes the precision 
with various scopes and thus gives an overall performance 
evaluation of the algorithms on the other hand the 
precision rate emphasizes the precision at a particular value of 
scope in general it is appropriate to present images on 
a screen putting more images on a screen may affect the 
quality of the presented images therefore the precision at 
top n is especially important 
in real world image retrieval systems the query image is 
usually not in the image database to simulate such 
environment we use five-fold cross validation to evaluate the 
algorithms more precisely we divide the whole image database 
into five subsets with equal size thus there are images 
per category in each subset at each run of cross validation 
one subset is selected as the query set and the other four 
subsets are used as the database for retrieval the 
precisionscope curve and precision rate are computed by averaging 
the results from the five-fold cross validation 
 automatic relevance feedback scheme 
we designed an automatic feedback scheme to model the 
retrieval process for each submitted query our system 
retrieves and ranks the images in the database images 
were selected from the database for user labeling and the 
label information is used by the system for re-ranking note 
that the images which have been selected at previous 
iterations are excluded from later selections for each query 
the automatic relevance feedback mechanism is performed 
for four iterations 
it is important to note that the automatic relevance 
feedback scheme used here is different from the ones described 
in in the top four relevant and irrelevant 
images were selected as the feedback images however this 
may not be practical in real world image retrieval systems 
it is possible that most of the top-ranked images are relevant 
 or irrelevant thus it is difficult for the user to find both 
four relevant and irrelevant images it is more reasonable 
for the users to provide feedback information only on the 
images selected by the system 
 image retrieval performance 
in real world it is not practical to require the user to 
provide many rounds of feedbacks the retrieval 
performance after the first two rounds of feedbacks especially the 
first round is more important figure shows the average 
precision-scope curves of the different algorithms for the first 
two feedback iterations at the beginning of retrieval the 
euclidean distances in the original -dimensional space 
are used to rank the images in database after the user 
provides relevance feedbacks the lrr svm svmactive 
aod and lod algorithms are then applied to re-rank the 
images in order to reduce the time complexity of active 
learning algorithms we didn t select the most informative 
images from the whole database but from the top 
images for lrr and svm the user is required to label the 
top images for svmactive aod and lod the user 
is required to label most informative images selected by 
these algorithms note that svmactive can only be 
ap a feedback iteration b feedback iteration 
figure the average precision-scope curves of different algorithms for the first two feedback iterations the 
lod algorithm performs the best on the entire scope note that at the first round of feedback the svmactive 
algorithm can not be applied it applies the ordinary svm to build the initial classifier 
 a precision at top b precision at top c precision at top 
figure performance evaluation of the five learning algorithms for relevance feedback image retrieval a 
precision at top b precision at top and c precision at top as can be seen our lod algorithm 
consistently outperforms the other four algorithms 
plied when the classifier is already built therefore it can 
not be applied at the first round and we use the standard 
svm to build the initial classifier as can be seen our lod 
algorithm outperforms the other four algorithms on the 
entire scope also the lrr algorithm performs better than 
svm this is because that the lrr algorithm makes 
efficient use of the unlabeled images by incorporating a locality 
preserving regularizer into the ordinary regression objective 
function the aod algorithm performs the worst as the 
scope gets larger the performance difference between these 
algorithms gets smaller 
by iteratively adding the user s feedbacks the 
corresponding precision results at top top and top of the 
five algorithms are respectively shown in figure as can be 
seen our lod algorithm performs the best in all the cases 
and the lrr algorithm performs the second best both of 
these two algorithms make use of the unlabeled images this 
shows that the unlabeled images are helpful for discovering 
the intrinsic geometrical structure of the image space and 
therefore enhance the retrieval performance in real world 
the user may not be willing to provide too many relevance 
feedbacks therefore the retrieval performance at the first 
two rounds are especially important as can be seen our 
lod algorithm achieves performance improvement for 
top results for top results and for top 
results comparing to the second best algorithm lrr after 
the first two rounds of relevance feedbacks 
 discussion 
several experiments on corel database have been 
systematically performed we would like to highlight several 
interesting points 
 it is clear that the use of active learning is beneficial 
in the image retrieval domain there is a significant 
increase in performance from using the active learning 
methods especially out of the three active learning 
methods svmactive aod lod our proposed lod 
algorithm performs the best 
 in many real world applications like relevance 
feedback image retrieval there are generally two ways of 
reducing labor-intensive manual labeling task one is 
active learning which selects the most informative 
samples to label and the other is semi-supervised learning 
which makes use of the unlabeled samples to enhance 
the learning performance both of these two 
strategies have been studied extensively in the past 
 the work presented in this paper is 
focused on active learning but it also takes advantage of 
the recent progresses on semi-supervised learning 
specifically we incorporate a locality preserving 
regularizer into the standard regression framework and 
find the most informative samples with respect to the 
new objective function in this way the active learning 
and semi-supervised learning techniques are seamlessly 
unified for learning an optimal classifier 
 the relevance feedback technique is crucial to image 
retrieval for all the five algorithms the retrieval 
performance improves with more feedbacks provided by 
the user 
 conclusions and future work 
this paper describes a novel active learning algorithm 
called laplacian optimal design to enable more effective 
relevance feedback image retrieval our algorithm is based 
on an objective function which simultaneously minimizes the 
empirical error and preserves the local geometrical structure 
of the data space using techniques from experimental 
design our algorithm finds the most informative images to 
label these labeled images and the unlabeled images in 
the database are used to learn a classifier the 
experimental results on corel database show that both active learning 
and semi-supervised learning can significantly improve the 
retrieval performance 
in this paper we consider the image retrieval problem on 
a small static and closed-domain image data a much more 
challenging domain is the world wide web www for 
web image search it is possible to collect a large amount 
of user click information this information can be naturally 
used to construct the affinity graph in our algorithm 
however the computational complexity in web scenario may 
become a crucial issue also although our primary interest in 
this paper is focused on relevance feedback image retrieval 
our results may also be of interest to researchers in patten 
recognition and machine learning especially when a large 
amount of data is available but only a limited samples can 
be labeled 
 references 
 a c atkinson and a n donev optimum 
experimental designs oxford university press 
 m belkin p niyogi and v sindhwani manifold 
regularization a geometric framework for learning 
from examples journal of machine learning 
research - 
 f r k chung spectral graph theory volume of 
regional conference series in mathematics ams 
 
 d a cohn z ghahramani and m i jordan active 
learning with statistical models journal of artificial 
intelligence research - 
 a dong and b bhanu a new semi-supervised em 
algorithm for image retrieval in ieee conf on 
computer vision and pattern recognition madison 
wi 
 p flaherty m i jordan and a p arkin robust 
design of biological experiments in advances in 
neural information processing systems vancouver 
canada 
 k -s goh e y chang and w -c lai multimodal 
concept-dependent active learning for image retrieval 
in proceedings of the acm conference on multimedia 
new york october 
 x he incremental semi-supervised subspace learning 
for image retrieval in proceedings of the acm 
conference on multimedia new york october 
 s c hoi and m r lyu a semi-supervised active 
learning framework for image retrieval in ieee 
international conference on computer vision and 
pattern recognition san diego ca 
 d p huijsmans and n sebe how to complete 
performance graphs in content-based image retrieval 
add generality and normalize scope ieee 
transactions on pattern analysis and machine 
intelligence - 
 y -y lin t -l liu and h -t chen semantic 
manifold learning for image retrieval in proceedings of 
the acm conference on multimedia singapore 
november 
 y rui t s huang m ortega and s mehrotra 
relevance feedback a power tool for interative 
content-based image retrieval ieee transactions on 
circuits and systems for video technology 
 a w smeulders m worring s santini a gupta 
and r jain content-based image retrieval at the end 
of the early years ieee transactions on pattern 
analysis and machine intelligence - 
 
 s tong and e chang support vector machine active 
learning for image retrieval in proceedings of the 
ninth acm international conference on multimedia 
pages - 
 h yu m li h -j zhang and j feng color texture 
moments for content-based image retrieval in 
international conference on image processing pages 
 - 
 k yu j bi and v tresp active learning via 
transductive experimental design in proceedings of 
the rd 
international conference on machine 
learning pittsburgh pa 
