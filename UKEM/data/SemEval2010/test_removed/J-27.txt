learning from revealed 
preference 
 extended abstract 
eyal beigman 
cms-ems 
kellogg school of management 
northwestern university 
evanston il 
e-beigman northwestern edu 
rakesh vohra 
meds 
kellogg school of management 
northwestern university 
evanston il 
r-vohra northwestern edu 
abstract 
a sequence of prices and demands are rationalizable if there 
exists a concave continuous and monotone utility function 
such that the demands are the maximizers of the utility 
function over the budget set corresponding to the price 
afriat presented necessary and sufficient conditions for 
a finite sequence to be rationalizable varian and later 
blundell et al continued this line of work studying 
nonparametric methods to forecasts demand their results 
essentially characterize learnability of degenerate classes of 
demand functions and therefore fall short of giving a 
general degree of confidence in the forecast the present paper 
complements this line of research by introducing a statistical 
model and a measure of complexity through which we are 
able to study the learnability of classes of demand functions 
and derive a degree of confidence in the forecasts 
our results show that the class of all demand functions 
has unbounded complexity and therefore is not learnable 
but that there exist interesting and potentially useful classes 
that are learnable from finite samples we also present a 
learning algorithm that is an adaptation of a new proof of 
afriat s theorem due to teo and vohra 
categories and subject descriptors 
f theory of computation analysis of algorithms 
and problem complexity j computer applications 
social and behavioral sciences-economics i learning 
parameter learning 
general terms 
economics algorithms theory 
 introduction 
a market is an institution by which economic agents meet 
and make transactions classical economic theory explains 
the incentives of the agents to engage in this behavior through 
the agents preference over the set of available bundles 
indicating that agents attempt to replace their current bundle 
with bundles that are both more preferred and attainable if 
such bundles exist the preference relation is therefore the 
key factor in understanding consumer behavior 
one of the common assumptions in this theory is that the 
preference relation is represented by a utility function and 
that agents strive to maximize their utility given a budget 
constraint this pattern of behavior is the essence of supply 
and demand general equilibria and other aspects of 
consumer theory furthermore as we elaborate in section 
basic observations on market demand behavior suggest that 
utility functions are monotone and concave 
this brings us to the question first raised by 
samuelson to what degree is this theory refutable given 
observations of price and demand under what circumstances 
can we conclude that the data is consistent with the 
behavior of a utility maximizing agent equipped with a monotone 
concave utility function and subject to a budget constraint 
samuelson gave a necessary but insufficient condition on the 
underlying preference known as the weak axiom of revealed 
preference uzawa and mas-colell introduced a 
notion of income-lipschitz and showed that demand 
functions with this property are rationalizable these properties 
do not require any parametric assumptions and are 
technically refutable but they do assume knowledge of the entire 
demand function and rely heavily on the differential 
properties of demand functions hence an infinite amount of 
information is needed to refute the theory 
it is often the case that apart form the demand 
observations there is additional information on the system and 
it is sensible to make parametric assumptions namely to 
stipulate some functional form of utility consistency with 
utility maximization would then depend on fixing the 
parameters of the utility function to be consistent with the 
observations and with a set of equations called the 
slutski equations if such parameters exist we conclude that 
the stipulated utility form is consistent with the 
observations this approach is useful when there is reason to make 
these stipulations it gives an explicit utility function which 
can be used to make precise forecasts on demand for 
unob 
served prices the downside of this approach is that real life 
data is often inconsistent with convenient functional forms 
moreover if the observations are inconsistent it is unclear 
whether this is a refutation of the stipulated functional form 
or of utility maximization 
addressing these issues houthakker noted that an 
observer can see only finite quantities of data he askes when 
can it be determined that a finite set of observations is 
consistent with utility maximization without making 
parametric assumptions he showes that rationalizability of a finite 
set of observations is equivalent to the strong axiom of 
revealed preference richter showes that strong axiom 
of revealed preference is equivalent to rationalizability by a 
strictly concave monotone utility function afriat gives 
another set of rationalizability conditions the observations 
must satisfy varian introduces the generalized axiom of 
revealed preference garp an equivalent form of afriat s 
consistency condition that is easier to verify 
computationally it is interesting to note that these necessary and 
sufficient conditions for rationalizability are essentially versions 
of the well known farkas lemma see also 
afriat proved his theorem by an explicit construction 
of a utility function witnessing consistency varian took 
this one step further progressing from consistency to 
forecasting varian s forecasting algorithm basically rules out 
bundles that are revealed inferior to observed bundles and 
finds a bundle from the remaining set that together with the 
observations is consistent with garp furthermore he 
introduces samuelson s money metric as a canonical utility 
function and gives upper and lower envelope utility functions 
for the money metric knoblauch shows these envelopes 
can be computed efficiently varian provides an up to 
date survey on this line of research 
a different approach is presented by blundell et al 
these papers introduce a model where an agent observes 
prices and engel curves for these prices this gives an 
improvement on varian s original bounds though the basic 
idea is still to rule out demands that are revealed inferior 
this model is in a sense a hybrid between mas-colell and 
afriat s aproaches the former requires full information for 
all prices the latter for a finite number of prices on the 
other hand the approach taken by blundell et al requires 
full information only on a finite number of price 
trajectories the motivation for this crossover is to utilize income 
segmentation in the population to restructure econometric 
information different segments of the population face the 
same prices with different budgets and as much as 
aggregate data can testify on individual preferences show how 
demand varies with the budget applying non parametric 
statistical methods they reconstruct a trajectory from the 
observed demands of different segments and use it to obtain 
tighter bounds 
both these methods would most likely give a good forecast 
for a fixed demand function after sufficiently many 
observations assuming they were spread out in a reasonable manner 
however these methods do not consider the complexity of 
the demand functions and do not use any probabilistic model 
of the observations therefore they are unable to provide 
any estimate of the number of observations that would be 
sufficient for a good forecast or the degree of confidence in 
such a forecast 
in this paper we examine the feasibility of demand 
forecasting with a high degree of confidence using afriat s 
conditions we formulate the question in terms of whether the 
class of demand functions derived from monotone concave 
utilities is efficiently pac-learnable our first result is 
negative we show by computing the fat shattering dimension 
that without any prior assumptions the set of all demand 
functions induced by monotone concave utility functions is 
too rich to be efficiently pac-learnable however under 
some prior assumptions on the set of demand functions we 
show that the fat shattering dimension is finite and therefore 
the corresponding sets are pac-learnable in these cases 
assuming the probability distribution by which the observed 
price-demand pairs are generated is fixed we are in a 
position to offer a forecast and a probabilistic estimate on its 
accuracy 
in section we briefly discuss the basic assumptions of 
demand theory and their implications in section we present 
a new proof to afriat s theorem incorporating an algorithm 
for efficiently generating a forecasting function due to teo 
and vohra we show that this algorithm is 
computationally efficient and can be used as a learning algorithm 
in section we give a brief introduction to pac learning 
including several modifications to learning real vector 
valued functions we introduce the notion of fat shattering 
dimension and use it to devise a lower bound on the 
sample complexity we also sketch results on upper bounds in 
section we study the learnability of demand functions and 
directly compute the fat shattering dimension of the class 
of all demand functions and a class of income-lipschitzian 
demand functions with a bounded global income-lipschitz 
constant 
 utility and demand 
a utility function u rn 
 → r is a function relating 
bundles of goods to a cardinal in a manner reflecting the 
preferences over the bundles a rational agent with a budget that 
w l g equals facing a price vector p ∈ rn 
 will choose from 
her budget set b p x ∈ rn 
 p · x ≤ a bundle x ∈ rn 
 
that maximizes her private utility 
the first assumption we make is that the function is 
monotone increasing namely if x ≥ y in the sense that the 
inequality holds coordinatewise then u x ≥ u y this 
reflects the assumption that agents will always prefer more of 
any one good this of course does not necessarily hold in 
practice as in many cases excess supply may lead to 
storage expenses or other externalities however in such cases 
the demand will be an interior point of the budget set and 
the less preferred bundles won t be observed the second 
assumption we make on the utility is that all the marginals 
 partial derivatives are monotone decreasing this is the 
law of diminishing marginal utility which assumes that the 
larger the excess of one good over the other the less we value 
each additional good of one kind over the other these 
assumptions imply that the utility function is concave and 
monotone on the observations 
the demand function of the agent is the correspondence 
fu rn 
 → rn 
 satisfying 
f p argmax u x p · x ≤ i 
in general this correspondence is not necessarily single 
valued but it is implicit in the proof of afriat s theorem that 
any set of observations can be rationalized by a demand 
function that is single valued for unobserved prices 
 
since large quantities of any good are likely to create 
utility decreasing externalities we assume the prices are limited 
to a compact set w l g we assume u has marginal utility 
zero outside d 
 any budget set that is not a subset of 
the support is maximized on any point outside the support 
and it is therefore difficult to forecast for these prices we 
are thus interested in forecasts for prices below the simplex 
∆d conv for these prices we take the 
metric 
dp p p max 
 
pi 
− 
 
pi 
 i d 
for p p ∈ ∆d note that with this metric ∆d is compact a 
demand function is l-income-lipschitz for l ∈ r if 
 f p − f p ∞ 
dp p p 
≤ l 
for any p p ∈ ∆d this property reflects an assumption 
that preferences and demands have some sort of stability it 
rules out different demands for the similar prices we may 
therefore assume from here on that demand functions are 
single valued 
 revealed preference 
a sequence of prices and demands p x pn xn is 
rationalizable if there exists a utility function u such that 
xi fu pi for i n we begin with a trivial 
observation if pi · xj ≤ pi · xi and xi f pi then xi is preferred 
over xj since the latter is in the budget set when the 
former was chosen it is therefore revealed that u xj ≤ u xi 
implying pj · xj ≤ pj · xi 
suppose there is a sequence pi xi pik xik such 
that pij · xij − xij ≤ for j k − and pik · xik − 
xi ≤ then the same reasoning shows that u xi 
u xi u xik implying pi · xi − xi pi · xi − 
xi pik− · xik− −xik we call the latter 
condition the afriat condition ac this argument shows that 
ac is necessary for rationalizability the surprising result in 
afriat s theorem is that this condition is also sufficient 
let a be an n × n matrix with entries aij pi · xj − xi 
 aij and aji are independent aii and let d a be the 
weighted digraph associated with a the matrix satisfies 
ac if every cycle with negative total weight includes at least 
one edge with positive weight 
theorem there exists y y yn ∈ rn 
and s 
 s sn ∈ rn 
 satisfying the set of inequalities l a 
yj ≤ yi siaij i j ≤ i j ≤ n 
iff d a satisfies ac 
proof if l a is feasible then it is easy to see that 
u x min 
i 
 yi sipi x − xi 
is a concave utility function that is consistent with the 
observations and from our previous remark it follows that d a 
satisfies ac 
in the other direction it is shown by explicit 
construction that afriat s condition for d a implies l a is 
feasible the construction provides a utility function that is 
consistent with the observations teo and vohra give 
a strongly polynomial time algorithm for this construction 
which will be the heart of our learning algorithm 
the construction is executed in two steps first the 
algorithm finds s ∈ rn 
 such that the weighted digraph d a s 
defined by the matrix ˜aij siaij has no cycle with 
negative total weight if d a satisfies ac and returns a negative 
cycle otherwise 
the dual of a shortest path problem is given by the 
constraints 
yj − yi ≤ siaij i j 
it is a standard result see p that the system is 
feasible iff d a s has no negative cycles thus in the second 
step if d a satisfies ac the algorithm calls a 
shortest path algorithm to find y ∈ rn 
satisfying the 
constraints 
now we describe how to choose the si s define s 
 i j aij e i j aij and t i j 
aij and let g n s ∪ e be a digraph with weights 
wij − if i j ∈ s and wij otherwise d a has no 
negative cycles hence g is acyclic and breadth first search 
can assign potentials φi such that φj ≤ φi wij for i j ∈ 
s ∪ e we relabel the vertices so that φ ≥ φ ≥ ≥ φn 
let 
δi n − 
max i j ∈s −aij 
min i j ∈t aij 
if φi φi− and δi otherwise and define 
si 
iy 
j 
δj δi · si− 
 
we show that for this choice of s d a s contains no 
negative weight cycle suppose c i ik is a cycle 
in d a s if φ is constant on c then aij ij for j 
 k and we are done otherwise let iv ∈ c be the vertex 
with smallest potential satisfying w l o g φ iv φ iv 
for any cycle c in the digraph d a s let v u be an 
edge in c such that i v has the smallest potential among 
all vertices in c and ii φu φv such an edge exists 
otherwise φi is identical for all vertices i in c in this case 
all edges in c have non-negative edge weight in d a s 
if iv iv ∈ s ∪ e then we have 
φ iv ≤ φ iv wiv iv ≤ φ iv 
a contradiction hence iv iv ∈ t now note that all 
vertices q in c with the same potential as iv must be incident 
to an edge q t in c such that φ t ≥ φ q hence the edge 
 q t must have non-negative weight i e aq t ≥ let 
p denote a vertex in c with the second smallest potential 
now c has weight 
svavu 
x 
 k l ∈c\ v u 
skak l ≥ svav u sp n− max 
 i j ∈s 
 aij ≥ 
i e c has non-negative weight ✷ 
algorithm returns in polynomial time a hypothesis that 
is a piecewise linear function and agrees with the labeling 
of the observation namely sample error zero to use this 
function to forecast demand for unobserved prices we need 
algorithm which maximizes the function on a given budget 
set since u x mini yi sipi x − xi this is a linear 
program and can be solved in time polynomial in d n as 
well as the size of the largest number in the input 
 
algorithm utility algorithm 
input x p xn pn 
s ← i j aij 
e ← i j aij 
for all i j ∈ s do 
wij ← − 
end for 
for all i j ∈ e do 
wij ← 
end for 
while there exist unvisited vertices do 
visit new vertex j 
assign potential to φj 
end while 
reorder indices so φ ≤ φ ≤ φn 
for all ≤ i ≤ n do 
δi ← n − 
max i j ∈s −aij 
min i j ∈t aij 
si ← 
qi 
j δj 
end for 
shortest path yj − yi ≤ siaij 
return y yn ∈ rd 
and s sn ∈ r 
algorithm evaluation 
input y yn ∈ rd 
and s sn ∈ r 
max z 
z ≤ yi sipi x − xi for i n 
px ≤ 
return x for which z is maximized 
 supervised learning 
in a supervised learning problem a learning algorithm is 
given a finite sample of labeled observations as input and 
is required to return a model of the functional relationship 
underlying the labeling this model referred to as a 
hypothesis is usually a computable function that is used to 
forecast the labels of future observations the labels are 
usually binary values indicating the membership of the 
observed points in the set that is being learned however we 
are not limited to binary values and indeed in the demand 
functions we are studying the labels are real vectors 
the learning problem has three major components 
estimation approximation and complexity the estimation 
problem is concerned with the tradeoff between the size of 
the sample given to the algorithm and the degree of 
confidence we have in the forecast it produces the 
approximation problem is concerned with the ability of hypotheses 
from a certain class to approximate target functions from 
a possibly different class the complexity problem is 
concerned with the computational complexity of finding a 
hypothesis that approximates the target function 
a parametric paradigm assumes that the underlying 
functional relationship comes from a well defined family such as 
the cobb-douglas production functions the system must 
learn the parameters characterizing this family suppose 
that a learning algorithm observes a finite set of production 
data which it assumes comes from a cobb-douglas 
production function and returns a hypothesis that is a polynomial 
of bounded degree the estimation problem in this case 
would be to assess the sample size needed to obtain a good 
estimate of the coefficients the approximation problem 
would be to assess the error sustained from approximating a 
rational function by a polynomial the complexity problem 
would be the assessment of the time required to compute 
the polynomial coefficients 
in the probably approximately correct pac paradigm 
the learning of a target function is done by a class of 
hypothesis functions that does or does not include the 
target function itself it does not necessitate any parametric 
assumptions on this class it is also assumed that the 
observations are generated independently by some distribution 
on the domain of the relation and that this distribution is 
fixed if the class of target functions has finite 
 dimensionality then a function in the class is characterized by its values 
on a finite number of points the basic idea is to observe 
the labeling of a finite number of points and find a 
function from a class of hypotheses which tends to agree with 
this labeling the theory tells us that if the sample is large 
enough then any function that tends to agree with the 
labeling will with high probability be a good approximation 
of the target function for future observations the prime 
objective of pac theory is to develop the relevant notion 
of dimensionality and to formalize the tradeoff between 
dimensionality sample size and the level of confidence in the 
forecast 
in the revealed preference setting our objective is to use 
a set of observations of prices and demand to forecast 
demand for unobserved prices thus the target function is a 
mapping from prices to bundles namely f rd 
 → rd 
 the 
theory of pac learning for real valued functions is concerned 
predominantly with functions from rd 
to r in this section 
we introduce modifications to the classical notions of pac 
learning to vector valued functions and use them to prove 
a lower bound for sample complexity an upper bound on 
the sample complexity can also be proved for our definition 
of fat shattering but we do not bring it here as the proof is 
much more tedious and analogous to the proof of theorem 
before we can proceed with the formal definition we must 
clarify what we mean by forecast and tend to agree in the 
case of discrete learning we would like to obtain a 
function h that with high probability agrees with f we would 
then take the probability pσ f x h x as the measure 
of the quality of the estimation demand functions are real 
vector functions and we therefore do not expect f and h 
to agree with high probability rather we are content with 
having small mean square errors on all coordinates thus 
our measure of estimation error is given by 
erσ f h 
z 
 f − h ∞ 
dσ 
for given observations s p x pn xn we 
measure the agreement by the sample error 
ers s h 
x 
j 
 xj − h pj ∞ 
 
a sample error minimization sem algorithm is an 
algorithm that finds a hypothesis minimizing ers s h in the 
case of revealed preference there is a function that takes the 
sample error to zero nevertheless the upper bounds 
theorem we use does not require the sample error to be zero 
definition a set of demand functions c is probably 
approximately correct pac learnable by hypotheses set h 
if for any ε δ f ∈ c and distribution σ on the prices 
 
there exists an algorithm l that for a set of observations of 
length ml ml ε δ poly 
δ 
 
ε 
 finds a function h from 
h such that erσ f h ε with probability − δ 
there may be several learning algorithms for c with different 
sample complexities the minimal ml is called the sample 
complexity of c 
note that in the definition there is no mention of the time 
complexity to find h in h and evaluating h p a set c is 
efficiently pac-learnable if there is a poly 
δ 
 
ε 
 time 
algorithm for choosing h and evaluating h p 
for discrete function sets sample complexity bounds may 
be derived from the vc-dimension of the set see 
an analog to this notion of dimension for real functions is 
the fat shattering dimension we use an adaptation of this 
notion to real vector valued function sets let γ ⊂ rd 
 and 
let c be a set of real functions from γ to rd 
 
definition for γ a set of points p pn ∈ γ 
is γ-shattered by a class of real functions c if there exists 
x xn ∈ rd 
 and parallel affine hyperplanes h h ⊂ rd 
such that ∈ h− 
 ∩ h 
 dist h h γ and for each 
b b bn ∈ n 
there exists a function fb ∈ c such 
that fb pi ∈ xi h 
 if bi and f pi ∈ xi h− 
 if 
bi 
we define the γ-fat shattering dimension of c denoted fatc γ 
as the maximal size of a γ-shattered set in γ if this size is 
unbounded then the dimension is infinite 
to demonstrate the usefulness of the this notion we use it 
to derive a lower bound on the sample complexity 
lemma suppose the functions fb b ∈ n 
 
witness the shattering of p pn then for any x ∈ rd 
 
and labels b b ∈ n 
such that bi bi either fb pi − 
x ∞ γ 
 d 
or fb pi − x ∞ γ 
 d 
 
proof since the max exceeds the mean it follows that if 
fb and fb correspond to labels such that bi bi then 
 fb pi − fb pi ∞ ≥ 
 
d 
 fb pi − fb pi 
γ 
d 
 
this implies that for any x ∈ rd 
 either fb pi − x ∞ γ 
 d 
or fb pi − x ∞ γ 
 d ✷ 
theorem suppose that c is a class of functions 
mapping from γ to rd 
 then any learning algorithm l for c 
has sample complexity satisfying 
ml ε δ ≥ 
 
 
fatc dε 
an analog of this theorem for real valued functions with a 
tighter bound can be found in this version will suffice 
for our needs 
proof suppose n 
 
fatc dε then there exists a set 
γs p p n that is shattered by c it suffices to 
show that at least one distribution requires large sample 
we construct such a distribution let σ be the uniform 
distribution on γs and cs fb b ∈ n 
 be the set 
of functions that witness the shattering of p pn 
let fb be a function chosen uniformly at random from cs 
it follows from lemma with γ d that for any fixed 
function h the probability that fb p − h p ∞ ε for 
p ∈ γs is at least as high as getting heads on a fair coin 
toss therefore eb fb p − h p ∞ ε 
suppose for a sequence of observations z pi x 
 pin xn a learning algorithm l finds a function h the 
observation above and fubini imply eb erσ h fb ε 
randomizing on the sample space we get eb z erσ h fb ε 
this shows eh z erσ h fb ε for some fb w l g we 
may assume the error is bounded since we are looking at 
what is essentially a finite set therefore the probability that 
erσ h fb ε cannot be too small hence fb is not 
paclearnable with a sample of size n ✷ 
the following theorem gives an upper bound on the 
sample complexity required for learning a set of functions with 
finite fat shattering dimension the theorem is proved in 
for real valued functions the proof for the real vector case 
is analogous and so omitted 
theorem let c be a set of real-valued functions from 
x to with fatc γ ∞ let a be approximate-sem 
algorithm for c and define l z a z ε 
 
 for z ∈ zm 
and 
ε √ 
m 
 then l is a learning algorithm for c with sample 
complexity given by 
ml ε δ o 
„ 
 
ε 
 ln 
 
 
ε 
 fatc ε ln 
 
δ 
 
 
for any ε δ 
 learning from revealed 
preference 
algorithm is an efficient learning algorithm in the sense 
that it finds a hypothesis with sample error zero in time 
polynomial in the number of observations as we have seen 
in section the number of observations required to pac 
learn the demand depends on the fat shattering dimension of 
the class of demand functions which in turn depends on the 
class of utility functions they are derived from we compute 
the fat shattering dimension for two classes of demands the 
first is the class of all demand functions we show that this 
class has infinite shattering dimension we give two proofs 
and is therefore not pac learnable the second class we 
consider is the class of demand functions derived from utilities 
with bounded support and income-lipschitz we show that 
the class has a finite fat shattering dimension that depends 
on the support and the income-lipschitz constant 
theorem let c be a set of demand functions from rd 
 
to rd 
 then 
fatc γ ∞ 
proof for ε let pi −i 
p for i n be 
a set of price vectors inducing parallel budget sets bi and 
let x xn be the intersection of these hyperplanes with 
an orthogonal line passing through the center let h and 
h be hyperplanes that are not parallel to p and let xi ∈ 
bi ∩ xi h 
 and xi ∈ bi ∩ xi h− 
 for i n see 
figure 
for any labeling b b bn ∈ n 
let y y b 
 y yn be a set of demands such that yi xi if bi 
and yi xi if bi we omit an additional index b in 
y for notational convenience to show that p pn is 
shattered it suffices to find for every b a demand function 
fb supported by concave utility such that fb pi yb 
i to 
show that such a function exists it suffices to show that 
afriat s conditions are satisfied since yi are in the budget 
 
set yi · −i 
p therefore pi · yj − yi j−i 
− this 
shows that pi · yj − yi ≤ iff j i hence there can be no 
negative cycles and the condition is met ✷ 
proof the utility functions satisfying afriat s condition 
in the first proof could be trivial assigning the same utility 
to xi as to xi in fact pick a utility function whose level 
sets are parallel to the budget constraint therefore the 
shattering of the prices p pn is the result of indifference 
rather than genuine preference to avoid this problem we 
reprove the theorem by constructing utility functions u such 
that u xi u xi for all i and therefore a distinct utility 
function is associated with each labeling 
for i n let pi pid be price vectors satisfying 
the following conditions 
 the budget sets bs 
i are supporting hyperplanes of a 
convex polytope λi 
 yi is a vertex of λi 
 yj · pis − pi ∞ o for s d and j 
 n 
finally let yi yid be points on the facets of λi that 
intersect yi such that pjr · yi − yis ∞ o for all j 
s and r we call the set of points yi yi yid the level i 
demand and pi pi pid level i prices applying h¨olders 
inequality we get 
 pir · yjs − pi · yj ≤ pir − pi · yj pir · yjs − yj 
 pir − pi ∞ · yj yjs − yj ∞ · pir 
 o 
this shows that 
pir · yjs − yir pi · ys − yi o j−i 
− o 
therefore pir · yjs − yir ≤ iff j i or i j this implies 
that if there is a negative cycle then all the points in the 
cycle must belong to the same level the points of any one 
level lie on the facets of a polytope λi and the prices pis are 
supporting hyperplanes of the polytope thus the polytope 
defines a utility function for which these demands are utility 
maximizing the other direction of afriat s theorem 
therefore implies there can be no negative cycles within points on 
the same level 
it follows that there are no negative cycles for the union 
of observations from all levels hence the sequence of 
observations y p y p y p ynd pnd is 
consistent with monotone concave utility function maximization 
and again by afriat s theorem there exists u supporting a 
demand function fb ✷ 
the proof above relies on the fact that an agent have high 
utility and marginal utility for very large bundles in many 
cases it is reasonable to assume that the marginal for very 
large bundles is very small or even that the utility or the 
marginal utility have compact support unfortunately 
rescaling the previous example shows that even a compact set 
may contain a large shattered set we notice however that 
in this case we obtain a utility function that yield demand 
functions that are very sensitive to small price changes we 
show that the class of utility functions that have marginal 
utilities with compact support and for which the relevant 
demand functions are income-lipschitzian has finite fat 
shattering dimension 
✲ 
✻ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
❅ 
 
 
 
 
 
 
 
 
h 
 
 
 
 
 
 
 
h r 
x 
r x 
❈ 
❈ 
❜ 
❜❜ 
r x 
r 
x 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❚ 
❜ 
❜❜ 
figure utility function shattering x and x 
theorem let c be a set of l-income-lipschitz 
demand functions from ∆d to rd 
 for some global constant 
l ∈ r then 
fatc γ ≤ 
l 
γ 
 d 
proof let p pn ∈ ∆d be a shattered set with 
witnesses x xn ∈ rd 
 w l g xi h 
 ∩xj h− 
 ∅ 
implying xi h− 
 ∩ xj h 
 ∅ for a labeling b b bn ∈ 
 n 
such that bi and bj fb pi − fb pj ∞ γ 
hence pi − pj ∞ γ 
l 
 a standard packing argument 
implies n ≤ l 
γ 
 d 
✷ 
 acknowledgments 
the authors would like to thank eli shamir ehud kalai 
julio gonz´alez d´ıaz rosa matzkin gad allon and adam 
galambos for helpful discussions and suggestions 
 references 
 afriat s n the construction of a utility 
function from expenditure data international 
economic review - 
 anthony m and bartlett p l neural network 
learning theoretical foundations cambridge 
university press 
 blundell r browning m and crawford i 
nonparametric engel curves and revealed preference 
econometrica - 
 blundell r how revealing is revealed 
preference european economic journal - 
 diewert e afriat and revealed preference 
theory review of economic studies - 
 farkas j ¨uber die theorie der einfachen 
ungleichungen journal f¨ur die reine und angewandte 
mathematik - 
 houthakker h revealed preference and the 
utility function economica - 
 kearns m and vazirani u an introduction to 
computational learning theory the mit press 
cambridge ma 
 
 knoblauch v a tight upper bound on the 
money metric utility function the american 
economic review - 
 mas-colell a the recoverability of 
consumers preferences from market demand 
econometrica - 
 mas-colell a on revealed preference 
analysis the review of economic studies 
 - 
 mas-colell a whinston m and green j r 
microeconomic theory oxford university press 
 matzkin r and richter m testing strictly 
concave rationality journal of economic theory 
 - 
 papadimitriou c h and steiglitz k 
combinatorial optimization dover publications inc 
 richter m revealed preference theory 
econometrica - 
 uzawa h preference and rational choice in 
the theory of consumption in k j arrow s karlin 
and p suppes editors mathematical models in social 
science stanford university press stanford ca 
 teo c p and vohra r v afriat s theorem 
and negative cycles working paper 
 samuelson p a consumption theory in terms 
of revealed preference economica - 
 vapnik v n statistical learning theory john 
wiley sons inc 
 varian h r the non-parametric approach to 
demand analysis econometrica - 
 varian h r revealed preference in michael 
szenberg editor samuelson economics and the st 
century 
 ziegler g m lectures on polytopes springer 
 
