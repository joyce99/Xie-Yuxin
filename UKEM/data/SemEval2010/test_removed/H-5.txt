utility-based information distillation over 
temporally sequenced documents 
yiming yang 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
yiming cs cmu edu 
abhimanyu lad 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
alad cs cmu edu 
ni lao 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
nlao cs cmu edu 
abhay harpale 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
aharpale cs cmu edu 
bryan kisiel 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
bkisiel cs cmu edu 
monica rogati 
language technologies inst 
carnegie mellon university 
pittsburgh usa 
mrogati cs cmu edu 
abstract 
this paper examines a new approach to information 
distillation over temporally ordered documents and proposes a 
novel evaluation scheme for such a framework it combines 
the strengths of and extends beyond conventional adaptive 
filtering novelty detection and non-redundant passage 
ranking with respect to long-lasting information needs 
  tasks with multiple queries our approach supports 
fine-grained user feedback via highlighting of arbitrary 
spans of text and leverages such information for utility 
optimization in adaptive settings for our experiments 
we defined hypothetical tasks based on news events in the 
tdt corpus with multiple queries per task answer 
keys nuggets were generated for each query and a 
semiautomatic procedure was used for acquiring rules that allow 
automatically matching nuggets against system responses 
we also propose an extension of the ndcg metric for 
assessing the utility of ranked passages as a combination of 
relevance and novelty our results show encouraging utility 
enhancements using the new approach compared to the 
baseline systems without incremental learning or the novelty 
detection components 
categories and subject descriptors 
h information search and retrieval information 
filtering relevance feedback retrieval models selection 
process i 
general terms 
design measurement performance experimentation 
 introduction 
tracking new and relevant information from temporal 
data streams for users with long-lasting needs has been a 
challenging research topic in information retrieval adaptive 
filtering af is one such task of online prediction of the 
relevance of each new document with respect to pre-defined 
topics based on the initial query and a few positive 
examples if available an af system maintains a profile for 
each such topic of interest and constantly updates it based 
on feedback from the user the incremental learning nature 
of af systems makes them more powerful than standard 
search engines that support ad-hoc retrieval e g google 
and yahoo in terms of finding relevant information with 
respect to long-lasting topics of interest and more attractive 
for users who are willing to provide feedback to adapt the 
system towards their specific information needs without 
having to modify their queries manually 
a variety of supervised learning algorithms rocchio-style 
classifiers exponential-gaussian models local regression 
and logistic regression approaches have been studied for 
adaptive settings examined with explicit and implicit 
relevance feedback and evaluated with respect to utility 
optimization on large benchmark data collections in trec 
 text retrieval conferences and tdt topic detection and 
tracking forums regularized 
logistic regression has been found representative for 
the state-of-the-art approaches and highly efficient for 
frequent model adaptations over large document collections 
such as the trec- corpus over documents and 
 topics despite substantial achievements in recent 
adaptive filtering research significant problems remain 
unsolved regarding how to leverage user feedback effectively 
and efficiently specifically the following issues may 
seriously limit the true utility of af systems in real-world 
applications 
 user has a rather  passive role in the conventional 
adaptive filtering setup - he or she reacts to the system 
only when the system makes a  yes decision on a 
document by confirming or rejecting that decision a 
more  active alternative would be to allow the user to 
issue multiple queries for a topic review a ranked list 
of candidate documents or passages per query and 
provide feedback on the ranked list thus refining their 
information need and requesting updated ranked lists 
the latter form of user interaction has been highly 
effective in standard retrieval for ad-hoc queries how 
to deploy such a strategy for long-lasting information 
needs in af settings is an open question for research 
 the unit for receiving a relevance judgment  yes or 
 no is restricted to the document level in conventional 
af however a real user may be willing to provide 
more informative fine-grained feedback via 
highlighting some pieces of text in a retrieved document 
as relevant instead of labeling the entire document 
as relevant effectively leveraging such fine-grained 
feedback could substantially enhance the quality of an 
af system for this we need to enable supervised 
learning from labeled pieces of text of arbitrary span 
instead of just allowing labeled documents 
 system-selected documents are often highly 
redundant a major news event for example would be 
reported by multiple sources repeatedly for a while 
making most of the information content in those 
articles redundant with each other a conventional af 
system would select all these redundant news stories 
for user feedback wasting the user s time while offering 
little gain clearly techniques for novelty detection 
can help in principle for improving the 
utility of the af systems however the effectiveness of 
such techniques at passage level to detect novelty with 
respect to user s fine-grained feedback and to detect 
redundancy in ranked lists remains to be evaluated 
using a measure of utility that mimics the needs of a 
real user 
to address the above limitations of current af systems 
we propose and examine a new approach in this paper 
combining the strengths of conventional af incremental 
learning of topic models multi-pass passage retrieval 
for long-lasting queries conditioned on topic and novelty 
detection for removal of redundancy from user interactions 
with the system we call the new process utility-based 
information distillation 
note that conventional benchmark corpora for af 
evaluations which have relevance judgments at the document level 
and do not define tasks with multiple queries are insufficient 
for evaluating the new approach therefore we extended a 
benchmark corpus - the tdt collection of news stories and 
tv broadcasts - with task definitions multiple queries per 
task and answer keys per query we have conducted our 
experiments on this extended tdt corpus and have made 
the additionally generated data publicly available for future 
comparative evaluations 
 
to automatically evaluate the system-returned arbitrary 
spans of text using our answer keys we further developed 
an evaluation scheme with semi-automatic procedure for 
 
url http nyc lti cs cmu edu downloads 
acquiring rules that can match nuggets against system 
responses moreover we propose an extension of ndcg 
 normalized discounted cumulated gain for assessing 
the utility of ranked passages as a function of both relevance 
and novelty 
the rest of this paper is organized as follows section 
 outlines the information distillation process with a 
concrete example section describes the technical cores 
of our system called cafÂ´e - cmu adaptive filtering 
engine section discusses issues with respect to evaluation 
methodology and proposes a new scheme section 
describes the extended tdt corpus section presents 
our experiments and results section concludes the study 
and gives future perspectives 
 a sample task 
consider a news event - the escape of seven convicts 
from a texas prison in december and their capture a 
month later assuming a user were interested in this event 
since its early stage the information need could be  find 
information about the escape of convicts from texas prison 
and information related to their recapture the associated 
lower-level questions could be 
 how many prisoners escaped 
 where and when were they sighted 
 who are their known contacts inside and outside the 
prison 
 how are they armed 
 do they have any vehicles 
 what steps have been taken so far 
we call such an information need a task and the 
associated questions as the queries in this task a 
distillation system is supposed to monitor the incoming 
documents process them chunk by chunk in a temporal 
order select potentially relevant and novel passages from 
each chunk with respect to each query and present a ranked 
list of passages to the user passage ranking here is based on 
how relevant a passage is with respect to the current query 
how novel it is with respect to the current user history of 
his or her interactions with the system and how redundant 
it is compared to other passages with a higher rank in the 
list 
when presented with a list of passages the user may 
provide feedback by highlighting arbitrary spans of text 
that he or she found relevant these spans of text are 
taken as positive examples in the adaptation of the query 
profile and also added to the user s history passages not 
marked by the user are taken as negative examples as 
soon as the query profile is updated the system re-issues 
a search and returns another ranked list of passages where 
the previously seen passages are either removed or ranked 
low based on user preference for example if the user 
highlights   officials have posted a reward for 
their capture as relevant answer to the query what 
steps have been taken so far then the highlighted piece 
is used as an additional positive training example in the 
adaptation of the query profile this piece of feedback is 
also added to the user history as a seen example so that in 
future the system will not place another passage mentioning 
  reward at the top of the ranked list however 
an article mentioning   officials have doubled the reward 
money to might be ranked high since it is 
both relevant to the updated query profile and novel with 
respect to the updated user history the user may modify 
the original queries or add a new query during the process 
the query profiles will be changed accordingly clearly 
novelty detection is very important for the utility of such 
a system because of the iterative search without novelty 
detection the old relevant passages would be shown to the 
user repeatedly in each ranked list 
through the above example we can see the main 
properties of our new framework for utility-based 
information distillation over temporally ordered documents our 
framework combines and extends the power of adaptive 
filtering af ad-hoc retrieval ir and novelty detection 
 nd compared to standard ir our approach has the 
power of incrementally learning long-term information needs 
and modeling a sequence of queries within a task compared 
to conventional af it enables a more active role of the 
user in refining his or her information needs and requesting 
new results by allowing relevance and novelty feedback via 
highlighting of arbitrary spans of text in passages returned 
by the system 
compared to past work this is the first evaluation 
of novelty detection integrated with adaptive filtering for 
sequenced queries that allows flexible user feedback over 
ranked passages the combination of af ir and nd with 
the new extensions raises an important research question 
regarding evaluation methodology how can we measure the 
utility of such an information distillation system existing 
metrics in standard ir af and nd are insufficient and new 
solutions must be explored as we will discuss in section 
after describing the technical cores of our system in the next 
section 
 technical cores 
the core components of cafÂ´e are - af for incremental 
learning of query profiles ir for estimating relevance of 
passages with respect to query profiles nd for assessing 
novelty of passages with respect to user s history and 
anti-redundancy component to remove redundancy from 
ranked lists 
 adaptive filtering component 
we use a state-of-the-art algorithm in the field - the 
regularized logistic regression method which had the best 
results on several benchmark evaluation corpora for af 
logistic regression lr is a supervised learning algorithm 
for statistical classification based on a training set of 
labeled instances it learns a class model which can then 
by used to predict the labels of unseen instances its 
performance as well as efficiency in terms of training time 
makes it a good candidate when frequent updates of the class 
model are required as is the case in adaptive filtering where 
the system must learn from each new feedback provided by 
the user see and for computational complexity 
and implementation issues 
in adaptive filtering each query is considered as a class 
and the probability of a passage belonging to this class 
corresponds to the degree of relevance of the passage with 
respect to the query for training the model we use the 
query itself as the initial positive training example of the 
class and the user-highlighted pieces of text marked as 
relevant or not-relevant during feedback as additional 
training examples to address the cold start issue in the 
early stage before any user feedback is obtained the system 
uses a small sample from a retrospective corpus as the initial 
negative examples in the training set the details of using 
logistic regression for adaptive filtering assigning different 
weights to positive and negative training instances and 
regularizing the objective function to prevent over-fitting on 
training data are presented in 
the class model w 
learned by logistic regression or the 
query profile is a vector whose dimensions are individual 
terms and whose elements are the regression coefficients 
indicating how influential each term is in the query profile 
the query profile is updated whenever a new piece of user 
feedback is received a temporally decaying weight can be 
applied to each training example as an option to emphasize 
the most recent user feedback 
 passage retrieval component 
we use standard ir techniques in this part of our system 
incoming documents are processed in chunks where each 
chunk can be defined as a fixed span of time or as a fixed 
number of documents as preferred by the user for each 
incoming document corpus statistics like the idf inverted 
document frequency of each term are updated we use a 
state-of-the-art named entity identifier and tracker 
to identify person and location names and merge them 
with co-referent named entities seen in the past then 
the documents are segmented into passages which can be 
a whole document a paragraph a sentence or any other 
continuous span of text as preferred each passage is 
represented using a vector of tf-idf term 
frequencyinverse document frequency weights where term can be a 
word or a named entity 
given a query profile i e the logistic regression solution 
w 
as described in section the system computes the 
posterior probability of relevance for each passage x as 
frl x â¡ p y x w 
 
 
 eâw Â·x 
 
passages are ordered by their relevance scores and the 
ones with scores above a threshold tuned on a training set 
comprise the relevance list that is passed on to the novelty 
detection step 
 novelty detection component 
cafÂ´e maintains a user history h t which contains all 
the spans of text hi that the user highlighted as feedback 
during his or her past interactions with the system up to 
the current time t denoting the history as 
h t 
n 
h h ht 
o 
 
the novelty score of a new candidate passage x is computed 
as 
fnd x â max 
iâ t 
 cos x hi 
where both candidate passage x and highlighted spans of 
text hi are represented as tf-idf vectors 
the novelty score of each passage is compared to a 
prespecified threshold also tuned on a training set and any 
passage with a score below this threshold is removed from 
the relevance list 
 anti-redundant ranking component 
although the novelty detection component ensures that 
only novel previously unseen information remains in 
the relevance list this list might still contain the same 
novel information at multiple positions in the ranked list 
suppose for example that the user has already read about a 
 reward for information about the escaped convicts 
a new piece of news that the award has been increased to 
 is novel since the user hasn t read about it yet 
however multiple news sources would report this news and 
we might end up showing redundant articles from all these 
sources in a ranked list hence a ranked list should also be 
made non-redundant with respect to its own contents we 
use a simplified version of the maximal marginal relevance 
method originally developed for combining relevance and 
novelty in text retrieval and summarization our procedure 
starts with the current list of passages sorted by relevance 
 section filtered by novelty detection component 
 section and generates a new non-redundant list as 
follows 
 take the top passage in the current list as the top one 
in the new list 
 add the next passage x in the current list to the new 
list only if 
far x t 
where 
far x â max 
piâlnew 
 cos x pi 
and lnew is the set of passages already selected in the 
new list 
 repeat step until all the passages in the current list 
have been examined 
after applying the above-mentioned algorithm each passage 
in the new list is sufficiently dissimilar to others thus 
favoring diversity rather than redundancy in the new ranked 
list the anti-redundancy threshold t is tuned on a training 
set 
 evaluation methodology 
the approach we proposed above for information 
distillation raises important issues regarding evaluation 
methodology firstly since our framework allows the output to be 
passages at different levels of granularity e g k-sentence 
windows where k may vary instead of a fixed length it 
is not possible to have pre-annotated relevance judgments 
at all such granularity levels secondly since we wish to 
measure the utility of the system output as a combination of 
both relevance and novelty traditional relevance-only based 
measures must be replaced by measures that penalize the 
repetition of the same information in the system output 
across time thirdly since the output of the system is 
ranked lists we must reward those systems that present 
useful information both relevant and previously unseen 
using shorter ranked lists and penalize those that present 
the same information using longer ranked lists none of 
the existing measures in ad-hoc retrieval adaptive filtering 
novelty detection or other related areas text summarization 
and question answering have desirable properties in all the 
three aspects therefore we must develop a new evaluation 
methodology 
 answer keys 
to enable the evaluation of a system whose output 
consists of passages of arbitrary length we borrow the 
concept of answer keys from the question answering qa 
community where systems are allowed to return arbitrary 
spans of text as answers answer keys define what should 
be present in a system response to receive credit and 
are comprised of a collection of information nuggets i e 
factoid units about which human assessors can make binary 
decisions of whether or not a system response contains them 
defining answer keys and making the associated binary 
decisions are conceptual tasks that require semantic 
mapping since system-returned passages can contain the 
same information expressed in many different ways hence 
qa evaluations have relied on human assessors for the 
mapping between various expressions making the process 
costly time consuming and not scalable to large query and 
document collections and extensive system evaluations with 
various parameter settings 
 automating evaluation based on answer keys 
automatic evaluation methods would allow for faster 
system building and tuning as well as provide an objective 
and affordable way of comparing various systems recently 
such methods have been proposed more or less based on 
the idea of n-gram co-occurrences pourpre assigns a 
fractional recall score to a system response based on its 
unigram overlap with a given nugget s description for 
example a system response  a b c has recall with 
respect to a nugget with description  a b c d however 
such an approach is unfair to systems that present the same 
information but using words other than a b c and d 
another open issue is how to weight individual words in 
measuring the closeness of a match for example consider 
the question how many prisoners escaped in the nugget 
 seven prisoners escaped from a texas prison there is no 
indication that  seven is the keyword and that it must 
be matched to get any relevance credit using idf values 
does not help since  seven will generally not have a higher 
idf than words like  texas and  prison also redefining 
the nugget as just  seven does not solve the problem since 
now it might spuriously match any mention of  seven out 
of context nuggeteer works on similar principles but 
makes binary decisions about whether a nugget is present in 
a given system response by tuning a threshold however 
it is also plagued by  spurious relevance since not all 
words contained in the nugget description or known correct 
responses are central to the nugget 
 nugget-matching rules 
we propose a reliable automatic method for determining 
whether a snippet of text contains a given nugget based on 
nugget-matching rules which are generated using a 
semiautomatic procedure explained below these rules are 
essentially boolean queries that will only match against 
snippets that contain the nugget for instance a candidate 
rule for matching answers to how many prisoners 
escaped is texas and seven and escape and convicts 
or prisoners possibly with other synonyms and variants 
in the rule for a corpus of news articles which usually 
follow a typical formal prose it is fairly easy to write such 
simple rules to match expected answers using a bootstrap 
approach as described below 
we propose a two-stage approach inspired by autoslog 
 that combines the strength of humans in identifying 
semantically equivalent expressions and the strength of the 
system in gathering statistical evidence from a 
humanannotated corpus of documents in the first stage human 
subjects annotated using a highlighting tool portions of 
ontopic documents that contained answers to each nugget 
 
in the second stage subjects used our rule generation tool 
to create rules that would match the annotations for each 
nugget the tool allows users to enter a boolean rule as a 
disjunction of conjunctions e g a and b or a and c 
and d or e given a candidate rule our tool uses it as 
a boolean query over the entire set of on-topic documents 
and calculates its recall and precision with respect to the 
annotations that it is expected to match hence the 
subjects can start with a simple rule and iteratively refine 
it until they are satisfied with its recall and precision we 
observed that it was very easy for humans to improve the 
precision of a rule by tweaking its existing conjunctions 
 adding more ands and improving the recall by adding 
more conjunctions to the disjunction adding more ors 
as an example let s try to create a rule for the nugget 
which says that seven prisoners escaped from the texas 
prison we start with a simple rule - seven when 
we input this into the rule generation tool we realize that 
this rule matches many spurious occurrences of seven e g 
  seven states and thus gets a low precision score 
we can further qualify our rule - texas and seven and 
convicts next by looking at the  missed annotations we 
realize that some news articles mentioned seven prisoners 
escaped we then replace convicts with the disjunction 
 convicts or prisoners we continue tweaking the rule 
in this manner until we achieve a sufficiently high recall and 
precision - i e the small number of misses and false alarms 
can be safely ignored 
thus we can create nugget-matching rules that succinctly 
capture various ways of expressing a nugget while avoiding 
matching incorrect or out of context responses human 
involvement in the rule creation process ensures high quality 
generic rules which can then be used to evaluate arbitrary 
system responses reliably 
 evaluating the utility of a sequence of 
ranked lists 
the utility of a retrieval system can be defined as the 
difference between how much the user gained in terms of 
useful information and how much the user lost in terms 
of time and energy we calculate this utility from the 
utilities of individual passages as follows after reading each 
passage returned by the system the user derives some gain 
depending on the presence of relevant and novel information 
and incurs a loss in terms of the time and energy spent in 
going through the passage however the likelihood that the 
user would actually read a passage depends on its position 
in the ranked list hence for a query q the expected utility 
 
ldc already provides relevance judgments for 
topics on the tdt corpus we further ensured that these 
judgments are exhaustive on the entire corpus using pooling 
of a passage pi at rank i can be defined as 
u pi q p i gain pi q â loss pi q 
where p i is the probability that the user would go through 
a passage at rank i 
the expected utility for an entire ranked list of length n 
can be calculated simply by adding the expected utility of 
each passage 
u q 
nx 
i 
p i gain pi q â loss pi q 
note that if we ignore the loss term and define p i as 
p i â logb b i â 
then we get the recently popularized metric called 
discounted cumulated gain dcg where gain pi q is 
defined as the graded relevance of passage pi however 
without the loss term dcg is a purely recall-oriented metric 
and not suitable for an adaptive filtering setting where the 
system s utility depends in part on its ability to limit the 
number of items shown to the user 
although p i could be defined based on empirical studies 
of user behavior for simplicity we use p i exactly as 
defined in equation 
the gain g pi q of passage pi with respect to the query q 
is a function of - the number of relevant nuggets present in 
pi and the novelty of each of these nuggets we combine 
these two factors as follows for each nugget nj we assign 
an initial weight wj and also keep a count nj of the number 
of times this nugget has been seen by the user in the past 
the gain derived from each subsequent occurrence of the 
same nugget is assumed to reduce by a dampening factor Î³ 
thus g pi q is defined as 
g pi q 
x 
nj âc pi q 
wj Î³nj 
 
where c pi q is the set of all nuggets that appear in passage 
pi and also belong to the answer key of query q the 
initial weights wj are all set of be in our experiments 
but can also be set based on a pyramid approach 
the choice of dampening factor Î³ determines the user s 
tolerance for redundancy when Î³ a nugget will 
only receive credit for its first occurrence i e when nj is 
zero 
 for Î³ a nugget receives smaller credit 
for each successive occurrence when Î³ no dampening 
occurs and repeated occurrences of a nugget receive the same 
credit note that the nugget occurrence counts are preserved 
between evaluation of successive ranked lists returned by the 
system since the users are expected to remember what the 
system showed them in the past 
we define the loss l pi q as a constant cost c we use 
incurred when reading a system-returned passage thus our 
metric can be re-written as 
u q 
nx 
i 
gain pi q 
logb b i â 
â l n 
where l n is the loss associated with a ranked list of length 
n 
l n c Â· 
nx 
i 
 
logb b i â 
 
 
note that 
 
due to the similarity with discounted cumulated gain 
 dcg we call our metric discounted cumulated utility 
 dcu the dcu score obtained by the system is converted 
to a normalized dcu ndcu score by dividing it by the 
dcu score of the ideal ranked list which is created by 
ordering passages by their decreasing utility scores u pi q 
and stopping when u pi q â¤ i e when the gain is less 
than or equal to the cost of reading the passage 
 data 
tdt was the benchmark corpus used in tdt and 
tdt evaluations the corpus consists of over 
news articles from multiple sources ap nyt cnn abc 
nbc msnbc xinhua zaobao voice of america pri the 
world etc published between october and january 
 in the languages of arabic english and mandarin 
speech-recognized and machine-translated versions of the 
non-english articles were provided as well 
ldc has annotated the corpus with topics that 
correspond to various news events in this time period out 
of these we selected a subset of actionable events and 
defined corresponding tasks for them 
 for each task we 
manually defined a profile consisting of an initial set of 
to queries a free-text description of the user history 
i e what the user already knows about the event and a list 
of known on-topic and off-topic documents if available as 
training examples 
for each query we generated answer keys and 
corresponding nugget matching rules using the procedure described in 
section and produced a total of queries with an 
average of nuggets per query 
 experiments and results 
 baselines 
we used indri a popular language-model based 
retrieval engine as a baseline for comparison with cafÂ´e 
indri supports standard search engine functionality 
including pseudo-relevance feedback prf and is 
representative of a typical query-based retrieval system 
indri does not support any kind of novelty detection 
we compare indri with prf turned on and off against 
cafÂ´e with user feedback novelty detection and 
antiredundant ranking turned on and off 
 experimental setup 
we divided the tdt corpus spanning months into 
chunks each defined as a period of consecutive days 
at any given point of time in the distillation process each 
system accessed the past data up to the current point and 
returned a ranked list of up passages per query 
the tasks defined on the corpus were divided into 
a training and test set with tasks each each system 
was allowed to use the training set to tune its parameters 
for optimizing ndcu equation including the relevance 
threshold for both indri and cafÂ´e and the novelty and 
antiredundancy thresholds for cafÂ´e 
the ndcu for each system run is calculated 
automatically user feedback was also simulated - relevance 
judgments for each system-returned passage as determined 
by the nugget matching rules described in section were 
 
url http nyc lti cs cmu edu downloads 
figure performance of indri across chunks 
figure performance of cafÂ´e across chunks 
used as user feedback in the adaptation of query profiles and 
user histories 
 results 
in table we show the ndcu scores of the two systems 
under various settings these scores are averaged over 
the six tasks in the test set and are calculated with two 
dampening factors see section Î³ and to 
simulate no tolerance and small tolerance for redundancy 
respectively 
using Î³ creates a much more strict metric since it does 
not give any credit to a passage that contains relevant but 
redundant information hence the improvement obtained 
from enabling user feedback is smaller with Î³ than the 
improvement obtained from feedback with Î³ this 
reveals a shortcoming of contemporary retrieval 
systemswhen the user gives positive feedback on a passage the 
systems gives higher weights to the terms present in that 
passage and tends to retrieve other passages containing the 
same terms - and thus - usually the same information 
however the user does not benefit from seeing such 
redundant passages and is usually interested in other 
passages containing related information it is informative 
to evaluate retrieval systems using our utility measure with 
Î³ which accounts for novelty and thus gives a more 
realistic picture of how well a system can generalize from 
user feedback rather than using traditional ir measures 
like recall and precision which give an incomplete picture of 
improvement obtained from user feedback 
sometimes however users might indeed be interested in 
seeing the same information from multiple sources as an 
table ndcu scores of indri and cafÂ´e for two dampening factors Î³ and various settings f feedback 
n novelty detection a anti-redundant ranking 
indri cafÂ´e 
Î³ base prf base f f n f a f n a 
 
 
indicator of its importance or reliability in such a case we 
can simply choose a higher value for Î³ which corresponds to 
a higher tolerance for redundancy and hence let the system 
tune its parameters accordingly 
since documents were processed chunk by chunk it 
would be interesting to see how the performance of systems 
improves over time figures and show the performance 
trends for both the systems across chunks while the 
performance with and without feedback on the first few 
chunks is expected to be close for subsequent chunks 
the performance curve with feedback enabled rises above 
the one with the no-feedback setting the performance 
trends are not consistent across all chunks because on-topic 
documents are not uniformly distributed over all the chunks 
making some queries  easier than others in certain chunks 
moreover since indri uses pseudo-relevance feedback while 
cafÂ´e uses feedback based on actual relevance judgments the 
improvement in case of indri is less dramatic than that of 
cafÂ´e 
 concluding remarks 
this paper presents the first investigation on utility-based 
information distillation with a system that learns the 
longlasting information needs from fine-grained user feedback 
over a sequence of ranked passages our system called cafÂ´e 
combines adaptive filtering novelty detection and 
antiredundant passage ranking in a unified framework for utility 
optimization we developed a new scheme for automated 
evaluation and feedback based on a semi-automatic 
procedure for acquiring rules that allow automatically matching 
nuggets against system responses we also proposed an 
extension of the ndcg metric for assessing the utility of 
ranked passages as a weighted combination of relevance and 
novelty our experiments on the newly annotated tdt 
benchmark corpus show encouraging utility enhancement 
over indri and also over our own system with incremental 
learning and novelty detection turned off 
 acknowledgments 
we would like to thank rosta farzan jonathan grady 
jaewook ahn yefei peng and the qualitative data 
analysis program at the university of pittsburgh lead 
by dr stuart shulman for their help with collecting 
and processing the extended tdt annotations used in 
our experiments this work is supported in parts by 
the national science foundation nsf under grant 
iis and the defense advanced research project 
agency darpa under contracts nbchd and 
w any opinions findings conclusions or 
recommendations expressed in this material are those of the 
authors and do not necessarily reflect the views of the 
sponsors 
 additional authors 
jian zhang jianzhan stat purdue edu 
 jaime 
carbonell jgc cs cmu edu â  
 peter brusilovsky 
 peterb  pitt edu â¡ 
 daqing he dah  pitt edu â¡ 
 references 
 j allan incremental relevance feedback for 
information filtering proceedings of the th annual 
international acm sigir conference on research and 
development in information retrieval pages - 
 
 j allan c wade and a bolivar retrieval and 
novelty detection at the sentence level proceedings 
of the acm sigir conference on research and 
development in information retrieval 
 c buckley g salton and j allan automatic 
retrieval with locality information using smart 
nist special publication - 
 j callan learning while filtering documents 
proceedings of the st annual international acm 
sigir conference on research and development in 
information retrieval pages - 
 j carbonell and j goldstein the use of mmr 
diversity-based reranking for reordering documents 
and producing summaries proceedings of the st 
annual international acm sigir conference on 
research and development in information retrieval 
pages - 
 e efthimiadis query expansion annual review of 
information science and technology arist 
 p - 
 j fiscus and g duddington topic detection and 
tracking overview topic detection and tracking 
event-based information organization pages - 
 r florian h hassan a ittycheriah h jing 
n kambhatla x luo n nicolov and s roukos a 
statistical model for multilingual entity detection 
and tracking naacl hlt 
 k jÂ¨arvelin and j kekÂ¨alÂ¨ainen cumulated gain-based 
evaluation of ir techniques acm transactions on 
information systems tois - 
 j lin and d demner-fushman automatically 
evaluating answers to definition questions 
proceedings of the human language technology 
conference and conference on empirical methods in 
natural language processing hlt emnlp 
 
 
statistics dept purdue university west lafayette usa 
â  
language technologies inst carnegie mellon university 
pittsburgh usa 
â¡ 
school of information sciences univ of pittsburgh 
pittsburgh usa 
 j lin and d demner-fushman will pyramids built 
of nuggets topple over proceedings of hlt-naacl 
 
 x luo a ittycheriah h jing n kambhatla and 
s roukos a mention-synchronous coreference 
resolution algorithm based on the bell tree proc of 
acl - 
 g marton nuggeteer automatic nugget-based 
evaluation using descriptions and judgments 
hlt naacl 
 e riloff automatically constructing a dictionary for 
information extraction tasks proceedings of the 
eleventh national conference on artificial 
intelligence pages - 
 s robertson and s walker microsoft cambridge at 
trec- filtering track the ninth text retrieval 
conference trec- pages - 
 r schapire y singer and a singhal boosting and 
rocchio applied to text filtering proceedings of the 
 st annual international acm sigir conference on 
research and development in information retrieval 
pages - 
 t strohman d metzler h turtle and w croft 
indri a language model-based search engine for 
complex queries proceedings of the international 
conference on intelligence analysis 
 the linguistic data consortium 
http www ldc upenn edu 
 e voorhees overview of the trec question 
answering track proceedings of the twelfth text 
retrieval conference trec 
 y yang and b kisiel margin-based local regression 
for adaptive filtering proceedings of the twelfth 
international conference on information and 
knowledge management pages - 
 y yang s yoo j zhang and b kisiel robustness 
of adaptive filtering methods in a cross-benchmark 
evaluation proceedings of the th annual 
international acm sigir conference on research and 
development in information retrieval pages - 
 
 c zhai w cohen and j lafferty beyond 
independent relevance methods and evaluation 
metrics for subtopic retrieval proceedings of the th 
annual international acm sigir conference on 
research and development in information retrieval 
pages - 
 j zhang and y yang robustness of regularized 
linear classification methods in text categorization 
proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval pages - 
 y zhang using bayesian priors to combine 
classifiers for adaptive filtering proceedings of the 
 th annual international conference on research and 
development in information retrieval pages - 
 
 y zhang j callan and t minka novelty and 
redundancy detection in adaptive filtering 
proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval 
