towards self-organising agent-based resource allocation 
in a multi-server environment 
tino schlegel 
 ryszard kowalczyk 
swinburne university of technology 
faculty of information and communication technologies 
hawthorn victoria australia 
 tschlegel 
 rkowalczyk 
  ict swin edu au 
abstract 
distributed applications require distributed techniques for 
efficient resource allocation these techniques need to take 
into account the heterogeneity and potential unreliability of 
resources and resource consumers in a distributed 
environments in this paper we propose a distributed algorithm that 
solves the resource allocation problem in distributed 
multiagent systems our solution is based on the self-organisation 
of agents which does not require any facilitator or 
management layer the resource allocation in the system is a purely 
emergent effect we present results of the proposed resource 
allocation mechanism in the simulated static and dynamic 
multi-server environment 
categories and subject descriptors 
i distributed artificial intelligence coherence 
and coordination 
general terms 
algorithms 
 introduction 
with the increasing popularity of distributed computing 
technologies such as grid and web services the 
internet is becoming a powerful computing platform where 
different software peers e g agents can use existing 
computing resources to perform tasks in this sense each agent 
is a resource consumer that acquires a certain amount of 
resources for the execution of its tasks it is difficult for a 
central resource allocation mechanism to collect and 
manage the information about all shared resources and resource 
consumers to effectively perform the allocation of resources 
hence distributed solutions of the resource allocation 
problem are required researchers have recognised these 
requirements and proposed techniques for distributed resource 
allocation a promising kind of such distributed approaches 
are based on economic market models inspired by 
principles of real stock markets even if those approaches are 
distributed they usually require a facilitator for pricing 
resource discovery and dispatching jobs to resources 
another mainly unsolved problem of those approaches is the 
fine-tuning of price and time budget constraints to enable 
efficient resource allocation in large dynamic systems 
in this paper we propose a distributed solution of the 
resource allocation problem based on self-organisation of the 
resource consumers in a system with limited resources in 
our approach agents dynamically allocate tasks to servers 
that provide a limited amount of resources in our approach 
agents select autonomously the execution platform for the 
task rather than ask a resource broker to do the allocation 
all control needed for our algorithm is distributed among 
the agents in the system they optimise the resource 
allocation process continuously over their lifetime to changes 
in the availability of shared resources by learning from past 
allocation decisions the only information available to all 
agents are resource load and allocation success information 
from past resource allocations additional resource load 
information about servers is not disseminated the basic 
concept of our solution is inspired by inductive reasoning and 
bounded rationality introduced by w brian arthur 
the proposed mechanism does not require a central 
controlling authority resource management layer or introduce 
additional communication between agents to decide which 
task is allocated on which server we demonstrate that 
this mechanism performs well dynamic systems with a large 
number of tasks and can easily be adapted to various 
system sizes in addition the overall system performance is 
not affected in case agents or servers fail or become 
unavailable the proposed approach provides an easy way to 
implement distributed resource allocation and takes into 
account multi-agent system tendencies toward autonomy 
heterogeneity and unreliability of resources and agents 
this proposed technique can be easily supplemented by 
techniques for queuing or rejecting resource allocation 
requests of agents such self-managing capabilities of 
software agents allow a reliable resource allocation even in 
an environment with unreliable resource providers this 
can be achieved by the mutual interactions between agents 
by applying techniques from complex system theory 
selforganisation of all agents leads to a self-organisation of the 
 
 - - - - rps c ifaamas 
system resources and is an emergent property of the 
system 
the remainder of the paper is structured as follows the 
next section gives an overview of the related work already 
done in the area of load balancing resource allocation or 
scheduling section describes the model of a multi-agent 
environment that was used to conduct simulations for a 
performance evaluation sections and describe the 
distributed resource allocation algorithm and presents various 
experimental results a summary conclusion and outlook 
to future work finish this paper 
 related work 
resource allocation is an important problem in the area 
of computer science over the past years solutions based on 
different assumptions and constraints have been proposed by 
different research groups generally speaking 
resource allocation is a mechanism or policy for the efficient 
and effective management of the access to a limited resource 
or set of resources by its consumers in the simplest case 
resource consumers ask a central broker or dispatcher for 
available resources where the resource consumer will be 
allocated the broker usually has full knowledge about all 
system resources all incoming requests are directed to the 
broker who is the solely decision maker in those approaches 
the resource consumer cannot influence the allocation 
decision process load balancing is a special case of the 
resource allocation problem using a broker that tries to be 
fair to all resources by balancing the system load equally 
among all resource providers this mechanism works best 
in a homogeneous system 
a simple distributed technique for resource management 
is capacity planning by refusing or queuing incoming agents 
to avoid resource overload from the resource owner 
perspective this technique is important to prevent overload 
at the resource but it is not sufficient for effective resource 
allocation this technique can only provide a good 
supplement for distributed resource allocation mechanisms 
most of today s techniques for resource allocation in grid 
computing toolkits like globus or condor-g 
coordinate the resource allocation with an auctioneer 
arbitrator dispatcher scheduler or manager those coordinators 
usually need to have global knowledge on the state of all 
system resources an example of a dynamic resource 
allocation algorithm is the cactus project for the allocation 
of computational very expensive jobs 
the value of distributed solutions for the resource 
allocation problem has been recognised by research inspired 
by the principles in stock markets economic market models 
have been developed for trading resources for the 
regulation of supply and demand in the grid these approaches 
use different pricing strategies such as posted price models 
different auction methods or a commodity market model 
users try to purchase cheap resources required to run the job 
while providers try to make as much profit as possible and 
operate the available resources at full capacity a collection 
of different distributed resource allocation techniques based 
on market models is presented in clearwater buyya et 
al developed a resource allocation framework based on the 
regulation of supply and demand for nimrod-g with 
the main focus on job deadlines and budget constraints 
the agent based resource allocation model aram for 
grids is designed to schedule computational expensive jobs 
using agents drawback of this model is the extensive use 
of message exchange between agents for periodic 
monitoring and information exchange within the hierarchical 
structure subtasks of a job migrate through the network until 
they find a resource that meets the price constraints the 
job s migration itinerary is determined by the resources in 
connecting them in different topologies the proposed 
mechanism in this paper eliminates the need of periodic 
information exchange about resource loads and does not need 
a connection topology between the resources 
there has been considerable work on decentralised 
resource allocation techniques using game theory published 
over recent years most of them are formulated as 
repetitive games in an idealistic and simplified environment for 
example arthur introduced the so called el farol bar 
problem that does not allow a perfect logical and rational 
solution it is an ill-defined decision problem that assumes 
and models inductive reasoning it is probably one of the 
most studied examples of complex adaptive systems derived 
from the human way of deciding ill-defined problems a 
variation of the el farol problem is the so called minority 
game in this repetitive decision game an odd number of 
agents have to choose between two resources based on past 
success information trying to allocate itself at the resource 
with the minority galstyan et al studied a variation 
with more than two resources changing resource capacities 
and information from neighbour agents they showed that 
agents can adapt effectively to changing capacities in this 
environment using a set of simple look-up tables strategies 
per agent 
another distributed technique that is employed for solving 
the resource allocation problem is based on reinforcement 
learning similar to our approach a set of agents 
compete for a limited number of resources based only on prior 
individual experience in this paper the system objective is 
to maximise system throughput while ensuring fairness to 
resources measured as the average processing time per job 
unit 
a resource allocation approach for sensor networks based 
on self-organisation techniques and reinforcement learning 
is presented in with main focus on the optimisation of 
energy consumption of network nodes we proposed a 
self-organising load balancing approach for a single server 
with focus on optimising the communication costs of mobile 
agents a mobile agent will reject a migration to a remote 
agent server if it expects the destination server to be 
already overloaded by other agents or server tasks agents 
make their decisions themselves based on forecasts of the 
server utilisation in this paper a solution for a multi-server 
environment is presented without consideration of 
communication or migration costs 
 model description 
we model a distributed multi-agent system as a network 
of servers l l lm agents a a an and 
tasks t t tm each agent has a number of tasks 
ti that needs to be executed during its lifetime a task ti 
requires u ti t resources for its execution at time t 
independent from its execution server resources for the execution 
of tasks are provided by each server li the task s execution 
location in general is specified by the map l t ×t → l an 
agent has to know about the existence of server resources in 
order to allocate tasks at those resources we write ls 
 ai 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
sysytem 
resources 
host l host l host l 
 a a a a 
host l 
 a a 
t t t t t t 
figure an illustration of our multi-server model 
with exclusive and shared resources for the agent 
execution 
to address the set of resources known by agent ai 
resources in the system can be used by all agents for 
the execution of tasks the amount of provided resources 
c li t of each server can vary over time the resource 
utilisation of a server li at time t is calculated using equation 
by adding the resource consumption u tj t of each task tj 
that is executed at the resource at time t all resource units 
used in our model represent real metrics such as memory or 
processor cycles 
u li t 
n 
j 
u tj t l tj t li 
additional to the case that the total amount of system 
resources is enough to execute all tasks we are also interested 
in the case that not enough system resources are provided 
to fulfil all allocation requests that is the overall shared 
resource capacity is lower than the amount of requested 
resources by agents in this case some agents must wait with 
their allocation request until free resources are expected 
the multi-agent system model used for our simulations is 
illustrated in fig 
 self-organising resource 
allocation 
the resource allocation algorithm as described in this 
section is integrated in each agent the only information 
required in order to make a resource allocation decision for 
a task is the server utilisation from completed task 
allocations at those servers there is no additional information 
dissemination about server resource utilisation or 
information about free resources our solution demonstrates that 
agents can self-organise in a dynamic environment without 
active monitoring information that causes a lot of network 
traffic overhead additionally we do not have any central 
controlling authority all behaviour that leads to the 
resource allocation is created by the effective competition of 
the agents for shared resources and is a purely emergent 
effect 
the agents in our multi-agent system compete for 
resources or a set of resources to execute tasks the 
collective action of these agents change the environment and 
as time goes by they have to adapt to these changes to 
compete more effectively in the newly created environment 
our approach is based on different agent beliefs represented 
by predictors and different information about their 
environment agents prefer a task allocation at a server with free 
resources however there is no way to be sure of the amount 
of free server resources in advance all agents have the same 
preferences and a agent will allocate a task on a server if it 
expects enough free resources for its execution there is no 
communication between agents actions taken by agents 
influence the actions of other agents indirectly the applied 
mechanism is inspired by inductive reasoning and bounded 
rationality principles it is derived from the human way 
of deciding ill-defined problems humans tend to keep in 
mind many hypotheses and act on the most plausible one 
therefore each agent keeps track of the performance of a 
private collection of its predictors and selects the one that 
is currently most promising for decision making 
 resource allocation algorithm 
this section describes the decision mechanism for our 
selforganising resource allocation all necessary control is 
integrated in the agents themselves there is no higher 
controlling authority management layer for decision support or 
information distribution all agents have a set of predictors 
for each resource to forecast the future resource utilisation of 
these servers for potential task allocation to do so agents 
use historical information from past task allocations at those 
resources based on the forecasted resource utilisation the 
agent will make its resource allocation decision after the 
task has finished its execution and returned the results back 
to the agent the predictor performances are evaluated and 
history information is updated 
algorithm shows the resource allocation algorithm for 
each agent the agent first predicts the next step s resource 
load for each server with historical information line - 
if the predicted resource load plus the task s resource 
consumption is below the last known server capacity this server 
is added to the list of candidates for the allocation the 
agent then evaluates if any free shared resources for the task 
allocation are expected in the case no free resources are 
expected line the agent will explore resources by 
allocating the task at a randomly selected server from all not 
predictable servers to gather resource load information this 
is the standard case at the beginning of the agent life-cycle 
as there is no information about the environment available 
the resource load prediction itself uses a set of r 
predictors p a l pi ≤ i ≤ r per server one predictor 
pa 
∈ p of each set is called active predictor which forecasts 
the next steps resource load each predictor is a function 
p h → ℵ 
∪ from the space of history data h to 
a non-negative integer which is the forecasted value for 
example a predictor could forecast a resource load equal to 
the average amount of occupied resources during the last 
execution at this resource a history h of resource load 
information is a list of up to m history items hi xi yi 
comprising the observation date xi and the observed value 
yi the most recent history item is h 
hm li x y xk yk ≤ k m 
our algorithm uses a set of predictors rather than only 
one to avoid that all agents make the same decision based 
on the predicted value leading to an invalidation of their 
beliefs imagine that only one shared resource is known 
by a number of agents using one predictor forecasting the 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
resourceload 
time 
 a 
predictor 
predictor 
predictor 
predictor 
predictor 
predictor 
predictor 
predictor 
predictor 
predictor 
 b 
figure a collected resource load information 
from previous task allocations that is used for future 
predictions b predictor s probability distribution 
for selecting the new active predictor 
same value as the last known server resource utilisation all 
agents that allocated a task at a server that was slightly 
overloaded would dismiss another allocation at this server 
as they expect the server to be overloaded again based on 
the predictions as the result the server would have a large 
amount of free resources a set of different predictors that 
predict different values avoids this situation of invalidating 
the beliefs of the agents 
an example of a collected resource load information from 
the last visits of an agent at a shared resource can be 
seen in fig a it shows that the resource was visited 
frequently which means free resources for execution were 
available and an exploration of other servers was 
unnecessary this may change in the future as the resource load has 
significantly increased recently 
in the case where the set of servers predicted having free 
resources available is not empty line the agent selects 
one of those for allocation we have implemented two 
alternative algorithms for the selection of a server for the task 
allocation 
algorithm resource allocation algorithm of an agent 
 l ← ∅ server with free resources 
 u ← u t t task resource consumption 
 for all p a l l ∈ ls 
 a do 
 u l ← resourceloadprediction p a l t 
 if u l u ≤ c l then 
 l ← l ∪ p a l 
 end if 
 end for 
 if l ∅ then 
 all unpredictable shared resources 
 e ← ls 
 l ∈ ls 
 a p a l ∈ l 
 allocationserver ← a random element of e 
 else 
 allocationserver ← serverselection l 
 end if 
 return allocationserver 
algorithm shows the first method which is a 
non-deterministic selection according to the predictability of the 
server resource utilisation a probability distribution is 
calculated from the confidence levels of the resource 
predictions the confidence level depends on three factors the 
accuracy of the active predictor the amount of historical 
information about the server and the average age of the 
history information see eq the server with the highest 
confidence level has the biggest chance to be selected as the 
active server 
g p 
w · size h 
m 
 
w · age h 
max age h 
 
w · g p 
max g p 
 
where 
wi − weights 
size h − number of data in history 
m − maximal number of history values 
age h − average age of historical data 
g p − see eq 
algorithm serverselection l - best predictable server 
 for all p a l ∈ l do 
 calculate g p 
 end for 
 transform all g p into a probability distribution 
 return l ∈ ls 
selected according to the probability 
distribution 
algorithm serverselection l - most free resources 
 for all p a l ∈ l do 
 c l ← c l − ul 
 end for 
 return l ∈ ls 
 c l is maximum 
the second alternative selection method of a server from 
the set of predicted servers with free resources is 
deterministic and shown in algorithm the server with most expected 
free resources from the set l of server with expected free 
resources is chosen in the case where all agents predict the 
most free resources for one particular server all agents will 
allocate the task at this server which would invalidate the 
agent s beliefs however our experiments show that 
different individual history information and the non-deterministic 
active predictor selection usually prevent this situation 
in the case the resource allocation algorithm does not 
return any server alg line the allocation at a resource 
in not recommended the agent will not allocate the task 
at a resource this case happens only if a resource load 
prediction for all servers is possible but no free resources are 
expected 
after the agent execution has finished the evaluation 
process described in algorithm is preformed this process is 
divided into three cases first the task was not allocated 
at a resource in this case the agent cannot decide if the 
decision not to allocate the task was correct or not the 
agent then removes old historical data this is necessary 
for a successful adaptation in the future if the agent would 
not delete old historical information the prediction would 
always forecast that no free resources are available the 
agent would never allocate a task at one of the resources in 
the future 
old historical information is removed from the agent s 
resource history using a decay rate the decay rate is a 
cumulative distribution function that calculates the probability 
that a history item is deleted after it has reached a certain 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
age of the history data 
decayrate 
 
 
older 
figure decay rate of historical information 
age the current implementation uses a constant probability 
density function in a configurable domain figure shows 
an example of such a cumulative distribution function for the 
decay rate depending on the environment the probability 
density function must be altered if the number of potential 
server per agent is high historical information must be kept 
longer to avoid the exploration of unexplored resources in 
addition a dynamic environment requires more up-to-date 
information to make more reliable predictions 
the second case in the evaluation process alg line 
 describes the actions taken after a server was visited the 
first time the agent creates a new predictor set for this 
server and records the historical information all predictors 
for this set are chosen randomly from some predefined set 
g p 
l 
i 
ri 
where 
ri 
⎧ 
⎨ 
⎩ 
 if ith 
correct decision 
 if ith 
unknown outcome 
− if ith 
wrong decision 
the general case alg line is the evaluation after the 
agent allocated the task at a resource the agent evaluates 
all predictors of the predictor set for this resource by 
predicting the resource load with all predictors based on the old 
historical data predictors that made a correct prediction 
meaning the resource allocation was correct will receive a 
positive rating this is the case that the resource was not 
overloaded and free resources for execution were predicted 
or the resource was overloaded and this predictor would have 
prevented the allocation all predictors that predicted 
values which would lead to wrong decisions will receive negative 
ratings in all other cases which includes that no 
prediction was possible a neutral rating is given to the predictors 
based on these performance ratings the confidence levels 
are calculated using equation the confidence for all 
predictors that cannot predict with the current historical 
information about the server is set to zero to prevent the selection 
of those as the new active predictor these values are 
transformed into a probability distribution according to this 
probability distribution the new active predictor is chosen 
implemented as a roulette wheel selection figure b 
illustrates the probabilities of a set of predictors which 
have been calculated from the predictor confidence levels 
even if predictor has the highest selection probability its 
was not chosen by roulette wheel selection process as the 
active predictor this non-deterministic predictor selection 
prevents the invalidation of the agents beliefs in case agents 
have the same set of predictors 
the prediction accuracy that is the error of the prediction 
compared to the observed value is not taken into 
consideration suppose the active predictor predicts slightly above 
the resource capacity which leads not to a allocation on a 
resources in fact enough resources for the execution would 
be available a less accurate prediction which is far below 
the capacity would lead to the correct decision and is 
therefore preferred 
the last action of the evaluation algorithm alg line 
 updates the history with the latest resource load 
information of the server the oldest history data is overwritten 
if already m history values are recorded for the server 
algorithm decision evaluation 
 if l ∈ le 
then 
 for all p a l l ∈ ls 
 a do 
 evaporate old historical data 
 end for 
 else if p a l null then 
 create p a l 
 update h l 
 else 
 for all p ∈ p a l do 
 pred ← resourceloadprediction p 
 if u l ≤ c l and pred u a t ≤ c l or 
 u l c l and pred u a t c l then 
 addpositiverating p 
 else if u l ≤ c l and pred u a t c l or 
u l ≤ c l and pred u a t c l then 
 addnegativerating p 
 else 
 addneutralrating p 
 end if 
 end for 
 calculate all g p g p ← if p is not working 
 transform all g p into a probability distribution 
 pa 
← p ∈ p a l is selected according to this 
probability distribution 
 update h l 
 end if 
 remarks and limitation of the approach 
our prediction mechanism uses a number of different types 
of simple predictors rather than of one sophisticated 
predictor this method assures that agents can compete more 
effectively in a changing environment different types of 
predictors are suitable for different situations and 
environments therefore all predictors are being evaluated after 
each decision and the active predictor is selected this 
nondeterministic of the new active predictor supports that the 
agents beliefs will not be invalidated which happens in the 
case that all predictors are making the same decision 
especially if there is only one shared resource available and 
all agents have only the choice to go the this one shared 
resource or not 
our self-organising approach is robust against failures of 
resources or agents in the system if they join or leave 
the system can self-organise quickly and adapts to the new 
conditions there is no classical bottleneck or single point 
of failure like in centralised mechanisms the limitations 
are the reliance on historical resource utilisation information 
about other servers a forecast of the resource utilisation of 
a remote server is only possible if an agent has a number of 
historical information about a shared resource if the 
number of servers per agent is very large there is no efficient way 
to gather historical information about remote servers this 
problem occurs if the amount of provided shared resources 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
is limited and not enough for all resource consumers in this 
case the an agent would randomly try all known servers 
until it will find one with free resources or there is no one in 
the worst case by the time for trying all servers historical 
information of the servers is already outdated 
 experimental evaluation 
the first part of this section gives a short overview of 
the setup of our simulation environment in the rest of 
the section results of the experiments are presented and 
discussed all experiments are conducted in a special 
testbed that simulates and models a multi-agent system we 
have implemented this test-bed in the java programming 
language independent from any specific agent toolkit it 
allows a variety of experiments in in stable as well as 
dynamic environments with a configurable number of agents 
tasks and servers an event-driven model is used to trigger 
all activities in the system 
for all simulations we limited the number of history data 
for each server to the number of performance ratings per 
predictor to and assigned predictors to every predictor 
set for each agent all predictors are chosen randomly from 
a arbitrary predefined set of predictors of the following 
type predictors differ in different cycles or window sizes 
- n-cycle predictor p n yn uses the nth 
-last history 
value 
- n-mean predictor p n 
n 
· 
n 
i 
yi uses the mean value 
of the n-last history values 
- n-linear regression predictor p n t a·t b uses the 
linear regression value from the last n history values 
where a b are calculated using linear regression with 
least squares fitting under consideration of the last n 
history data 
- n-distribution predictor uses a random value from the 
frequency distribution of the n last history values 
- n-mirror predictor p n · h − yn uses the mirror 
image around the mean of all history values of the nth 
last history value 
the efficiency of our proposed self-organising resource 
allocation is assessed by the resource load development of each 
server over the simulation as well as the total resource load 
development cumulated over all shared resources resource 
loads for each server are calculated using equation as the 
sum of the resource consumption of all currently executed 
agents at this server the total resource load of the system 
is calculated as the sum of the resources load of all resources 
the self-organising resource allocation algorithm has 
random elements therefore the presented results show mean 
values and standard derivation calculated over repeated 
experiments 
 experimental setup 
the following parameters have an impact on the resource 
allocation process we give an overview of the parameters 
and a short description 
- agents the number of agents involved in the resource 
allocation this number varies in the experiments 
between and dependent on the total amount of 
available system resources 
- resource consumption each task consumes server 
resources for its execution the resource consumption is 
assigned randomly to each task prior to its allocation 
from an interval resource consumption is specified in 
resource units which corresponds to real world metrics 
like memory or processor cycles 
- agent home server all agents are located on a home 
agent server the resources of those servers not 
considered in our simulation and does not affect the resource 
allocation performance 
- server resources experiments use servers with 
different amount of available shared resources the first 
experiment is conducted in a static server environment 
that provides the same amount of shared resources 
while the other experiment varies the available server 
resource during the simulation the total amount of 
resources remains constant in both experiments 
- execution time the execution time of a task for the 
execution independent from the execution platform 
for this time the task consumes the assigned amount of 
server resources this parameter is randomly assigned 
before the execution 
- task creation time the time before the next task 
is created after successful or unsuccessful completion 
this parameter influences the age of the historical 
information about resources and has a major influence 
on the length of the initial adaptation phase this 
parameter is randomly assigned after the task was 
completed 
 experimental results 
this section shows results from selected experiments that 
demonstrate the performance of our proposed resource 
allocation mechanism the first experiment show the 
performance in a stable environment where a number of agents 
allocate tasks to servers that provide a constant amount of 
resources the second experiment was conducted in a 
dynamic server environment with a constant number of agents 
the first experiment shows our model in a stable -server 
environment that provide a total amount of resource 
units the resource capacity of each server remains constant 
over the experiment we used agents with the 
parameters of the execution time between and time units and 
a task creation time in the interval − time units the 
task s resource consumption is randomly assigned from the 
interval − resource units figure shows the results 
from repetitions of this experiment figure a shows 
that the total amount of provided resources is larger than 
the demand of resource in average at the beginning of the 
experiment all agents allocate their tasks randomly at one 
of the available servers and explore the available capacities 
and resource utilisations for about time units this 
initial exploration phase shows that the average resource load 
of each server has a similar level this causes an overload 
situation at server because of its low capacity of shared 
resources and a large amount of free resources on server 
 agents that allocated tasks to server detect the 
overload situation and explore randomly other available servers 
they find free resources at server after learning period 
the agents have self-organised themselves in this stable 
environment and find a stable solution for the allocation of 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
 
time 
 
 
 
 
 
 
 
 
resourceload 
 a total resource load 
versus total shared resource 
capacity 
 
time 
 
 
 
 
 
 
resourceload 
 b resource load server 
 
time 
 
 
 
 
 
 
resourceload 
 c resource load server 
 
time 
 
 
 
 
 
 
 
 
 
resourceload 
 d resource load server 
figure results of experiment in a static -server 
environment averaged over repetitions 
all tasks the standard deviation of the resource loads are 
small for each server which indicates that our distributed 
approach find stable solutions in almost every run 
this experiment used algorithm for the selection of the 
active server we also ran the same experiment with the 
most free resources selection mechanism to select the active 
server the resource allocation for each server is similar 
the absolute amount of free resources per server is almost 
the same 
experiment was conducted in a dynamic -server 
environment with a number of agents the amount of 
resources of server and server changes periodically while 
the total amount of available resources remains constant 
server has an initial capacity of units server start 
with a capacity of units the change in capacity starts 
after time units which is approximately the end of the 
learning phase figure b c d shows the behaviour of our 
self-organising resource allocation in this environment all 
agents use the deterministic most free resources selection 
mechanism to select the active server it can bee seen in 
fig b and c that the number of allocated resources to 
server and server changes periodically with the amount of 
provided resources this shows that agents can sense 
available resources in this dynamic environment and are able to 
adapt to those changes the resource load development of 
server see fig d shows a periodic change because 
some agent try to be allocated tasks to this server in case 
their previously favoured server reduce the amount of shared 
resources the total resource load of all shared resources is 
constant over the experiments which indicates the all agents 
allocate their tasks to one of the shared resource comp fig 
 a 
 conclusions and future work 
in this paper a self-organising distributed resource 
allocation technique for multi-agent systems was presented we 
enable agents to select the execution platform for their tasks 
themselves before each execution at run-time in our 
approach the agents compete for an allocation at one of the 
 
time 
 
 
 
 
resourceload 
 a total resource load 
versus total shared resource 
capacity 
 
time 
 
 
 
 
 
 
 
 
 
resourceload 
 b resource load server 
 
time 
 
 
 
 
 
 
 
 
 
resourceload 
 c resource load server 
 
time 
 
 
 
 
 
 
 
 
 
resourceload 
 d resource load server 
figure results of experiment in a dynamic 
server environment averaged over repetitions 
available shared resource agents sense their server 
environment and adopt their action to compete more efficient in 
the new created environment this process is adaptive and 
has a strong feedback as allocation decisions influence 
indirectly decisions of other agents the resource allocation is a 
purely emergent effect our mechanism demonstrates that 
resource allocation can be done by the effective 
competition of individual and autonomous agents neither do they 
need coordination or information from a higher authority 
nor is an additional direct communication between agents 
required 
this mechanism was inspired by inductive reasoning and 
bounded rationality principles which enables the agents 
adaptation of their strategies to compete effectively in a 
dynamic environment in the case of a server becomes 
unavailable the agents can adapt quickly to this new situation 
by exploring new resources or remain at the home server 
if an allocation is not possible especially in dynamic and 
scalable environments such as grid systems a robust and 
distributed mechanism for resource allocation is required 
our self-organising resource allocation approach was 
evaluated with a number of simulation experiments in a dynamic 
environment of agents and server resources the presented 
results for this new approach for strategic migration 
optimisation are very promising and justify further investigation 
in a real multi-agent system environment 
it is a distributed scalable and easy-to-understand 
policy for the regulation of supply and demand of resources 
all control is implemented in the agents a simple decision 
mechanism based on different beliefs of the agent creates an 
emergent behaviour that leads to effective resource 
allocation this approach can be easily extended or supported 
by resource balancing queuing mechanisms provided by 
resources 
our approach adapts to changes in the environment but it 
is not evolutionary there is no discovery of new strategies 
by the agents the set of predictors stays the same over the 
whole life in fact we believe that this could further improve 
the system s behaviour over a long term period and could be 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
investigated in the future the evolution would be very slow 
and selective and will not influence the system behaviour 
in a short-term period that is covered by our experimental 
results 
in the near future we will investigate if an automatic 
adaptation of the decay rate of historical information our 
algorithm is possible and can improve the resource allocation 
performance the decay rate is currently predefined and 
must be altered manually depending on the environment 
a large number of shared resources requires older historical 
information to avoid a too frequently resources exploration 
in contrast a dynamic environment with varying capacities 
requires more up-to-date information to make more reliable 
predictions 
we are aware of the long learning phase in environments 
with a large number of shared resources known by each 
agent in the case that more resources are requested by 
agents than shared resources are provided by all servers all 
agents will randomly explore all known servers this 
process of acquiring resource load information about all servers 
can take a long time in the case that no not enough shared 
resources for all tasks are provided in the worst case by 
the time for exploring all servers historical information of 
some servers could be already outdated and the exploration 
starts again in this situation it is difficult for an agent 
to efficiently gather historical information about all remote 
servers this issue needs more investigation in the future 
 references 
 g allen w benger t dramlitsch t goodale 
h -c hege g lanfermann a merzky t radke 
e seidel and j shalf cactus tools for grid 
applications in cluster computing volume pages 
 - hingham ma usa kluwer academic 
publishers 
 w b arthur inductive reasoning and bounded 
rationality american economic review papers and 
proceedings - may 
 t bourke server load balancing o reilly media 
edition august 
 r buyya economic-based distributed resource 
management and scheduling for grid computing 
phd thesis monash university melbourne australia 
may 
 r buyya d abramson j giddy and h stockinger 
economic models for resource management and 
scheduling in grid computing special issue on grid 
computing environments of the journal concurrency 
and computation - - 
 r buyya s chapin and d dinucci architectural 
models for resource management in the grid in 
proceedings of the first international workshop on 
grid computing pages - springer lncs 
 t l casavant and j g kuhl a taxonomy of 
scheduling in general-purpose distributed computing 
systems ieee transactions on software engineering 
 - february 
 d challet and y zhang emergence of cooperation 
and organization in an evolutionary game physica 
a 
 k -p chow and y -k kwok on load balancing for 
distributed multiagent computing in ieee 
transactions on parallel and distributed systems 
volume pages - ieee august 
 s h clearwater market-based control a paradigm 
for distributed resource allocation world scientific 
singapore 
 c fl¨us capacity planning of mobile agent systems 
designing efficient intranet applications phd thesis 
universit¨at duisburg-essen germany feb 
 i foster and c kesselman globus a 
metacomputing infrastructure toolkit international 
journal of supercomputing applications 
 - 
 j frey t tannenbaum i foster m livny and 
s tuecke condor-g a computation management 
agent for multi-institutional grids cluster 
computing - 
 a galstyan s kolar and k lerman resource 
allocation games with changing resource capacities in 
proceedings of the second international joint 
conference on autonomous agents and multiagent 
systems pages - melbourne australia 
acm press new york ny usa 
 c georgousopoulos and o f rana combining state 
and model-based approaches for mobile agent load 
balancing in sac proceedings of the acm 
symposium on applied computing pages - new 
york ny usa acm press 
 g mainland d c parkes and m welsh 
decentralized adaptive resource allocation for sensor 
networks in proceedings of the nd usenix 
symposium on network systems design and 
implementation nsdi may 
 s manvi m birje and b prasad an agent-based 
resource allocation model for computational grids 
multiagent and grid systems - an international 
journal - 
 a schaerf y shoham and m tennenholtz 
adaptive load balancing a study in multi-agent 
learning in journal of artificial intelligence 
research volume pages - 
 t schlegel p braun and r kowalczyk towards 
autonomous mobile agents with emergent migration 
behaviour in proceedings of the fifth international 
joint conference on autonomous agents multi 
agent systems aamas hakodate japan 
pages - acm press may 
 w c web services activity 
http www w org ws - last visited 
 m m waldrop complexity the emerging science at 
the edge of order and chaos simon schuster st 
edition 
 r wolsk j s plank j brevik and t bryan 
analyzing market-based resource allocation 
strategies for the computational grid in 
international journal of high performance computing 
applications volume pages - sage science 
press 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
