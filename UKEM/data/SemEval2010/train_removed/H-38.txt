diffusionrank a possible penicillin for web spamming 
haixuan yang irwin king and michael r lyu 
dept of computer science and engineering 
the chinese university of hong kong 
shatin nt hong kong 
 hxyang king lyu  cse cuhk edu hk 
abstract 
while the pagerank algorithm has proven to be very 
effective for ranking web pages the rank scores of web pages 
can be manipulated to handle the manipulation problem 
and to cast a new insight on the web structure we propose 
a ranking algorithm called diffusionrank diffusionrank is 
motivated by the heat diffusion phenomena which can be 
connected to web ranking because the activities flow on the 
web can be imagined as heat flow the link from a page to 
another can be treated as the pipe of an air-conditioner and 
heat flow can embody the structure of the underlying web 
graph theoretically we show that diffusionrank can serve 
as a generalization of pagerank when the heat diffusion 
coefficient γ tends to infinity in such a case γ 
diffusionrank pagerank has low ability of anti-manipulation 
when γ diffusionrank obtains the highest ability of 
anti-manipulation but in such a case the web structure is 
completely ignored consequently γ is an interesting factor 
that can control the balance between the ability of 
preserving the original web and the ability of reducing the effect 
of manipulation it is found empirically that when γ 
diffusionrank has a penicillin-like effect on the link 
manipulation moreover diffusionrank can be employed to 
find group-to-group relations on the web to divide the web 
graph into several parts and to find link communities 
experimental results show that the diffusionrank algorithm 
achieves the above mentioned advantages as expected 
categories and subject descriptors h 
 information systems information search and retrieval g 
 discrete mathematics graph theory 
general terms algorithms 
 introduction 
while the pagerank algorithm has proven to be very 
effective for ranking web pages inaccurate pagerank 
results are induced because of web page manipulations by 
people for commercial interests the manipulation problem is 
also called the web spam which refers to hyperlinked pages 
on the world wide web that are created with the intention 
of misleading search engines it is reported that 
approximately of all pages in the biz domain and about 
of the pages in the us domain belong to the spam category 
 the reason for the increasing amount of web spam is 
explained in some web site operators try to influence 
the positioning of their pages within search results because 
of the large fraction of web traffic originating from searches 
and the high potential monetary value of this traffic 
from the viewpoint of the web site operators who want 
to increase the ranking value of a particular page for search 
engines keyword stuffing and link stuffing are being used 
widely from the viewpoint of the search engine 
managers the web spam is very harmful to the users evaluations 
and thus their preference to choosing search engines because 
people believe that a good search engine should not return 
irrelevant or low-quality results there are two methods 
being employed to combat the web spam problem machine 
learning methods are employed to handle the keyword 
stuffing to successfully apply machine learning methods we 
need to dig out some useful textual features for web pages 
to mark part of the web pages as either spam or non-spam 
then to apply supervised learning techniques to mark other 
pages for example see link analysis methods are 
also employed to handle the link stuffing problem one 
example is the trustrank a link-based method in which 
the link structure is utilized so that human labelled trusted 
pages can propagate their trust scores trough their links 
this paper focuses on the link-based method 
the rest of the materials are organized as follows in the 
next section we give a brief literature review on various 
related ranking techniques we establish the heat diffusion 
model hdm on various cases in section and propose 
diffusionrank in section in section we describe the 
data sets that we worked on and the experimental results 
finally we draw conclusions in section 
 literature review 
the importance of a web page is determined by either 
the textual content of pages or the hyperlink structure or 
both as in previous work we focus on ranking 
methods solely determined by hyperlink structure of the 
web graph all the mentioned ranking algorithms are 
established on a graph for our convenience we first give some 
notations denote a static graph by g v e where v 
 v v vn e vi vj there is an edge from vi to 
vj ii and di denote the in-degree and the out-degree of 
page i respectively 
 pagerank 
the importance of a web page is an inherently subjective 
matter which depends on the reader s interests knowledge 
and attitudes however the average importance of all 
readers can be considered as an objective matter pagerank 
tries to find such average importance based on the web link 
structure which is considered to contain a large amount of 
statistical data the web is modelled by a directed graph g 
in the pagerank algorithms and the rank or importance 
xi for page vi ∈ v is defined recursively in terms of pages 
which point to it xi j i ∈e aijxj where aij is assumed 
to be dj if there is a link from j to i and otherwise or 
in matrix terms x ax when the concept of random 
jump is introduced the matrix form is changed to 
x − α g t 
 αa x 
where α is the probability of following the actual link from a 
page − α is the probability of taking a random jump 
and g is a stochastic vector i e t 
g typically α 
 and g 
n 
 is one of the standard settings where is 
the vector of all ones 
 trustrank 
trustrank is composed of two parts the first part 
is the seed selection algorithm in which the inverse 
pagerank was proposed to help an expert of determining a good 
node the second part is to utilize the biased pagerank 
in which the stochastic distribution g is set to be shared by 
all the trusted pages found in the first part moreover the 
initial input of x is also set to be g the justification for 
the inverse pagerank and the solid experiments support its 
advantage in combating the web spam although there are 
many variations of pagerank e g a family of link-based 
ranking algorithms in trustrank is especially chosen for 
comparisons for three reasonss it is designed for 
combatting spamming its fixed parameters make a 
comparison easy and it has a strong theoretical relations with 
pagerank and diffusionrank 
 manifold ranking 
in the idea of ranking on the data manifolds was 
proposed the data points represented as vectors in euclidean 
space are considered to be drawn from a manifold from 
the data points on such a manifold an undirected weighted 
graph is created then the weight matrix is given by the 
gaussian kernel smoothing while the manifold ranking 
algorithm achieves an impressive result on ranking images 
the biased vector g and the parameter k in the general 
personalized pagerank in are unknown in the web graph 
setting therefore we do not include it in the comparisons 
 heat diffusion 
heat diffusion is a physical phenomena in a medium 
heat always flow from position with high temperature to 
position with low temperature heat kernel is used to 
describe the amount of heat that one point receives from 
another point recently the idea of heat kernel on a manifold 
is borrowed in applications such as dimension reduction 
and classification in these work the input data 
is considered to lie in a special structure 
all the above topics are related to our work the readers 
can find that our model is a generalization of pagerank in 
order to resist web manipulation that we inherit the first 
part of trustrank that we borrow the concept of ranking on 
the manifold to introduce our model and that heat diffusion 
is a main scheme in this paper 
 heat diffusion model 
heat diffusion provides us with another perspective about 
how we can view the web and also a way to calculate 
ranking values in this paper the web pages are considered to 
be drawn from an unknown manifold and the link structure 
forms a directed graph which is considered as an 
approximation to the unknown manifold the heat kernel established 
on the web graph is considered as the representation of the 
relationship between web pages the temperature 
distribution after a fixed time period induced by a special initial 
temperature distribution is considered as the rank scores on 
the web pages before establishing the proposed models we 
first show our motivations 
 motivations 
there are two points to explain that pagerank is 
susceptible to web spam 
 over-democratic there is a belief behind 
pagerank-all pages are born equal this can be seen from 
the equal voting ability of one page the sum of each 
column is equal to one this equal voting ability of all 
pages gives the chance for a web site operator to 
increase a manipulated page by creating a large number 
of new pages pointing to this page since all the newly 
created pages can obtain an equal voting right 
 input-independent for any given non-zero initial 
input the iteration will converge to the same stable 
distribution corresponding to the maximum eigenvalue 
 of the transition matrix this input-independent 
property makes it impossible to set a special initial 
input larger values for trusted pages and less values even 
negative values for spam pages to avoid web spam 
the input-independent feature of pagerank can be further 
explained as follows p − α g t 
 αa is a positive 
stochastic matrix if g is set to be a positive stochastic vector 
 the uniform distribution is one of such settings and so the 
largest eigenvalue is and no other eigenvalue whose 
absolute value is equal to which is guaranteed by the perron 
theorem let y be the eigenvector corresponding to 
then we have py y let xk be the sequence generated 
from the iterations xk pxk and x is the initial input 
if xk converges to x then xk pxk implies that x 
must satisfy px x since the only maximum eigenvalue 
is we have x cy where c is a constant and if both x 
and y are normalized by their sums then c the above 
discussions show that pagerank is independent of the initial 
input x 
in our opinion g and α are objective parameters 
determined by the users behaviors and preferences a α and 
g are the true web structure while a is obtained by a 
crawler and the setting α is accepted by the people 
we think that g should be determined by a user behavior 
investigation something like without any prior 
knowledge g has to be set as g 
n 
 
trustrank model does not follow the true web structure 
by setting a biased g but the effects of combatting 
spamming are achieved in pagerank is on the contrary in 
some ways we expect a ranking algorithm that has an 
effect of anti-manipulation as trustrank while respecting the 
true web structure as pagerank 
we observe that the heat diffusion model is a natural way 
to avoid the over-democratic and input-independent feature 
of pagerank since heat always flows from a position with 
higher temperatures to one with lower temperatures points 
are not equal as some points are born with high 
temperatures while others are born with low temperatures on the 
other hand different initial temperature distributions will 
give rise to different temperature distributions after a fixed 
time period based on these considerations we propose the 
novel diffusionrank this ranking algorithm is also 
motivated by the viewpoint for the web structure we view 
all the web pages as points drawn from a highly complex 
geometric structure like a manifold in a high dimensional 
space on a manifold heat can flow from one point to 
another through the underlying geometric structure in a given 
time period different geometric structures determine 
different heat diffusion behaviors and conversely the diffusion 
behavior can reflect the geometric structure more 
specifically on the manifold the heat flows from one point to 
another point and in a given time period if one point x 
receives a large amount of heat from another point y we 
can say x and y are well connected and thus x and y have 
a high similarity in the sense of a high mutual connection 
we note that on a point with unit mass the temperature 
and the heat of this point are equivalent and these two terms 
are interchangeable in this paper in the following we first 
show the hdm on a manifold which is the origin of hdm 
but cannot be employed to the world wide web directly 
and so is considered as the ideal case to connect the ideal 
case and the practical case we then establish hdm on a 
graph as an intermediate case to model the real world 
problem we further build hdm on a random graph as a 
practical case finally we demonstrate the diffusionrank 
which is derived from the hdm on a random graph 
 heat flow on a known manifold 
if the underlying manifold is known the heat flow 
throughout a geometric manifold with initial conditions can be 
described by the following second order differential equation 
∂f x t 
∂t 
− ∆f x t where f x t is the heat at location x 
at time t and ∆f is the laplace-beltrami operator on a 
function f the heat diffusion kernel kt x y is a special 
solution to the heat equation with a special initial condition-a 
unit heat source at position y when there is no heat in other 
positions based on this the heat kernel kt x y describes 
the heat distribution at time t diffusing from the initial unit 
heat source at position y and thus describes the 
connectivity which is considered as a kind of similarity between x 
and y however it is very difficult to represent the world 
wide web as a regular geometry with a known dimension 
even the underlying is known it is very difficult to find the 
heat kernel kt x y which involves solving the heat 
equation with the delta function as the initial condition this 
motivates us to investigate the heat flow on a graph the 
graph is considered as an approximation to the underlying 
manifold and so the heat flow on the graph is considered as 
an approximation to the heat flow on the manifold 
 on an undirected graph 
on an undirected graph g the edge vi vj is considered 
as a pipe that connects nodes vi and vj the value fi t 
describes the heat at node vi at time t beginning from an 
initial distribution of heat given by fi at time zero f t 
 f denotes the vector consisting of fi t fi 
we construct our model as follows suppose at time t 
each node i receives m i j t ∆t amount of heat from its 
neighbor j during a period of ∆t the heat m i j t ∆t 
should be proportional to the time period ∆t and the heat 
difference fj t − fi t moreover the heat flows from node 
j to node i through the pipe that connects nodes i and j 
based on this consideration we assume that m i j t ∆t 
γ fj t − fi t ∆t as a result the heat difference at node 
i between time t ∆t and time t will be equal to the sum 
of the heat that it receives from all its neighbors this is 
formulated as 
fi t ∆t − fi t 
j j i ∈e 
γ fj t − fi t ∆t 
where e is the set of edges to find a closed form solution 
to eq we express it in a matrix form f t ∆t − 
f t ∆t γhf t where d v denotes the degree of the 
node v in the limit ∆t → it becomes d 
dt 
f t γhf t 
solving it we obtain f t eγth 
f especially we have 
f eγh 
f hij 
 
 
 
−d vj j i 
 vj vi ∈ e 
 otherwise 
 
where eγh 
is defined as eγh 
 i γh γ 
 
h 
 γ 
 
h 
 · · · 
 on a directed graph 
the above heat diffusion model must be modified to fit the 
situation where the links between web pages are directed 
on one web page when the page-maker creates a link a b 
to another page b he actually forces the energy flow for 
example people s click-through activities to that page and 
so there is added energy imposed on the link as a result 
heat flows in a one-way manner only from a to b not from 
b to a based on such consideration we modified the heat 
diffusion model on an undirected graph as follows 
on a directed graph g the pipe vi vj is forced by added 
energy such that heat flows only from vi to vj suppose at 
time t each node vi receives rh rh i j t ∆t amount of 
heat from vj during a period of ∆t we have three 
assumptions rh should be proportional to the time period ∆t 
 rh should be proportional to the the heat at node vj 
and rh is zero if there is no link from vj to vi as a 
result vi will receive j vj vi ∈e σjfj t ∆t amount of heat 
from all its neighbors that points to it 
on the other hand node vi diffuses dh i t ∆t amount 
of heat to its subsequent nodes we assume that the 
heat dh i t ∆t should be proportional to the time period 
∆t the heat dh i t ∆t should be proportional to the 
the heat at node vi each node has the same ability of 
diffusing heat this fits the intuition that a web surfer only 
has one choice to find the next page that he wants to browse 
 the heat dh i t ∆t should be uniformly distributed 
to its subsequent nodes the real situation is more complex 
than what we assume but we have to make this simple 
assumption in order to make our model concise as a result 
node vi will diffuse γfi t ∆t di amount of heat to any of its 
subsequent nodes and each of its subsequent node should 
receive γfi t ∆t di amount of heat therefore σj γ dj 
to sum up the heat difference at node vi between time 
t ∆t and time t will be equal to the sum of the heat that it 
receives deducted by what it diffuses this is formulated as 
fi t ∆t − fi t −γfi t ∆t j vj vi ∈e γ djfj t ∆t 
similarly we obtain 
f eγh 
f hij 
 
 
 
− j i 
 dj vj vi ∈ e 
 otherwise 
 
 on a random directed graph 
for real world applications we have to consider random 
edges this can be seen in two viewpoints the first one 
is that in eq the web graph is actually modelled as 
a random graph there is an edge from node vi to node vj 
with a probability of − α gj see the item − α g t 
 
and that the web graph is predicted by a random graph 
 the second one is that the web structure is a 
random graph in essence if we consider the content similarity 
between two pages though this is not done in this paper 
for these reasons the model would become more flexible if 
we extend it to random graphs the definition of a random 
graph is given below 
definition a random graph rg v p pij is 
defined as a graph with a vertex set v in which the edges are 
chosen independently and for ≤ i j ≤ v the probability 
of vi vj being an edge is exactly pij 
the original definition of random graphs in is changed 
slightly to consider the situation of directed graphs note 
that every static graph can be considered as a special 
random graph in the sense that pij can only be or 
on a random graph rg v p where p pij is 
the probability of the edge vi vj exists in such a random 
graph the expected heat difference at node i between time 
t ∆t and time t will be equal to the sum of the expected 
heat that it receives from all its antecedents deducted by 
the expected heat that it diffuses 
since the probability of the link vj vi is pji the 
expected heat flow from node j to node i should be multiplied 
by pji and so we have fi t ∆t − fi t −γ fi t ∆t 
j vj vi ∈e γpjifj t ∆t rd 
 vj where rd 
 vi is the 
expected out-degree of node vi it is defined as k pik 
similarly we have 
f eγr 
f rij 
 
 
 
− j i 
pji rd 
 vj j i 
 
when the graph is large a direct computation of eγr 
is 
time-consuming and we adopt its discrete approximation 
f i 
γ 
n 
r n 
f 
the matrix i γ 
n 
r n 
in eq and matrix eγr 
in eq 
are called discrete diffusion kernel and the continuous 
diffusion kernel respectively based on the heat diffusion 
models and their solutions diffusionrank can be 
established on undirected graphs directed graphs and random 
graphs in the next section we mainly focus on 
diffusionrank in the random graph setting 
 diffusionrank 
for a random graph the matrix i γ 
n 
r n 
or eγr 
can 
measure the similarity relationship between nodes let fi 
 fj if j i then the vector f represent the unit 
heat at node vi while all other nodes has zero heat for such 
f in a random graph we can find the heat distribution 
at time by using eq or eq the heat 
distribution is exactly the i−th row of the matrix of i γ 
n 
r n 
or 
eγr 
 so the ith-row jth-column element hij in the matrix 
 i γ∆tr n 
or eγr 
means the amount of heat that vi can 
receive from vj from time to thus the value hij can be 
used to measure the similarity from vj to vi for a static 
graph similarly the matrix i γ 
n 
h n 
or eγh 
can measure 
the similarity relationship between nodes 
the intuition behind is that the amount h i j of heat 
that a page vi receives from a unit heat in a page vj in a 
unit time embodies the extent of the link connections from 
page vj to page vi roughly speaking when there are more 
uncrossed paths from vj to vi vi will receive more heat from 
vj when the path length from vj to vi is shorter vi will 
receive more heat from vj and when the pipe connecting 
vj and vi is wide the heat will flow quickly the final heat 
that vi receives will depend on various paths from vj to vi 
their length and the width of the pipes 
algorithm diffusionrank function 
input the transition matrix a the inverse transition 
matrix u the decay factor αi for the inverse pagerank the 
decay factor αb for pagerank number of iterations mi for 
the inverse pagerank the number of trusted pages l the 
thermal conductivity coefficient γ 
output diffusionrank score vector h 
 s 
 for i to mi do 
 s αi · u · s − αi · 
n 
· 
 end for 
 sort s in a decreasing order π rank n s 
 d count i 
 while count ≤ l do 
 if π i is evaluated as a trusted page then 
 d π i count 
 end if 
 i 
 end while 
 d d d 
 h d 
 find the iteration number mb according to λ 
 for i to mb do 
 h − γ 
mb 
 h γ 
mb 
 αb · a · h − αb · 
n 
· 
 end for 
 return h 
 algorithm 
for the ranking task we adopt the heat kernel on a 
random graph formally the diffusionrank is described in 
algorithm in which the element uij in the inverse transition 
matrix u is defined to be ij if there is a link from i to j 
and otherwise this trusted pages selection procedure by 
inverse pagerank is completely borrowed from trustrank 
 except for a fix number of the size of the trusted set 
although the inverse pagerank is not perfect in its 
ability of determining the maximum coverage it is appealing 
because of its polynomial execution time and its 
reasonable intuition-we actually inverse the original link when 
we try to build the seed set from those pages that point 
to many pages that in turn point to many pages and so 
on in the algorithm the underlying random graph is set as 
p αb · a − αb · 
n 
· n×n which is induced by the 
web graph as a result r −i p 
in fact the more general setting for diffusionrank is p 
αb ·a −αb · 
n 
·g· t 
 by such a setting diffusionrank 
is a generalization of trustrank when γ tends to infinity 
and when g is set in the same way as trustrank however 
the second part of trustrank is not adopted by us in our 
model g should be the true teleportation determined by 
the user s browse habits popularity distribution over all the 
web pages and so on p should be the true model of the 
random nature of the world wide web setting g according 
to the trusted pages will not be consistent with the basic idea 
of heat diffusion on a random graph we simply set g 
only because we cannot find it without any priori knowledge 
remark in a social network interpretation 
diffusionrank first recognizes a group of trusted people who may 
not be highly ranked but they know many other people 
the initially trusted people are endowed with the power to 
decide who can be further trusted but cannot decide the 
final voting results and so they are not dictators 
 advantages 
next we show the four advantages for diffusionrank 
 two closed forms 
first its solutions have two forms both of which are 
closed form one takes the discrete form and has the 
advantage of fast computing while the other takes the continuous 
form and has the advantage of being easily analyzed in 
theoretical aspects the theoretical advantage has been shown 
in the proof of theorem in the next section 
 a group to group relations b an undirected graph 
figure two graphs 
 group-group relations 
second it can be naturally employed to detect the 
groupgroup relation for example let g and g denote two 
groups containing pages j j js and i i it 
respectively then u v hiu jv is the total amounts of heat 
that g receives from g where hiu jv is the iu−th row 
jv−th column element of the heat kernel more specifically 
we need to first set f for such an application as follows 
in f f f fn t 
 if i ∈ j j js 
then fi and otherwise then we employ eq 
to calculate f f f fn t 
 finally we sum 
those fj where j ∈ i i it fig a shows the 
results generated by the diffusionrank we consider five 
groups-five departments in our engineering faculty cse 
mae ee ie and se γ is set to be the numbers in 
fig a are the amount of heat that they diffuse to each 
other these results are normalized by the total number of 
each group and the edges are ignored if the values are less 
than the group-to-group relations are therefore 
detected for example we can see that the most strong 
overall tie is from ee to ie while it is a natural application 
for diffusionrank because of the easy interpretation by the 
amount heat from one group to another group it is difficult 
to apply other ranking techniques to such an application 
because they lack such a physical meaning 
 graph cut 
third it can be used to partition the web graph into 
several parts a quick example is shown below the graph 
in fig b is an undirected graph and so we employ the 
eq if we know that node belongs to one 
community and that node belongs to another community then 
we can put one unit positive heat source on node and 
one unit negative heat source on node after time if 
we set γ the heat distribution is 
 - - - - - and if 
we set γ it will be 
 - - - - - in both settings we 
can easily divide the graph into two parts 
with positive temperatures and with 
negative temperatures for directed graphs and random graphs 
similarly we can cut them by employing corresponding heat 
solution 
 anti-manipulation 
fourth it can be used to combat manipulation let g 
contain trusted web pages j j js then for each page 
i v hi jv is the heat that page i receives from g and can 
be computed by the discrete approximation of eq in 
the case of a static graph or eq in the case of a random 
graph in which f is set to be a special initial heat 
distribution so that the trusted web pages have unit heat while 
all the others have zero heat in doing so manipulated web 
page will get a lower rank unless it has strong in-links from 
the trusted web pages directly or indirectly the situation 
is quite different for pagerank because pagerank is 
inputindependent as we have shown in section based on the 
fact that the connection from a trusted page to a bad page 
should be weak-less uncross paths longer distance and 
narrower pipe we can say diffusionrank can resist web spam if 
we can select trusted pages it is fortunate that the trusted 
pages selection method in -the first part of trustrank can 
help us to fulfill this task for such an application of 
diffusionrank the computation complexity for discrete 
diffusion kernel is the same as that for pagerank in cases of 
both a static graph and a random graph this can be seen 
in eq by which we need n iterations and for each 
iteration we need a multiplication operation between a matrix 
and a vector while in eq we also need a multiplication 
operation between a matrix and a vector for each iteration 
 the physical meaning of γ 
γ plays an important role in the anti-manipulation effect 
of diffusionrank γ is the thermal conductivity-the heat 
diffusion coefficient if it has a high value heat will 
diffuse very quickly conversely if it is small heat will diffuse 
slowly in the extreme case if it is infinitely large then heat 
will diffuse from one node to other nodes immediately and 
this is exactly the case corresponding to pagerank next 
we will interpret it mathematically 
theorem when γ tends to infinity and f is not the 
zero vector eγr 
f is proportional to the stable distribution 
produced by pagerank 
let g 
n 
 by the perron theorem we have shown 
that is the largest eigenvalue of p − α g t 
 αa 
and that no other eigenvalue whose absolute value is equal 
to let x be the stable distribution and so px x x is 
the eigenvector corresponding to the eigenvalue assume 
the n − other eigenvalues of p are λ λn 
we can find an invertible matrix s x s such that 
s− 
ps 
 
 
 
 
 
 
 λ 
 
 
 λn 
 
 
 
 
 
 
since eγr 
 eγ −i p 
 
s− 
 
 
 
 
 
 
 eγ λ − 
 
 
 
 eγ λn− 
 
 
 
 
 
s 
all eigenvalues of the matrix eγr 
are eγ λ − 
 eγ λn− 
 
when γ → ∞ they become which means that is 
the only nonzero eigenvalue of eγr 
when γ → ∞ we can see 
that when γ → ∞ eγr 
eγr 
f eγr 
f and so eγr 
f 
is an eigenvector of eγr 
when γ → ∞ on the other hand 
eγr 
x i γr γ 
 
r 
 γ 
 
r 
 x ix γrx γ 
 
r 
x 
γ 
 
r 
x x since rx −i p x −x x 
and hence x is the eigenvector of eγr 
for any γ therefore 
both x and eγr 
f are the eigenvectors corresponding the 
unique eigenvalue of eγr 
when γ → ∞ and consequently 
x ceγr 
f 
by this theorem we see that diffusionrank is a 
generalization of pagerank when γ the ranking value is 
most robust to manipulation since no heat is diffused and 
the system is unchangeable but the web structure is 
completely ignored since eγr 
f e r 
f if f 
when γ ∞ diffusionrank becomes pagerank it can be 
manipulated easily we expect an appropriate setting of 
γ that can balance both for this we have no theoretical 
result but in practice we find that γ works well in 
section next we discuss how to determine the number of 
iterations if we employ the discrete heat kernel 
 the number of iterations 
while we enjoy the advantage of the concise form of the 
exponential heat kernel it is better for us to calculate 
diffusionrank by employing eq in an iterative way then 
the problem about determining n-the number of iterations 
arises 
for a given threshold find n such that i γ 
n 
r n 
− 
eγr 
 f for any f whose sum is one 
since it is difficult to solve this problem we propose a 
heuristic motivated by the following observations when 
r −i p by eq we have i γ 
n 
r n 
 i γ 
n 
 −i 
p n 
 
s− 
 
 
 
 
 
 
 γ λ − 
n 
 n 
 
 
 
 γ λn− 
n 
 n 
 
 
 
 
 
s 
comparing eq and eq we observe that the 
eigenvalues of i γ 
n 
r n 
− eγr 
are γ λn− 
n 
 n 
− eγ λn− 
 
we propose a heuristic method to determine n so that the 
difference between the eigenvalues are less than a threshold 
for only positive λs 
we also observe that if γ λ then γ λ− 
n 
 n 
− 
eγ λ− 
 if n ≥ and γ λ− 
n 
 n 
−eγ λ− 
 
 if n ≥ so we can set n or n or others 
according to different accuracy requirements in this paper 
we use the relatively accurate setting n to make the 
real eigenvalues in i γ 
n 
r n 
− eγr 
less than 
 experiments 
in this section we show the experimental data the 
methodology the setting and the results 
 data preparation 
our input data consist of a toy graph a middle-size 
realworld graph and a large-size real-world graph the toy 
graph is shown in fig a the graph below it shows node 
 is being manipulated by adding new nodes a b c 
such that they all point to node and node points to 
them all the data of two real web graph were obtained 
from the domain in our institute in october the 
total number of pages found are in the middle-size 
graph and in the large-size graph respectively the 
middle-size graph is a subgraph of the large-size graph and 
they were obtained by the same crawler one is recorded 
by the crawler in its earlier time and the other is obtained 
when the crawler stopped 
 methodology 
the algorithms we run include pagerank trustrank and 
diffusionrank all the rank values are multiplied by the 
number of nodes so that the sum of the rank values is equal 
to the number of nodes by this normalization we can 
compare the results on graphs with different sizes since the 
average rank value is one for any graph after such normalization 
we will need value difference and pairwise order difference as 
comparison measures their definitions are listed as follows 
value difference the value difference between a 
 ai n 
i and b bi n 
i is measured as n 
i ai − bi 
pairwise order difference the order difference between 
a and b is measured as the number of significant order 
differences between a and b the pair a i a j and 
 b i b j is considered as a significant order difference if 
one of the following cases happens both a i a j 
and b i ≤ ≥ a j both a i ≤ ≥ a j and b i 
 a j 
a 
 
b 
c 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
gamma 
valuedifference 
trust set 
trust set 
trust set 
trust set 
trust set 
trust set 
 a b 
figure a the toy graph consisting of six nodes 
and node is being manipulated by adding new 
nodes a b c b the approximation tendency to 
pagerank by diffusionrank 
 experimental set-up 
the experiments on the middle-size graph and the 
largesize graphs are conducted on the workstation whose 
hardware model is nix dual intel xeon ghz with gb ram 
and a linux kernel - smp redhat in 
calculating diffusionrank we employ eq and the discrete 
approximation of eq for such graphs the related tasks 
are implemented using c language while in the toy graph 
we employ the continuous diffusion kernel in eq and 
eq and implement related tasks using matlab 
for nodes that have zero out-degree dangling nodes we 
employ the method in the modified pagerank algorithm 
in which dangling nodes of are considered to have random 
links uniformly to each node we set α αi αb in 
all algorithms we also set g to be the uniform distribution 
in both pagerank and diffusionrank for diffusionrank 
we set γ according to the discussions in section and 
section we set the iteration number to be mb in 
diffusionrank and for accuracy consideration the iteration 
number in all the algorithms is set to be 
 approximation of pagerank 
we show that when γ tends to infinity the value 
differences between diffusionrank and pagerank tend to zero 
fig b shows the approximation property of 
diffusionrank as proved in theorem on the toy graph the 
horizontal axis of fig b marks the γ value and vertical axis 
corresponds to the value difference between diffusionrank 
and pagerank all the possible trusted sets with l 
are considered for l the results should be the linear 
combination of some of these curves because of the 
linearity of the solutions to heat equations on other graphs the 
situations are similar 
 results of anti-manipulation 
in this section we show how the rank values change as the 
intensity of manipulation increases we measure the 
intensity of manipulation by the number of newly added points 
that point to the manipulated point the horizontal axes 
of fig stand for the numbers of newly added points and 
vertical axes show the corresponding rank values of the 
manipulated nodes to be clear we consider all six situations 
every node in fig a is manipulated respectively and its 
 
 
 
 
 
 
 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
 
 
 
 
 
 
 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
 
 
 
 
 
 
 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
 
 
 
 
 
 
 
number of new added nodes 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
 
 
 
 
 
 
 
number of new added nodes 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
 
 
 
 
 
 
 
number of new added nodes 
rankofthemanipulatdnode− 
diffusionrank−trust 
pagerank 
trustranl−trust 
figure the rank values of the manipulated nodes 
on the toy graph 
 
 
 
 
 
 
 
 
 
 
number of new added points 
rankofthemanipulatdnode 
pagerank 
diffusionrank−uniform 
diffusionrank 
diffusionrank 
diffusionrank 
diffusionrank 
trustrank 
trustrank 
trustrank 
trustrank 
 
 
 
 
 
 
 
 
 
 
 
number of new added points 
rankofthemanipulatdnode 
pagerank 
diffusionrank 
trustrank 
diffusionrank−uniform 
 a b 
figure a the rank values of the manipulated 
nodes on the middle-size graph b the rank values 
of the manipulated nodes on the large-size graph 
corresponding values for pagerank trustrank tr 
diffusionrank dr are shown in the one of six sub-figures in 
fig the vertical axes show which node is being 
manipulated in each sub-figure the trusted sets are 
computed below since the inverse pagerank yields the results 
 let l if the 
manipulated node is not then the trusted set is and 
otherwise we observe that in all the cases rank values 
of the manipulated node for diffusionrank grow slowest as 
the number of the newly added nodes increases on the 
middle-size graph and the large-size graph this conclusion 
is also true see fig note that in fig a we choose 
four trusted sets l on which we test diffusionrank 
and trustrank the results are denoted by diffusionranki 
and trustranki i denotes the four trusted set 
in fig b we choose one trusted set l moreover 
in both fig a and fig b we show the results for 
diffusionrank when we have no trusted set and we trust 
all the pages before some of them are manipulated 
we also test the order difference between the ranking 
order a before the page is manipulated and the ranking order 
pa after the page is manipulated because after 
manipulation the number of pages changes we only compare the 
common part of a and pa this experiment is used to test 
the stability of all these algorithms the less the order 
difference the stabler the algorithm in the sense that only a 
smaller part of the order relations is affected by the 
manipulation figure a shows that the order difference values 
change when we add new nodes that point to the 
manipulated node we give several γ settings we find that when 
γ the least order difference is achieved by 
diffusionrank it is interesting to point out that as γ increases the 
order difference will increase first after reaching a maximum 
value it will decrease and finally it tends to the pagerank 
results we show this tendency in fig b in which we 
choose three different settings-the number of manipulated 
nodes are and respectively from these 
figures we can see that when γ the values are less than 
those for pagerank and that when γ the difference 
between pagerank and diffusionrank is very small 
after these investigations we find that in all the graphs we 
tested diffusionrank when γ is most robust to 
manipulation both in value difference and order difference the 
trust set selection algorithm proposed in is effective for 
both trustrank and diffusionrank 
 
 
 
 
 
 
 
 
x 
 
number of new added points 
pairwiseorderdifference 
pagerank 
diffusionrank−gamma 
diffusionrank−gamma 
diffusionrank−gamma 
diffusionrank−gamma 
diffusionrank−gamma 
diffusionrank−gamma 
trustrank 
 
 
 
 
 
 
 
x 
 
gamma 
pairwiseorderdifference 
diffusionrank when added nodes 
diffusionrank when added nodes 
diffusionrank when added nodes 
pagerank 
 a b 
figure a pairwise order difference on the 
middle-size graph the least it is the more stable 
the algorithm b the tendency of varying γ 
 conclusions 
we conclude that diffusionrank is a generalization of 
pagerank which is interesting in that the heat diffusion 
coefficient γ can balance the extent that we want to model the 
original web graph and the extent that we want to reduce 
the effect of link manipulations the experimental results 
show that we can actually achieve such a balance by 
setting γ although the best setting including varying γi 
is still under further investigation this anti-manipulation 
feature enables diffusionrank to be a candidate as a 
penicillin for web spamming moreover diffusionrank can be 
employed to find group-group relations and to partition web 
graph into small communities all these advantages can be 
achieved in the same computational complexity as 
pagerank for the special application of anti-manipulation 
diffusionrank performs best both in reduction effects and in 
its stability among all the three algorithms 
 acknowledgments 
we thank patrick lau zhenjiang lin and zenglin xu 
for their help this work is fully supported by two grants 
from the research grants council of the hong kong special 
administrative region china project no cuhk e 
and project no cuhk e 
 references 
 e agichtein e brill and s t dumais improving web search 
ranking by incorporating user behavior information in e n 
efthimiadis s t dumais d hawking and k j¨arvelin 
editors proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval sigir pages - 
 r a baeza-yates p boldi and c castillo generalizing 
pagerank damping functions for link-based ranking 
algorithms in e n efthimiadis s t dumais d hawking 
and k j¨arvelin editors proceedings of the th annual 
international acm sigir conference on research and 
development in information retrieval sigir pages 
 - 
 m belkin and p niyogi laplacian eigenmaps for 
dimensionality reduction and data representation neural 
computation - jun 
 b bollob´as random graphs academic press inc london 
 
 c burges t shaked e renshaw a lazier m deeds 
n hamilton and g hullender learning to rank using 
gradient descent in proceedings of the nd international 
conference on machine learning icml pages - 
 n eiron k s mccurley and j a tomlin ranking the web 
frontier in proceeding of the th world wide web 
conference www pages - 
 z gy¨ongyi h garcia-molina and j pedersen combating 
web spam with trustrank in m a nascimento m t ¨ozsu 
d kossmann r j miller j a blakeley and k b schiefer 
editors proceedings of the thirtieth international conference 
on very large data bases vldb pages - 
 s d kamvar t h haveliwala c d manning and g h 
golub exploiting the block structure of the web for computing 
pagerank technical report stanford university 
 r i kondor and j d lafferty diffusion kernels on graphs 
and other discrete input spaces in c sammut and a g 
hoffmann editors proceedings of the nineteenth 
international conference on machine learning icml 
pages - 
 j lafferty and g lebanon diffusion kernels on statistical 
manifolds journal of machine learning research - 
jan 
 c r maccluer the many proofs and applications of perron s 
theorem siam review - 
 a ntoulas m najork m manasse and d fetterly detecting 
spam web pages through content analysis in proceedings of 
the th international conference on world wide web 
 www pages - 
 l page s brin r motwani and t winograd the pagerank 
citation ranking bringing order to the web technical report 
paper sidl-wp- - version of stanford 
digital library technologies project 
 h yang i king and m r lyu nhdc and phdc 
non-propagating and propagating heat diffusion classifiers in 
proceedings of the th international conference on neural 
information processing iconip pages - 
 h yang i king and m r lyu predictive ranking a novel 
page ranking approach by estimating the web structure in 
proceedings of the th international conference on world 
wide web www - special interest tracks and posters 
pages - 
 h yang i king and m r lyu predictive random graph 
ranking on the web in proceedings of the ieee world 
congress on computational intelligence wcci pages 
 - 
 d zhou j weston a gretton o bousquet and 
b sch¨olkopf ranking on data manifolds in s thrun l saul 
and b sch¨olkopf editors advances in neural information 
processing systems nips 
