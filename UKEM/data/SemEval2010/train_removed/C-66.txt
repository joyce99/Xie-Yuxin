heuristics-based scheduling of 
composite web service workloads 
thomas phan wen-syan li 
ibm almaden research center 
 harry rd 
san jose ca 
 phantom wsl  us ibm com 
abstract 
web services can be aggregated to create composite workflows that 
provide streamlined functionality for human users or other systems 
although industry standards and recent research have sought to 
define best practices and to improve end-to-end workflow 
composition one area that has not fully been explored is the scheduling 
of a workflow s web service requests to actual service 
provisioning in a multi-tiered multi-organisation environment this issue 
is relevant to modern business scenarios where business processes 
within a workflow must complete within qos-defined limits 
because these business processes are web service consumers service 
requests must be mapped and scheduled across multiple web 
service providers each with its own negotiated service level 
agreement in this paper we provide heuristics for scheduling service 
requests from multiple business process workflows to web service 
providers such that a business value metric across all workflows is 
maximised we show that a genetic search algorithm is appropriate 
to perform this scheduling and through experimentation we show 
that our algorithm scales well up to a thousand workflows and 
produces better mappings than traditional approaches 
categories and subject descriptors 
c computer-communication networks distributed 
systems-distributed applications d software engineering 
metrics-complexity measures performance measures 
 introduction 
web services can be composed into workflows to provide 
streamlined end-to-end functionality for human users or other systems 
although previous research efforts have looked at ways to 
intelligently automate the composition of web services into workflows 
 e g an important remaining problem is the assignment of 
web service requests to the underlying web service providers in a 
multi-tiered runtime scenario within constraints in this paper we 
address this scheduling problem and examine means to manage a 
large number of business process workflows in a scalable manner 
the problem of scheduling web service requests to providers is 
relevant to modern business domains that depend on multi-tiered 
service provisioning consider the example shown in figure 
that illustrates our problem space workflows comprise multiple 
related business processes that are web service consumers here we 
assume that the workflows represent requested service from 
customers or automated systems and that the workflow has already 
been composed with an existing choreography toolkit these 
workflows are then submitted to a portal not shown that acts as a 
scheduling agent between the web service consumers and the web 
service providers 
in this example a workflow could represent the actions needed to 
instantiate a vacation itinerary where one business process requests 
booking an airline ticket another business process requests a hotel 
room and so forth each of these requests target a particular service 
type e g airline reservations hotel reservations car reservations 
etc and for each service type there are multiple instances of 
service providers that publish a web service interface an important 
challenge is that the workflows must meet some quality-of-service 
 qos metric such as end-to-end completion time of all its business 
processes and that meeting or failing this goal results in the 
assignment of a quantitative business value metric for the workflow 
intuitively it is desired that all workflows meet their respective qos 
goals we further leverage the notion that qos service agreements 
are generally agreed-upon between the web service providers and 
the scheduling agent such that the providers advertise some level 
of guaranteed qos to the scheduler based upon runtime conditions 
such as turnaround time and maximum available concurrency the 
resulting problem is then to schedule and assign the business 
processes requests for service types to one of the service providers 
for that type the scheduling must be done such that the aggregate 
business value across all the workflows is maximised 
in section we state the scenario as a combinatorial problem and 
utilise a genetic search algorithm to find the best assignment 
of web service requests to providers this approach converges 
towards an assignment that maximises the overall business value for 
all the workflows 
in section we show through experimentation that this search 
heuristic finds better assignments than other algorithms greedy 
round-robin and proportional further this approach allows us to 
scale the number of simultaneous workflows up to one thousand 
workflows in our experiments and yet still find effective schedules 
 related work 
in the context of service assignment and scheduling maps 
web service calls to potential servers using linear programming but 
their work is concerned with mapping only single workflows our 
principal focus is on scalably scheduling multiple workflows up 
 
service type 
superhotels com 
business 
process 
business 
process 
workflow 
 
business 
process 
business 
process 
 
hostilehostels com 
incredibleinns com 
business 
process 
business 
process 
business 
process 
 
business 
process 
service 
provider 
skyhighairlines com 
supercrazyflights com 
business 
process 
 
 
 
 
 
 
advertised qos 
service agreement 
carrentalservice com 
figure an example scenario demonstrating the interaction between business processes in workflows and web service providers 
each business process accesses a service type and is then mapped to a service provider for that type 
to one thousand as we show later using different business 
metrics and a search heuristic presents a dynamic 
provisioning approach that uses both predictive and reactive techniques for 
multi-tiered internet application delivery however the 
provisioning techniques do not consider the challenges faced when there are 
alternative query execution plans and replicated data sources 
presents a feedback-based scheduling mechanism for multi-tiered 
systems with back-end databases but unlike our work it assumes 
a tighter coupling between the various components of the system 
our work also builds upon prior scheduling research the classic 
job-shop scheduling problem shown to be np-complete is 
similar to ours in that tasks within a job must be scheduled onto 
machinery c f our scenario is that business processes within a 
workflow must be scheduled onto web service providers the salient 
differences are that the machines can process only one job at a time 
 we assume servers can multi-task but with degraded performance 
and a maximum concurrency level tasks within a job cannot 
simultaneously run on different machines we assume business 
processes can be assigned to any available server and the principal 
metric of performance is the makespan which is the time for the 
last task among all the jobs to complete and as we show later 
optimising on the makespan is insufficient for scheduling the business 
processes necessitating different metrics 
 design 
in this section we describe our model and discuss how we can 
find scheduling assignments using a genetic search algorithm 
 model 
we base our model on the simplified scenario shown in figure 
 specifically we assume that users or automated systems request 
the execution of a workflow the workflows comprise business 
processes each of which makes one web service invocation to a 
service type further business processes have an ordering in the 
workflow the arrangement and execution of the business processes and 
the data flow between them are all managed by a composition or 
choreography tool e g although composition languages 
can use sophisticated flow-control mechanisms such as conditional 
branches for simplicity we assume the processes execute 
sequentially in a given order 
this scenario can be naturally extended to more complex 
relationships that can be expressed in bpel which defines how 
business processes interact messages are exchanged activities are 
ordered and exceptions are handled due to space constraints 
we focus on the problem space presented here and will extend our 
model to more advanced deployment scenarios in the future 
each workflow has a qos requirement to complete within a 
specified number of time units e g on the order of seconds as 
detailed in the experiments section upon completion or failure 
the workflow is assigned a business value we extended this 
approach further and considered different types of workflow 
completion in order to model differentiated qos levels that can be applied 
by businesses for example to provide tiered customer service 
we say that a workflow is successful if it completes within its qos 
requirement acceptable if it completes within a constant factor κ 
 
of its qos bound in our experiments we chose κ or failing 
if it finishes beyond κ times its qos bound for each category 
a business value score is assigned to the workflow with the 
successful category assigned the highest positive score followed by 
acceptable and then failing the business value point 
distribution is non-uniform across workflows further modelling cases 
where some workflows are of higher priority than others 
each service type is implemented by a number of different 
service providers we assume that the providers make service level 
agreements slas to guarantee a level of performance defined by 
the completion time for completing a web service invocation 
although slas can be complex in this paper we assume for 
simplicity that the guarantees can take the form of a linear performance 
degradation under load this guarantee is defined by several 
parameters α is the expected completion time for example on the 
order of seconds if the assigned workload of web service requests 
is less than or equal to β the maximum concurrency and if the 
workload is higher than β the expected completion for a workload 
of size ω is α γ ω − β where γ is a fractional coefficient in our 
experiments we vary α β and γ with different distributions 
ideally all workflows would be able to finish within their qos 
limits and thus maximise the aggregate business value across all 
workflows however because we model service providers with 
degrading performance under load not all workflows will achieve 
their qos limit it may easily be the case that business processes 
are assigned to providers who are overloaded and cannot complete 
within the respective workflow s qos limit the key research 
problem then is to assign the business processes to the web service 
providers with the goal of optimising on the aggregate business 
value of all workflows 
given that the scope of the optimisation is the entire set of 
workflows it may be that the best scheduling assignments may result in 
some workflows having to fail in order for more workflows to 
succeed this intuitive observation suggests that traditional scheduling 
approaches such as round-robin or proportional assignments will 
not fare well which is what we observe and discuss in section 
on the other hand an exhaustive search of all the possible 
assignments will find the best schedule but the computational complexity 
is prohibitively high suppose there are w workflows with an 
average of b business processes per workflow further in the worst 
case each business process requests one service type for which 
there are p providers there are thus w · pb 
combinations to 
explore to find the optimal assignments of business processes to 
providers even for small configurations e g w b p 
the computational time for exhaustive search is significant and in 
our work we look to scale these parameters in the next subsection 
discuss how a genetic search algorithm can be used to converge 
toward the optimum scheduling assignments 
 genetic algorithm 
given an exponential search space of business process 
assignments to web service providers the problem is to find the optimal 
assignment that produces the overall highest aggregate business 
value across all workflows to explore the solution space we use 
a genetic algorithm ga search heuristic that simulates darwinian 
natural selection by having members of a population compete to 
survive in order to pass their genetic chromosomes onto the next 
generation after successive generations there is a tendency for the 
chromosomes to converge toward the best combination 
although other search heuristics exist that can solve 
optimization problems e g simulated annealing or steepest-ascent 
hillclimbing the business process scheduling problem fits well with a 
ga because potential solutions can be represented in a matrix form 
and allows us to use prior research in effective ga chromosome 
recombination to form new members of the population e g 
 
 
 
 
figure an example chromosome representing a scheduling 
assignment of workflow service type → service provider each 
row represents a workflow and each column represents a 
service type for example here there are workflows to and 
 service types to in workflow any request for service 
type goes to provider note that the service provider 
identifier is within a range limited to its service type i e its column 
so the listed for service type is a different server from 
server in other columns 
chromosome representation of a solution in figure we 
show an example chromosome that encodes one scheduling 
assignment the representation is a -dimensional matrix that maps 
 workflow service type to a service provider for a business 
process in workflow i and utilising service type j the i j th 
entry in 
the table is the identifier for the service provider to which the 
business process is assigned note that the service provider identifier is 
within a range limited to its service type 
ga execution a ga proceeds as follows initially a random 
set of chromosomes is created for the population the 
chromosomes are evaluated hashed to some metric and the best ones 
are chosen to be parents in our problem the evaluation produces 
the net business value across all workflows after executing all 
business processes once they are assigned to their respective service 
providers according to the mapping in the chromosome the 
parents recombine to produce children simulating sexual crossover 
and occasionally a mutation may arise which produces new 
characteristics that were not available in either parent the principal idea 
is that we would like the children to be different from the parents 
 in order to explore more of the solution space yet not too 
different in order to contain the portions of the chromosome that result 
in good scheduling assignments note that finding the global 
optimum is not guaranteed because the recombination and mutation 
are stochastic 
ga recombination and mutation as mentioned the 
chromosomes are -dimensional matrices that represent scheduling 
assignments to simulate sexual recombination of two chromosomes to 
produce a new child chromosome we applied a one-point crossover 
scheme twice once along each dimension the crossover is best 
explained by analogy to cartesian space as follows a random 
point is chosen in the matrix to be coordinate matrix 
elements from quadrants ii and iv from the first parent and elements 
from quadrants i and iii from the second parent are used to create 
the new child this approach follows ga best practices by keeping 
contiguous chromosome segments together as they are transmitted 
from parent to child 
the uni-chromosome mutation scheme randomly changes one 
of the service provider assignments to another provider within the 
available range other recombination and mutation schemes are an 
area of research in the ga community and we look to explore new 
operators in future work 
ga evaluation function an important ga component is the 
evaluation function given a particular chromosome representing 
one scheduling mapping the function deterministically calculates 
the net business value across all workloads the business 
processes in each workload are assigned to service providers and each 
provider s completion time is calculated based on the service 
agreement guarantee using the parameters mentioned in section 
namely the unloaded completion time α the maximum 
concur 
rency β and a coefficient γ that controls the linear performance 
degradation under heavy load note that the evaluation function 
can be easily replaced if desired for example other evaluation 
functions can model different service provider guarantees or 
parallel workflows 
 experiments and results 
in this section we show the benefit of using our ga-based 
scheduler because we wanted to scale the scenarios up to a large number 
of workflows up to in our experiments we implemented a 
simulation program that allowed us to vary parameters and to 
measure the results with different metrics the simulator was written 
in standard c and was run on a linux fedora core desktop 
computer running at ghz with gb of ram 
we compared our algorithm against alternative candidates 
 a well-known round-robin algorithm that assigns each 
business process in circular fashion to the service providers for a 
particular service type this approach provides the simplest 
scheme for load-balancing 
 a random-proportional algorithm that proportionally assigns 
business processes to the service providers that is for a 
given service type the service providers are ranked by their 
guaranteed completion time and business processes are 
assigned proportionally to the providers based on their 
completion time we also tried a proportionality scheme based 
on both the completion times and maximum concurrency but 
attained the same results so only the former scheme s results 
are shown here 
 a strawman greedy algorithm that always assigns business 
processes to the service provider that has the fastest 
guaranteed completion time this algorithm represents a naive 
approach based on greedy local observations of each workflow 
without taking into consideration all workflows 
in the experiments that follow all results were averaged across 
 trials and to help normalise the effects of randomisation used 
during the ga each trial started by reading in pre-initialised data 
from disk in table we list our experimental parameters 
in figure we show the results of running our ga against the 
three candidate alternatives the x-axis shows the number for 
workflows scaled up to and the y-axis shows the aggregate 
business value for all workflows as can be seen the ga consistently 
produces the highest business value even as the number of 
workflows grows at workflows the ga produces a 
improvement over the next-best alternative note that although we 
are optimising against the business value metric we defined earlier 
genetic algorithms are able to converge towards the optimal value 
of any metric as long as the evaluation function can consistently 
measure a chromosome s value with that metric 
as expected the greedy algorithm performs very poorly because 
it does the worst job at balancing load all business processes for 
a given service type are assigned to only one server the one 
advertised to have the fastest completion time and as more 
business processes arrive the provider s performance degrades linearly 
the round-robin scheme is initially outperformed by the 
randomproportional scheme up to around workflows as shown in the 
magnified graph of figure but as the number of workflows 
increases the round-robin scheme consistently wins over 
randomproportional the reason is that although the random-proportional 
scheme assigns business processes to providers proportionally 
according to the advertised completion times which is a measure of 
the power of the service provider even the best providers will 
eventually reach a real-world maximum concurrency for the large 
- 
- 
 
 
 
 
 
 
 
 
 
aggregatebusinessvalueacrossallworkflows 
total number of workflows 
business value scores of scheduling algorithms 
genetic algorithm 
round robin 
random proportional 
greedy 
figure net business value scores of different scheduling algorithms 
- 
 
 
 
 
 
 
 
 
 
 aggregatebusinessvalueacrossallworkflows 
total number of workflows 
business value scores of scheduling algorithms 
genetic algorithm 
round robin 
random proportional 
greedy 
figure magnification of the left-most region in figure 
number of workflows that we are considering for a very large 
number of workflows the round-robin scheme is able to better 
balance the load across all service providers 
to better understand the behaviour resulting from the scheduling 
assignments we show the workflow completion results in figures 
 and for and workflows respectively these 
figures show the percentage of workflows that are successful can 
complete with their qos limit acceptable can complete within 
κ times their qos limit and failed cannot complete within κ 
times their qos limit the ga consistently produces the highest 
percentage of successful workflows resulting in higher business 
values for the aggregate set of workflows further the round-robin 
scheme produces better results than the random-proportional for a 
large number of workflows but does not perform as well as the ga 
in figure we graph the makespan resulting from the same 
experiments above makespan is a traditional metric from the job 
scheduling community measuring elapsed time for the last job to 
complete while useful it does not capture the high-level business 
value metric that we are optimising against indeed the makespan 
is oblivious to the fact that we provide multiple levels of 
completion successful acceptable and failed and assign business value 
scores accordingly for completeness we note that the ga 
provides the fastest makespan but it is matched by the round robin 
algorithm the ga produces better business values as shown in 
figure because it is able to search the solution space to find 
better mappings that produce more successful workflows as shown in 
figures to 
we also looked at the effect of the scheduling algorithms on 
balancing the load figure shows the percentage of services 
providers that were accessed while the workflows ran as expected 
the greedy algorithm always hits one service provider on the other 
hand the round-robin algorithm is the fastest to spread the business 
 
experimental parameter comment 
workflows to 
business processes per workflow uniform random - 
service types 
service providers per service type uniform random - 
workflow qos goal uniform random - seconds 
service provider completion time α uniform random - seconds 
service provider maximum concurrency β uniform random - 
service provider degradation coefficient γ uniform random - 
business value for successful workflows uniform random - points 
business value for acceptable workflows uniform random - points 
business value for failed workflows uniform random - - points 
ga number of parents 
ga number of children 
ga number of generations 
table experimental parameters 
failed 
acceptable completed but not within qos 
successful completed within qos 
 
 
 
 
 
 
roundrobinrandproportionalgreedygeneticalg 
percentageofallworkflows 
workflow behaviour workflows 
figure workflow behaviour for workflows 
failed 
acceptable completed but not within qos 
successful completed within qos 
 
 
 
 
 
 
roundrobinrandproportionalgreedygeneticalg 
percentageofallworkflows 
workflow behaviour workflows 
figure workflow behaviour for workflows 
failed 
acceptable completed but not within qos 
successful completed within qos 
 
 
 
 
 
 
roundrobinrandproportionalgreedygeneticalg 
percentageofallworkflows 
workflow behaviour workflows 
figure workflow behaviour for workflows 
 
 
 
 
 
 
 
 
makespan seconds 
number of workflows 
maximum completion time for all workflows 
genetic algorithm 
round robin 
random proportional 
greedy 
figure maximum completion time for all workflows this value 
is the makespan metric used in traditional scheduling research 
although useful the makespan does not take into consideration the 
business value scoring in our problem domain 
processes figure is the percentage of accessed service providers 
 that is the percentage of service providers represented in figure 
 that had more assigned business processes than their advertised 
maximum concurrency for example in the greedy algorithm only 
one service provider is utilised and this one provider quickly 
becomes saturated on the other hand the random-proportional 
algorithm uses many service providers but because business processes 
are proportionally assigned with more assignments going to the 
better providers there is a tendency for a smaller percentage of 
providers to become saturated 
for completeness we show the performance of the genetic 
algorithm itself in figure the algorithm scales linearly with an 
increasing number of workflows we note that the round-robin 
random-proportional and greedy algorithms all finished within 
second even for the largest workflow configuration however we 
feel that the benefit of finding much higher business value scores 
justifies the running time of the ga further we would expect that 
the running time will improve with both software tuning as well as 
with a computer faster than our off-the-shelf pc 
 conclusion 
business processes within workflows can be orchestrated to 
access web services in this paper we looked at multi-tiered service 
provisioning where web service requests to service types can be 
mapped to different service providers the resulting problem is 
that in order to support a very large number of workflows the 
assignment of business process to web service provider must be 
intelligent we used a business value metric to measure the 
be 
 
 
 
 
 
 
 
percentageofallserviceproviders 
number of workflows 
service providers utilised 
genetic algorithm 
round robin 
random proportional 
greedy 
figure the percentage of service providers utilized during 
workload executions the greedy algorithm always hits the one service 
provider while the round robin algorithm spreads requests evenly 
across the providers 
 
 
 
 
 
 
 
percentageofallserviceproviders 
number of workflows 
service providers saturated 
genetic algorithm 
round robin 
random proportional 
greedy 
figure the percentage of service providers that are saturated 
among those providers who were utilized that is percentage of the 
service providers represented in figure a saturated service provider 
is one whose workload is greater that its advertised maximum 
concurrency 
 
 
 
 
 
 
 
runningtimeinseconds 
total number of workflows 
running time of genetic algorithm 
ga running time 
figure running time of the genetic algorithm 
haviour of workflows meeting or failing qos values and we 
optimised our scheduling to maximise the aggregate business value 
across all workflows since the solution space of scheduler 
mappings is exponential we used a genetic search algorithm to search 
the space and converge toward the best schedule with a default 
configuration for all parameters and using our business value 
scoring the ga produced up to business value improvement over 
the next best algorithm finally because a genetic algorithm will 
converge towards the optimal value using any metric even other 
than the business value metric we used we believe our approach 
has strong potential for continuing work 
in future work we look to acquire real-world traces of web 
service instances in order to get better estimates of service agreement 
guarantees although we expect that such guarantees between the 
providers and their consumers are not generally available to the 
public we will also look at other qos metrics such as cpu and 
i o usage for example we can analyse transfer costs with 
varying bandwidth latency data size and data distribution further 
we hope to improve our genetic algorithm and compare it to more 
scheduler alternatives finally since our work is complementary 
to existing work in web services choreography because we rely on 
pre-configured workflows we look to integrate our approach with 
available web service workflow systems expressed in bpel 
 references 
 a ankolekar et al daml-s semantic markup for web 
services in proc of the int l semantic web working 
symposium 
 l davis job shop scheduling with genetic algorithms 
in proc of the int l conference on genetic algorithms 
 h -l fang p ross and d corne a promising genetic 
algorithm approach to job-shop scheduling rescheduling 
and open-shop scheduling problems in proc on the th 
int l conference on genetic algorithms 
 m gary and d johnson computers and intractability a 
guide to the theory of np-completeness freeman 
 j holland adaptation in natural and artificial systems 
an introductory analysis with applications to biology 
control and artificial intelligence mit press 
 d goldberg genetic algorithms in search optimization 
and machine learning kluwer academic publishers 
 business processes in a web services world 
www- ibm com developerworks 
webservices library ws-bpelwp 
 g soundararajan k manassiev j chen a goel and c 
amza back-end databases in shared dynamic content 
server clusters in proc of the ieee int l conference on 
autonomic computing 
 b srivastava and j koehler web service composition 
current solutions and open problems icap 
 b urgaonkar p shenoy a chandra and p goyal 
dynamic provisioning of multi-tier internet applications 
in proc of the ieee int l conference on autonomic 
computing 
 l zeng b benatallah m dumas j kalagnanam and q 
sheng quality driven web services composition in 
proc of the www conference 
 
