a framework for agent-based distributed machine 
learning and data mining 
jan tozicka 
gerstner laboratory 
czech technical university 
technick a prague 
czech republic 
tozicka labe felk cvut cz 
michael rovatsos 
school of informatics 
the university of edinburgh 
edinburgh eh le 
united kingdom 
mrovatso inf ed ac uk 
michal pechoucek 
gerstner laboratory 
czech technical university 
technick a prague 
czech republic 
pechouc labe felk cvut cz 
abstract 
this paper proposes a framework for agent-based 
distributed machine learning and data mining based on i 
the exchange of meta-level descriptions of individual 
learning processes among agents and ii online reasoning about 
learning success and learning progress by learning agents 
we present an abstract architecture that enables agents to 
exchange models of their local learning processes and 
introduces a number of different methods for integrating these 
processes this allows us to apply existing agent 
interaction mechanisms to distributed machine learning tasks 
thus leveraging the powerful coordination methods available 
in agent-based computing and enables agents to engage in 
meta-reasoning about their own learning decisions we 
apply this architecture to a real-world distributed clustering 
application to illustrate how the conceptual framework can 
be used in practical systems in which different learners may 
be using different datasets hypotheses and learning 
algorithms we report on experimental results obtained using 
this system review related work on the subject and discuss 
potential future extensions to the framework 
general terms 
theory 
categories and subject descriptors 
i artificial intelligence distributed artificial 
intelligence-multiagent systems 
 introduction 
in the areas of machine learning and data mining cf 
 for overviews it has long been recognised that 
parallelisation and distribution can be used to improve learning 
performance various techniques have been suggested in 
this respect ranging from the low-level integration of 
independently derived learning hypotheses e g combining 
different classifiers to make optimal classification decisions 
 model averaging of bayesian classifiers or 
consensusbased methods for integrating different clusterings to 
the high-level combination of learning results obtained by 
heterogeneous learning agents using meta-learning e g 
 
all of these approaches assume homogeneity of agent 
design all agents apply the same learning algorithm and or 
agent objectives all agents are trying to cooperatively solve 
a single global learning problem therefore the techniques 
they suggest are not applicable in societies of autonomous 
learners interacting in open systems in such systems 
learners agents may not be able to integrate their datasets or 
learning results because of different data formats and 
representations learning algorithms or legal restrictions that 
prohibit such integration and cannot always be 
guaranteed to interact in a strictly cooperative fashion discovered 
knowledge and collected data might be economic assets that 
should only be shared when this is deemed profitable 
malicious agents might attempt to adversely influence others 
learning results etc 
examples for applications of this kind abound many 
distributed learning domains involve the use of sensitive data 
and prohibit the exchange of this data e g exchange of 
patient data in distributed brain tumour diagnosis - 
however they may permit the exchange of local learning 
hypotheses among different learners in other areas training 
data might be commercially valuable so that agents would 
only make it available to others if those agents could 
provide something in return e g in remote ship surveillance 
and tracking where the different agencies involved are 
commercial service providers furthermore agents might 
have a vested interest in negatively affecting other agents 
learning performance an example for this is that of 
fraudulent agents on ebay which may try to prevent 
reputationlearning agents from the construction of useful models for 
detecting fraud 
viewing learners as autonomous self-directed agents is 
the only appropriate view one can take in modelling these 
distributed learning environments the agent metaphor 
becomes a necessity as oppossed to preferences for scalability 
dynamic data selection interactivity which can also 
be achieved through non-agent distribution and 
parallelisation in principle 
despite the autonomy and self-directedness of learning 
agents many of these systems exhibit a sufficient overlap 
in terms of individual learning goals so that beneficial 
cooperation might be possible if a model for flexible 
interaction between autonomous learners was available that allowed 
agents to 
 exchange information about different aspects of their 
own learning mechanism at different levels of detail 
without being forced to reveal private information that 
should not be disclosed 
 decide to what extent they want to share information 
about their own learning processes and utilise 
information provided by other learners and 
 reason about how this information can best be used to 
improve their own learning performance 
our model is based on the simple idea that autonomous 
learners should maintain meta-descriptions of their own 
learning processes see also in order to be able to 
exchange information and reason about them in a rational way 
 i e with the overall objective of improving their own 
learning results our hypothesis is a very simple one 
if we can devise a sufficiently general abstract 
view of describing learning processes we will be 
able to utilise the whole range of methods for i 
rational reasoning and ii communication and 
coordination offered by agent technology so as to 
build effective autonomous learning agents 
to test this hypothesis we introduce such an abstract 
architecture section and implement a simple concrete 
instance of it in a real-world domain section we report 
on empirical results obtained with this implemented system 
that demonstrate the viability of our approach section 
finally we review related work section and conclude 
with a summary discussion of our approach and outlook to 
future work on the subject section 
 abstract architecture 
our framework is based on providing formal meta-level 
descriptions of learning processes i e representations of all 
relevant components of the learning machinery used by a 
learning agent together with information about the state of 
the learning process 
to ensure that this framework is sufficiently general we 
consider the following general description of a learning 
problem 
given data d ⊆ d taken from an instance space 
d a hypothesis space h and an unknown 
target function c ∈ h 
 derive a function h ∈ h that 
approximates c as well as possible according to 
some performance measure g h → q where q 
is a set of possible levels of learning performance 
 
by requiring this we are ensuring that the learning problem 
can be solved in principle using the given hypothesis space 
this very broad definition includes a number of components 
of a learning problem for which more concrete specifications 
can be provided if we want to be more precise for the cases 
of classification and clustering for example we can further 
specify the above as follows learning data can be described 
in both cases as d ×n 
i ai where ai is the domain of 
the ith attribute and the set of attributes is a n 
for the hypothesis space we obtain 
h ⊆ h h d → 
in the case of classification i e a subset of the set of all 
possible classifiers the nature of which depends on the 
expressivity of the learning algorithm used and 
h ⊆ h h d → n h is total with range k 
in the case of clustering i e a subset of all sets of possible 
cluster assignments that map data points to a finite number 
of clusters numbered to k for classification g might be 
defined in terms of the numbers of false negatives and false 
positives with respect to some validation set v ⊆ d and 
clustering might use various measures of cluster validity to 
evaluate the quality of a current hypothesis so that q r 
in both cases but other sets of learning quality levels can 
be imagined 
next we introduce a notion of learning step which 
imposes a uniform basic structure on all learning processes that 
are supposed to exchange information using our framework 
for this we assume that each learner is presented with a 
finite set of data d d dk in each step this is an 
ordered set to express that the order in which the samples are 
used for training matters and employs a training update 
function f h × d 
→ h which updates h given a series of 
samples d dk in other words one learning step always 
consists of applying the update function to all samples in d 
exactly once we define a learning step as a tuple 
l d h f g h 
where we require that h ⊆ h and h ∈ h 
the intuition behind this definition is that each learning 
step completely describes one learning iteration as shown 
in figure in step t the learner updates the current 
hypothesis ht− with data dt and evaluates the resulting new 
hypothesis ht according to the current performance measure 
gt such a learning step is equivalent to the following steps 
of computation 
 train the algorithm on all samples in d once i e 
calculate ft ht− dt ht 
 calculate the quality gt of the resulting hypothesis 
gt ht 
we denote the set of all possible learning steps by l for 
ease of notation we denote the components of any l ∈ l by 
d l h l f l and g l respectively the reason why such 
learning step specifications use a subset h of h instead of 
h itself is that learners often have explicit knowledge about 
which hypotheses are effectively ruled out by f given h in 
the future if this is not the case we can still set h h 
a learning process is a finite non-empty sequence 
l l → l → → ln 
of learning steps such that 
∀ ≤ i n h li f li h li d li 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
training function 
ht 
performance measure solution quality 
qtgtft 
training set 
dt 
hypothesis 
hypothesis 
ht− 
figure a generic model of a learning step 
i e the only requirement the transition relation →⊆ l × l 
makes is that the new hypothesis is the result of training the 
old hypothesis on all available sample data that belongs to 
the current step we denote the set of all possible learning 
processes by l ignoring for ease of notation the fact that 
this set depends on h d and the spaces of possible 
training and evaluation functions f and g the performance 
trace associated with a learning process l is the sequence 
q qn ∈ qn 
where qi g li h li i e the sequence 
of quality values calculated by the performance measures of 
the individual learning steps on the respective hypotheses 
such specifications allow agents to provide a 
selfdescription of their learning process however in 
communication among learning agents it is often useful to 
provide only partial information about one s internal learning 
process rather than its full details e g when advertising 
this information in order to enter information exchange 
negotiations with others for this purpose we will assume 
that learners describe their internal state in terms of sets of 
learning processes in the sense of disjunctive choice which 
we call learning process descriptions lpds rather than by 
giving precise descriptions about a single concrete learning 
process 
this allows us to describe properties of a learning 
process without specifying its details exhaustively as an 
example the set l ∈ l ∀l l i d l ≤ describes all 
processes that have a training set of at most 
samples where all the other elements are arbitrary likewise 
 l ∈ l ∀l l i d l d is equivalent to just providing 
information about a single sample d and no other details 
about the process this can be useful to model for 
example data received from the environment therefore we use 
℘ l that is the set of all lpds as the basis for 
designing content languages for communication in the protocols 
we specify below 
in practice the actual content language chosen will of 
course be more restricted and allow only for a special type 
of subsets of l to be specified in a compact way and its 
choice will be crucial for the interactions that can occur 
between learning agents for our examples below we simply 
assume explicit enumeration of all possible elements of the 
respective sets and function spaces d h etc extended by 
the use of wildcard symbols so that our second example 
above would become d 
 learning agents 
in our framework a learning agent is essentially a 
metareasoning function that operates on information about 
learning processes and is situated in an environment co-inhabited 
by other learning agents this means that it is not only 
capable of meta-level control on how to learn but in doing 
so it can take information into account that is provided by 
other agents or the environment although purely 
cooperative or hybrid cases are possible for the purposes of this 
paper we will assume that agents are purely self-interested 
and that while there may be a potential for cooperation 
considering how agents can mutually improve each others 
learning performance there is no global mechanism that can 
enforce such cooperative behaviour 
formally speaking an agent s learning function is a 
function which given a set of histories of previous learning 
processes of oneself and potentially of learning processes about 
which other agents have provided information and outputs 
a learning step which is its next learning action in the 
most general sense our learning agent s internal learning 
process update can hence be viewed as a function 
λ ℘ l → l × ℘ l 
which takes a set of learning histories of oneself and others 
as inputs and computes a new learning step to be executed 
while updating the set of known learning process histories 
 e g by appending the new learning action to one s own 
learning process and leaving all information about others 
learning processes untouched note that in λ l ln 
 l l ln some elements li of the input learning process 
set may be descriptions of new learning data received from 
the environment 
the λ-function can essentially be freely chosen by the 
agent as long as one requirement is met namely that the 
learning data that is being used always stems from what 
has been previously observed more formally 
∀ l ln ∈ ℘ l λ l ln l l ln 
⇒ 
„ 
d l ∪ 
 
l li j 
d l 
 
⊆ 
 
l li j 
d l 
i e whatever λ outputs as a new learning step and updated 
set of learning histories it cannot invent new data it has 
to work with the samples that have been made available 
to it earlier in the process through the environment or from 
other agents and it can of course re-train on previously used 
data 
the goal of the agent is to output an optimal learning 
step in each iteration given the information that it has one 
possibility of specifying this is to require that 
∀ l ln ∈ ℘ l λ l ln l l ln 
⇒ l arg max 
l ∈l 
g l h l 
but since it will usually be unrealistic to compute the 
optimal next learning step in every situation it is more useful 
 
note that our outlook is not only different from common 
cooperative models of distributed machine learning and data 
mining but also delineates our approach from multiagent 
learning systems in which agents learn about other agents 
 i e the learning goal itself is not affected by agents 
behaviour in the environment 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
i j dj hj fj gj hj 
di 
pd→d 
 di dj 
 
 
pd→d 
kd→d 
 di dj 
 n a 
hi 
 
 
 n a 
fi 
 
 
 n a 
gi 
 
 n a 
pg→h 
 gi hj 
 
 
pg→h 
kg→h 
 gi hj 
hi 
 
 n a 
 
table matrix of integration functions for 
messages sent from learner i to j 
to simply use g l h l as a running performance measure 
to evaluate how well the agent is performing 
this is too abstract and unspecific for our purposes while 
it describes what agents should do transform the settings 
for the next learning step in an optimal way it doesn t 
specify how this can be achieved in practice 
 integrating learning process information 
to specify how an agent s learning process can be affected 
by integrating information received from others we need to 
flesh out the details of how the learning steps it will perform 
can be modified using incoming information about learning 
processes described by other agents this includes the 
acquisition of new learning data from the environment as a 
special case in the most general case we can specify this 
in terms of the potential modifications to the existing 
information about learning histories that can be performed using 
new information for ease of presentation we will assume 
that agents are stationary learning processes that can only 
record the previously executed learning step and only 
exchange information about this one individual learning step 
 our model can be easily extended to cater for more complex 
settings 
let lj dj hj fj gj hj be the current state of 
agent j when receiving a learning process description li 
di hi fi gi hi from agent i for the time being we 
assume that this is a specific learning step and not a more 
vague disjunctive description of properties of the 
learning step of i considering all possible interactions at an 
abstract level we basically obtain a matrix of 
possibilities for modifications of j s learning step specification as 
shown in table in this matrix each entry specifies 
a family of integration functions pc→c 
 pc→c 
kc→c 
where 
c c ∈ d h f g h and which define how agent j s 
component cj will be modified using the information ci provided 
about the same or a different component of i s learning 
step by applying pc→c 
r ci cj for some r ∈ kc→c 
to put it more simply the collections of p-functions an agent 
j uses specifies how it will modify its own learning behaviour 
using information obtained from i 
for the diagonal of this matrix which contains the most 
common ways of integrating new information in one s own 
learning model obvious ways of modifying one s own 
learning process include replacing cj by ci or ignoring ci 
altogether more complex subtle forms of learning process 
integration include 
 modification of dj append di to dj filter out all 
elements from dj which also appear in di append 
di to dj discarding all elements with attributes 
outside ranges which affect gj or those elements already 
correctly classified by hj 
 modification of hi use the union intersection of hi 
and hj alternatively discard elements of hj that are 
inconsistent with dj in the process of intersection or 
union or filter out elements that cannot be obtained 
using fj unless fj is modified at the same time 
 modification of fj modify parameters or background 
knowledge of fj using information about fi assess 
their relevance by simulating previous learning steps 
on dj using gj and discard those that do not help 
improve own performance 
 modification of hj combine hj with hi using say 
logical or mathematical operators make the use of hi 
contingent on a pre-integration assessment of its quality 
using own data dj and gj 
while this list does not include fully fledged concrete 
integration operations for learning processes it is indicative of 
the broad range of interactions between individual agents 
learning processes that our framework enables 
note that the list does not include any modifications to 
gj this is because we do not allow modifications to the 
agent s own quality measure as this would render the model 
of rational learning action useless if the quality measure 
is relative and volatile we cannot objectively judge learning 
performance also note that some of the above examples 
require consulting other elements of lj than those appearing 
as arguments of the p-operations we omit these for ease 
of notation but emphasise that information-rich operations 
will involve consulting many different aspects of lj 
apart from operations along the diagonal of the matrix 
more exotic integration operations are conceivable that 
combine information about different components in theory 
we could fill most of the matrix with entries for them but 
for lack of space we list only a few examples 
 modification of dj using fi pre-process samples in 
fi e g to achieve intermediate representations that fj 
can be applied to 
 modification of dj using hi filter out samples from 
dj that are covered by hi and build hj using fj only 
on remaining samples 
 modification of hj using fi filter out hypotheses from 
hj that are not realisable using fi 
 modification of hj using gi if hj is composed of several 
sub-components filter out those sub-components that 
do not perform well according to gi 
 
finally many messages received from others describing 
properties of their learning processes will contain 
information about several elements of a learning step giving rise to 
yet more complex operations that depend on which kinds of 
information are available 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
figure screenshot of our simulation system 
displaying online vessel tracking data for the north sea 
region 
 application example 
 domain description 
as an illustration of our framework we present an 
agentbased data mining system for clustering-based surveillance 
using ais automatic identification system data in 
our application domain different commercial and 
governmental agencies track the journeys of ships over time 
using ais data which contains structured information 
automatically provided by ships equipped with shipborne 
mobile ais stations to shore stations other ships and aircrafts 
this data contains the ship s identity type position course 
speed navigational status and other safety-related 
information figure shows a screenshot of our simulation system 
it is the task of ais agencies to detect anomalous 
behaviour so as to alarm police coastguard units to further 
investigate unusual potentially suspicious behaviour such 
behaviour might include things such as deviation from the 
standard routes between the declared origin and destination 
of the journey unexpected close encounters between 
different vessels on sea or unusual patterns in the choice of 
destination over multiple journeys taking the type of 
vessel and reported freight into account while the reasons for 
such unusual behaviour may range from pure coincidence or 
technical problems to criminal activity such as smuggling 
piracy terrorist military attacks it is obviously useful to 
pre-process the huge amount of vessel tracking data that 
is available before engaging in further analysis by human 
experts 
to support this automated pre-processing task software 
used by these agencies applies clustering methods in order 
to identify outliers and flag those as potentially suspicious 
entities to the human user however many agencies active 
in this domain are competing enterprises and use their 
 partially overlapping but distinct datasets and learning 
hypotheses models as assets and hence cannot be expected 
to collaborate in a fully cooperative way to improve 
overall learning results considering that this is the reality of 
the domain in the real world it is easy to see that a 
framework like the one we have suggested above might be useful 
to exploit the cooperation potential that is not exploited by 
current systems 
 agent-based distributed learning system 
design 
to describe a concrete design for the ais domain we need 
to specify the following elements of the overall system 
 the datasets and clustering algorithms available to 
individual agents 
 the interaction mechanism used for exchanging 
descriptions of learning processes and 
 the decision mechanism agents apply to make learning 
decisions 
regarding our agents are equipped with their own private 
datasets in the form of vessel descriptions learning samples 
are represented by tuples containing data about individual 
vessels in terms of attributes a n including things 
such as width length etc with real-valued domains ai 
r for all i 
in terms of learning algorithm we consider clustering 
with a fixed number of k clusters using the k-means and 
k-medoids clustering algorithms fixed meaning that 
the learning algorithm will always output k clusters 
however we allow agents to change the value of k over different 
learning cycles this means that the hypothesis space can 
be defined as h c ck ci ∈ r a 
 i e the set of all 
possible sets of k cluster centroids in a -dimensional 
euclidean space for each hypothesis h c ck and any 
data point d ∈ ×n 
i ai given domain ai for the ith 
attribute of each sample the assignment to clusters is given 
by 
c c ck d arg min 
 ≤j≤k 
 d − cj 
i e d is assigned to that cluster whose centroid is closest to 
the data point in terms of euclidean distance 
for evaluation purposes each dataset pertaining to a 
particular agent i is initially split into a training set di and a 
validation vi then we generate a set of fake vessels fi 
such that fi vi these two sets assess the agent s 
ability to detect suspicious vessels for this we assign a 
confidence value r h d to every ship d 
r h d 
 
 d − cc h d 
where c h d is the index of the nearest centroid based 
on this measure we classify any vessel in fi ∪ vi as fake if 
its r-value is below the median of all the confidences r h d 
for d ∈ fi ∪ vi with this we can compute the quality 
gi h ∈ r as the ratio between all correctly classified vessels 
and all vessels in fi ∪ vi 
as concerns we use a simple contract-net protocol 
 cnp based hypothesis trading mechanism before 
each learning iteration agents issue publicly broadcasted 
calls-for-proposals cfps advertising their own numerical 
model quality in other words the initiator of a cnp 
describes its own current learning state as gi h 
where h is their current hypothesis model we assume that 
agents are sincere when advertising their model quality but 
note that this quality might be of limited relevance to other 
agents as they may specialise on specific regions of the data 
space not related to the test set of the sender of the cfp 
subsequently some agents may issue bids in which they 
advertise in turn the quality of their own model if the 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
bids if any are accepted by the initiator of the protocol 
who issued the cfp the agents exchange their hypotheses 
and the next learning iteration ensues 
to describe what is necessary for we have to specify 
 i under which conditions agents submit bids in response 
to a cfp ii when they accept bids in the cnp negotiation 
process and iii how they integrate the received 
information in their own learning process concerning i and ii 
we employ a very simple rule that is identical in both cases 
let g be one s own model quality and g that advertised by 
the cfp or highest bid respectively if g g we respond 
to the cfp accept the bid else respond to the cfp 
 accept the bid with probability p g g and ignore reject it 
else if two agents make a deal they exchange their 
learning hypotheses models in our experiments g and g are 
calculated by an additional agent that acts as a global 
validation mechanism for all agents in a more realistic setting a 
comparison mechanism for different g functions would have 
to be provided 
as for iii each agent uses a single model merging 
operator taken from the following two classes of operators hj is 
the receiver s own model and hi is the provider s model 
 ph→h 
 hi hj 
- m-join the m best clusters in terms of coverage 
of dj from hypothesis hi are appended to hj 
- m-select the set of the m best clusters in terms 
of coverage of dj from the union hi ∪hj is chosen 
as a new model unlike m-join this method does 
not prefer own clusters over others 
 ph→d 
 hi dj 
- m-filter the m best clusters as above from 
hi are identified and appended to a new model 
formed by using those samples not covered by 
these clusters applying the own learning 
algorithm fj 
whenever m is large enough to encompass all clusters we 
simply write join or filter for them in section we analyse 
the performance of each of these two classes for different 
choices of m 
it is noteworthy that this agent-based distributed data 
mining system is one of the simplest conceivable instances 
of our abstract architecture while we have previously 
applied it also to a more complex market-based architecture 
using inductive logic programming learners in a transport 
logistics domain we believe that the system described 
here is complex enough to illustrate the key design decisions 
involved in using our framework and provides simple 
example solutions for these design issues 
 experimental results 
figure shows results obtained from simulations with 
three learning agents in the above system using the k-means 
and k-medoids clustering methods respectively we 
partition the total dataset of ships into three disjoint sets of 
 samples each and assign each of these to one learning 
agent the single agent is learning from the whole dataset 
the parameter k is set to as this is the optimal value for 
the total dataset according to the davies-bouldin index 
for m-select we assume m k which achieves a constant 
figure performance results obtained for different 
integration operations in homogeneous learner 
societies using the k-means top and k-medoids 
 bottom methods 
model size for m-join and m-filter we assume m to 
limit the extent to which models increase over time 
during each experiment the learning agents receive ship 
descriptions in batches of samples between these 
batches there is enough time to exchange the models among 
the agents and recompute the models if necessary each 
ship is described using width length draught and speed 
attributes with the goal of learning to detect which vessels 
have provided fake descriptions of their own properties the 
validation set contains real and randomly generated 
fake ships to generate sufficiently realistic properties for 
fake ships their individual attribute values are taken from 
randomly selected ships in the validation set so that each 
fake sample is a combination of attribute values of several 
existing ships 
in these experiments we are mainly interested in 
investigating whether a simple form of knowledge sharing between 
self-interested learning agents could improve agent 
performance compared to a setting of isolated learners thereby 
we distinguish between homogeneous learner societies where 
all agents use the same clustering algorithm and 
heterogeneous ones where different agents use different algorithms 
as can be seen from the performance plots in figure 
 homogeneous case and heterogeneous case two agents 
use the same method and one agent uses the other this is 
clearly the case for the unrestricted join and filter 
integration operations m k in both cases this is quite natural 
as these operations amount to sharing all available model 
knowledge among agents under appropriate constraints 
depending on how beneficial the exchange seems to the agents 
we can see that the quality of these operations is very close 
to the single agent that has access to all training data 
for the restricted m k m-join m-filter and m-select 
methods we can also observe an interesting distinction 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
figure performance results obtained for 
different integration operations in heterogeneous societies 
with the majority of learners using the k-means 
 top and k-medoids bottom methods 
namely that these perform similarly to the isolated learner 
case in homogeneous agent groups but better than isolated 
learners in more heterogeneous societies this suggests that 
heterogeneous learners are able to benefit even from rather 
limited knowledge sharing and this is what using a rather 
small m amounts to given that k while this is 
not always true for homogeneous agents this nicely 
illustrates how different learning or data mining algorithms can 
specialise on different parts of the problem space and then 
integrate their local results to achieve better individual 
performance 
apart from these obvious performance benefits 
integrating partial learning results can also have other advantages 
the m-filter operation for example decreases the number 
of learning samples and thus can speed up the learning 
process the relative number of filtered examples measured in 
our experiments is shown in the following table 
k-means k-medoids 
filtering - - 
m-filtering - - 
the overall conclusion we can draw from these initial 
experiments with our architecture is that since a very 
simplistic application of its principles has proven capable of 
improving the performance of individual learning agents it is 
worthwhile investigating more complex forms of 
information exchange about learning processes among autonomous 
learners 
 related work 
we have already mentioned work on distributed 
 nonagent machine learning and data mining in the 
introductory chapter so in this section we shall restrict ourselves to 
approaches that are more closely related to our outlook on 
distributed learning systems 
very often approaches that are allegedly agent-based 
completely disregard agent autonomy and prescribe local 
decision-making procedures a priori a typical example for 
this type of system is the one suggested by caragea et al 
which is based on a distributed support-vector machine 
approach where agents incrementally join their datasets 
together according to a fixed distributed algorithm a similar 
example is the work of weiss where groups of 
classifier agents learn to organise their activity so as to optimise 
global system behaviour 
the difference between this kind of collaborative 
agentbased learning systems and our own framework is that 
these approaches assume a joint learning goal that is pursued 
collaboratively by all agents 
many approaches rely heavily on a homogeneity 
assumption plaza and ontanon suggest methods for 
agentbased intelligent reuse of cases in case-based reasoning but 
is only applicable to societies of homogeneous learners and 
coined towards a specific learning method an 
agentbased method for integrating distributed cluster analysis 
processes using density estimation is presented by klusch 
et al which is also specifically designed for a 
particular learning algorithm the same is true of which 
both present market-based mechanisms for aggregating the 
output of multiple learning agents even though these 
approaches consider more interesting interaction mechanisms 
among learners 
a number of approaches for sharing learning data 
have also been proposed grecu and becker suggest an 
exchange of learning samples among agents and ghosh et 
al is a step in the right direction in terms of revealing 
only partial information about one s learning process as it 
deals with limited information sharing in distributed 
clustering 
papyrus is a system that provides a markup language 
for meta-description of data hypotheses and intermediate 
results and allows for an exchange of all this information 
among different nodes however with a strictly cooperative 
goal of distributing the load for massively distributed data 
mining tasks 
the male system was a very early multiagent 
learning system in which agents used a blackboard approach to 
communicate their hypotheses agents were able to critique 
each others hypotheses until agreement was reached 
however all agents in this system were identical and the system 
was strictly cooperative 
the animals system was used to simulate 
multistrategy learning by combining two or more learning 
techniques represented by heterogeneous agents in order to 
overcome weaknesses in the individual algorithms yet it was 
also a strictly cooperative system 
as these examples show and to the best of our knowledge 
there have been no previous attempts to provide a 
framework that can accommodate both independent and 
heterogeneous learning agents and this can be regarded as the main 
contribution of our work 
 conclusion 
in this paper we outlined a generic abstract framework 
for distributed machine learning and data mining this 
framework constitutes to our knowledge the first attempt 
 the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
to capture complex forms of interaction between 
heterogeneous and or self-interested learners in an architecture that 
can be used as the foundation for implementing systems that 
use complex interaction and reasoning mechanisms to enable 
agents to inform and improve their learning abilities with 
information provided by other learners in the system 
provided that all agents engage in a sufficiently similar learning 
activity 
to illustrate that the abstract principles of our 
architecture can be turned into concrete computational systems 
we described a market-based distributed clustering system 
which was evaluated in the domain of vessel tracking for 
purposes of identifying deviant or suspicious behaviour 
although our experimental results only hint at the potential 
of using our architecture they underline that what we are 
proposing is feasible in principle and can have beneficial 
effects even in its most simple instantiation 
yet there is a number of issues that we have not addressed 
in the presentation of the architecture and its empirical 
evaluation firstly we have not considered the cost of 
communication and made the implicit assumption that the required 
communication comes for free this is of course 
inadequate if we want to evaluate our method in terms of the 
total effort required for producing a certain quality of 
learning results secondly we have not experimented with agents 
using completely different learning algorithms e g symbolic 
and numerical in systems composed of completely different 
agents the circumstances under which successful information 
exchange can be achieved might be very different from those 
described here and much more complex communication and 
reasoning methods may be necessary to achieve a useful 
integration of different agents learning processes finally more 
sophisticated evaluation criteria for such distributed 
learning architectures have to be developed to shed some light 
on what the right measures of optimality for autonomously 
reasoning and communicating agents should be 
these issues together with a more systematic and 
thorough investigation of advanced interaction and 
communication mechanisms for distributed collaborating and 
competing agents will be the subject of our future work on the 
subject 
acknowledgement we gratefully acknowledge the 
support of the presented research by army research 
laboratory project n - - and office for naval research 
project n - - - 
 references 
 http www aislive com 
 http www healthagents com 
 s bailey r grossman h sivakumar and 
a turinsky papyrus a system for data mining over 
local and wide area clusters and super-clusters in 
proc of the conference on supercomputing 
 e bauer and r kohavi an empirical comparison of 
voting classification algorithms bagging boosting 
and variants machine learning 
 p berkhin survey of clustering data mining 
techniques technical report accrue software 
 d caragea a silvescu and v honavar agents that 
learn from distributed dynamic data sources in 
proc of the workshop on learning agents 
 n chawla and s e abd l o hall creating 
ensembles of classifiers in proceedings of icdm 
pages - san jose ca usa 
 d dash and g f cooper model averaging for 
prediction with discrete bayesian networks journal 
of machine learning research - 
 d l davies and d w bouldin a cluster 
separation measure ieee transactions on pattern 
analysis and machine intelligence - 
 p edwards and w davies a heterogeneous 
multi-agent learning system in proceedings of the 
special interest group on cooperating knowledge 
based systems pages - 
 j ghosh a strehl and s merugu a consensus 
framework for integrating distributed clusterings 
under limited knowledge sharing in nsf workshop 
on next generation data mining - 
 d l grecu and l a becker coactive learning for 
distributed data mining in proceedings of kdd- 
pages - new york ny august 
 m klusch s lodi and g moro agent-based 
distributed data mining the kdec scheme in 
agentlink number in lncs springer 
 t m mitchell machine learning pages - 
mcgraw-hill new york 
 s ontanon and e plaza recycling data for 
multi-agent learning in proc of icml- 
 l panait and s luke cooperative multi-agent 
learning the state of the art autonomous agents 
and multi-agent systems - 
 b park and h kargupta distributed data mining 
algorithms systems and applications in n ye 
editor data mining handbook pages - 
 f j provost and d n hennessy scaling up 
distributed machine learning with cooperation in 
proc of aaai- pages - aaai press 
 s sian extending learning to multiple agents issues 
and a model for multi-agent machine learning 
 ma-ml in y kodratoff editor machine 
learningewsl- pages - springer-verlag 
 r smith the contract-net protocol high-level 
communication and control in a distributed problem 
solver ieee transactions on computers 
c- - 
 s j stolfo a l prodromidis s tselepis w lee 
d w fan and p k chan jam java agents for 
meta-learning over distributed databases in proc of 
the kdd- pages - usa 
 j toˇziˇcka m jakob and m pˇechouˇcek 
market-inspired approach to collaborative learning 
in cooperative information agents x cia 
volume of lncs pages - springer 
 y z wei l moreau and n r jennings 
recommender systems a market-based design in 
proceedings of aamas- pages - 
 g weiß a multiagent perspective of parallel and 
distributed machine learning in proceedings of 
agents pages - 
 g weiss and p dillenbourg what is multi in 
multi-agent learning collaborative-learning 
cognitive and computational approaches - 
the sixth intl joint conf on autonomous agents and multi-agent systems aamas 
