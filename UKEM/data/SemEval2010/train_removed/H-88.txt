controlling overlap in content-oriented xml retrieval 
charles l a clarke 
school of computer science university of waterloo canada 
claclark plg uwaterloo ca 
abstract 
the direct application of standard ranking techniques to 
retrieve individual elements from a collection of xml 
documents often produces a result set in which the top ranks are 
dominated by a large number of elements taken from a small 
number of highly relevant documents this paper presents 
and evaluates an algorithm that re-ranks this result set with 
the aim of minimizing redundant content while preserving 
the benefits of element retrieval including the benefit of 
identifying topic-focused components contained within 
relevant documents the test collection developed by the 
initiative for the evaluation of xml retrieval inex forms 
the basis for the evaluation 
categories and subject descriptors 
h information systems information storage and 
retrieval-information search and retrieval 
general terms 
algorithms measurement performance experimentation 
 introduction 
the representation of documents in xml provides an 
opportunity for information retrieval systems to take 
advantage of document structure returning individual document 
components when appropriate rather than complete 
documents in all circumstances in response to a user query an 
xml information retrieval system might return a mixture 
of paragraphs sections articles bibliographic entries and 
other components this facility is of particular benefit when 
a collection contains very long documents such as product 
manuals or books where the user should be directed to the 
most relevant portions of these documents 
 article 
 fm 
 atl text compression for 
dynamic document databases atl 
 au alistair moffat au 
 au justin zobel au 
 au neil sharman au 
 abs p b abstract b for p abs 
 fm 
 bdy 
 sec st introduction st 
 ip modern document databases ip 
 p there are good reasons to compress p 
 sec 
 sec st reducing memory requirements st 
 ss st method a st 
 sec 
 
 bdy 
 article 
figure a journal article encoded in xml 
figure provides an example of a journal article encoded 
in xml illustrating many of the important characteristics 
of xml documents tags indicate the beginning and end of 
each element with elements varying widely in size from one 
word to thousands of words some elements such as 
paragraphs and sections may be reasonably presented to the user 
as retrieval results but others are not appropriate elements 
overlap each other - articles contain sections sections 
contain subsections and subsections contain paragraphs each 
of these characteristics affects the design of an xml ir 
system and each leads to fundamental problems that must be 
solved in an successful system most of these fundamental 
problems can be solved through the careful adaptation of 
standard ir techniques but the problems caused by overlap 
are unique to this area and form the primary focus of 
this paper 
the article of figure may be viewed as an xml tree 
as illustrated in figure formally a collection of xml 
documents may be represented as a forest of ordered rooted 
trees consisting of a set of nodes n and a set of directed 
edges e connecting these nodes for each node x ∈ n the 
notation x parent refers to the parent node of x if one exists 
and the notation x children refers to the set of child nodes 
sec 
bdyfm 
atl au au au 
abs 
p 
b 
st ip 
sec 
st 
ss 
st 
article 
p 
figure example xml tree 
of x since an element may be represented by the node at 
its root the output of an xml ir system may be viewed as 
a ranked list of the top-m nodes 
the direct application of a standard relevance ranking 
technique to a set of xml elements can produce a result 
in which the top ranks are dominated by many structurally 
related elements a high scoring section is likely to contain 
several high scoring paragraphs and to be contained in an 
high scoring article for example many of the elements in 
figure would receive a high score on the keyword query 
text index compression algorithms if each of these 
elements are presented to a user as an individual and 
separate result she may waste considerable time reviewing and 
rejecting redundant content 
one possible solution is to report only the highest 
scoring element along a given path in the tree and to remove 
from the lower ranks any element containing it or contained 
within it unfortunately this approach destroys some of the 
possible benefits of xml ir for example an outer element 
may contain a substantial amount of information that does 
not appear in an inner element but the inner element may 
be heavily focused on the query topic and provide a short 
overview of the key concepts in such cases it is reasonable 
to report elements which contain or are contained in higher 
ranking elements even when an entire book is relevant a 
user may still wish to have the most important paragraphs 
highlighted to guide her reading and to save time 
this paper presents a method for controlling overlap 
starting with an initial element ranking a re-ranking algorithm 
adjusts the scores of lower ranking elements that contain or 
are contained within higher ranking elements reflecting the 
fact that this information may now be redundant for 
example once an element representing a section appears in the 
ranking the scores for the paragraphs it contains and the 
article that contains it are reduced the inspiration for this 
strategy comes partially from recent work on structured 
documents retrieval where terms appearing in different fields 
such as the title and body are given different weights 
extending that approach the re-ranking algorithm varies 
weights dynamically as elements are processed 
the remainder of the paper is organized as follows after 
a discussion of background work and evaluation 
methodology a baseline retrieval method is presented in section 
this baseline method represents a reasonable adaptation of 
standard ir technology to xml section then outlines a 
strategy for controlling overlap using the baseline method as 
a starting point a re-ranking algorithm implementing this 
strategy is presented in section and evaluated in section 
section discusses an extended version of the algorithm 
 background 
this section provides a general overview of xml 
information retrieval and discusses related work with an emphasis 
on the fundamental problems mentioned in the introduction 
much research in the area of xml retrieval views it from a 
traditional database perspective being concerned with such 
problems as the implementation of structured query 
languages and the processing of joins here we take 
a content oriented ir perceptive focusing on xml 
documents that primarily contain natural language data and 
queries that are primarily expressed in natural language 
we assume that these queries indicate only the nature of 
desired content not its structure and that the role of the 
ir system is to determine which elements best satisfy the 
underlying information need other ir research has 
considered mixed queries in which both content and structural 
requirements are specified 
 term and document statistics 
in traditional information retrieval applications the 
standard unit of retrieval is taken to be the document 
depending on the application this term might be interpreted 
to encompass many different objects including web pages 
newspaper articles and email messages 
when applying standard relevance ranking techniques in 
the context of xml ir a natural approach is to treat each 
element as a separate document with term statistics 
available for each in addition most ranking techniques 
require global statistics e g inverse document frequency 
computed over the collection as a whole if we consider this 
collection to include all elements that might be returned by 
the system a specific occurrence of a term may appear in 
several different documents perhaps in elements 
representing a paragraph a subsection a section and an article 
it is not appropriate to compute inverse document frequency 
under the assumption that the term is contained in all of 
these elements since the number of elements that contain a 
term depends entirely on the structural arrangement of the 
documents 
 retrievable elements 
while an xml ir system might potentially retrieve any 
element many elements may not be appropriate as retrieval 
results this is usually the case when elements contain very 
little text for example a section title containing only 
the query terms may receive a high score from a ranking 
algorithm but alone it would be of limited value to a user who 
might prefer the actual section itself other elements may 
reflect the document s physical rather than logical 
structure which may have little or no meaning to a user an 
effective xml ir system must return only those elements 
that have sufficient content to be usable and are able to 
stand alone as independent objects standard 
document components such as paragraphs sections subsections 
and abstracts usually meet these requirements titles 
italicized phrases and individual metadata fields often do not 
 evaluation methodology 
over the past three years the initiative for the 
evaluation of xml retrieval inex has encouraged research into 
xml information retrieval technology inex is an 
experimental conference series similar to trec with groups 
from different institutions completing one or more 
experimental tasks using their own tools and systems and 
comparing their results at the conference itself over groups 
participated in inex and the conference has become 
as influential in the area of xml ir as trec is in other ir 
areas the research described in this paper as well as much 
of the related work it cites depends on the test collections 
developed by inex 
overlap causes considerable problems with retrieval 
evaluation and the inex organizers and participants have 
wrestled with these problems since the beginning while 
substantial progress has been made these problem are still not 
completely solved kazai et al provide a detailed 
exposition of the overlap problem in the context of inex 
retrieval evaluation and discuss both current and proposed 
evaluation metrics many of these metrics are applied to 
evaluate the experiments reported in this paper and they 
are briefly outlined in the next section 
 inex 
space limitations prevent the inclusion of more than a 
brief summary of inex tasks and evaluation 
methodology for detailed information the proceedings of the 
conference itself should be consulted 
 tasks 
for the main experimental tasks inex participants 
were provided with a collection of articles taken from 
the ieee computer societies magazines and journals 
between and each document is encoded in xml 
using a common dtd with the document of figures and 
providing one example 
at inex the two main experimental tasks were both 
adhoc retrieval tasks investigating the performance of 
systems searching a static collection using previously unseen 
topics the two tasks differed in the types of topics they 
used for one task the content-only or co task the 
topics consist of short natural language statements with no 
direct reference to the structure of the documents in the 
collection for this task the ir system is required to select the 
elements to be returned for the other task the 
contentand-structure or cas task the topics are written in an 
xml query language and contain explicit references to 
document structure which the ir system must attempt to 
satisfy since the work described in this paper is directed 
at the content-only task where the ir system receives no 
guidance regarding the elements to return the cas task is 
ignored in the remainder of our description 
in new co topics were selected by the conference 
organizers from contributions provided by the conference 
participants each topic includes a short keyword query 
which is executed over the collection by each participating 
group on their own xml ir system each group could 
submit up to three experimental runs consisting of the top 
m elements for each topic 
 relevance assessment 
since xml ir is concerned with locating those elements 
that provide complete coverage of a topic while containing as 
little extraneous information as possible simple relevant 
vs not relevant judgments are not sufficient instead the 
inex organizers adopted two dimensions for relevance 
assessment the exhaustivity dimension reflects the degree to 
which an element covers the topic and the specificity 
dimension reflects the degree to which an element is focused on the 
topic a four-point scale is used in both dimensions thus 
a element is highly exhaustive and highly specific a 
 element is marginally exhaustive and highly specific 
and a element is not relevant additional information 
on the assessment methodology may be found in piwowarski 
and lalmas who provide a detailed rationale 
 evaluation metrics 
the principle evaluation metric used at inex is a 
version of mean average precision map adjusted by 
various quantization functions to give different weights to 
different elements depending on their exhaustivity and specificity 
values one variant the strict quantization function gives a 
weight of to elements and a weight of to all others 
this variant is essentially the familiar map value with 
elements treated as relevant and all other elements treated 
as not relevant other quantization functions are designed 
to give partial credit to elements which are near misses 
due to a lack or exhaustivity and or specificity both the 
generalized quantization function and the specificity-oriented 
generalization sog function credit elements according to 
their degree of relevance with the second function 
placing greater emphasis on specificity this paper reports 
results of this metric using all three of these quantization 
functions since this metric was first introduced at inex 
it is generally referred as the inex- metric 
the inex- metric does not penalize overlap in 
particular both the generalized and sog quantization functions 
give partial credit to a near miss even when a 
element overlapping it is reported at a higher rank to address 
this problem kazai et al propose an xml cumulated 
gain metric which compares the cumulated gain of a 
ranked list to an ideal gain vector this ideal gain vector 
is constructed from the relevance judgments by 
eliminating overlap and retaining only best element along a given 
path thus the xcg metric rewards retrieval runs that 
avoid overlap while xcg was not used officially at inex 
 a version of it is likely to be used in the future 
at inex yet another metric was introduced to 
ameliorate the perceived limitations of the inex- metric 
this inex- metric extends the definitions of precision 
and recall to consider both the size of reported components 
and the overlap between them two versions were created 
one that considered only component size and another that 
considered both size and overlap while the inex- 
metric exhibits undesirable anomalies and was not used in 
 values are reported in the evaluation section to provide 
an additional instrument for investigating overlap 
 baseline retrieval method 
this section provides an overview of baseline xml 
information retrieval method currently used in the multitext 
ir system developed by the information retrieval group at 
the university of waterloo this retrieval method results 
from the adaptation and tuning of the okapi bm 
measure to the xml information retrieval task the 
multitext system performed respectably at inex placing 
in the top ten under all of the quantization functions and 
placing first when the quantization function emphasized 
exhaustivity 
to support retrieval from xml and other structured 
document types the system provides generalized queries of the 
form 
rank x by y 
where x is a sub-query specifying a set of document elements 
to be ranked and y is a vector of sub-queries specifying 
individual retrieval terms 
for our inex runs the sub-query x specified a list 
of retrievable elements as those with tag names as follows 
abs app article bb bdy bm fig fm ip 
li p sec ss ss vt 
this list includes bibliographic entries bb and figure 
captions fig as well as paragraphs sections and subsections 
prior to inex the inex collection and the inex 
relevance judgments were manually analyzed to select these 
tag names tag names were selected on the basis of their 
frequency in the collection the average size of their 
associated elements and the relative number of positive relevance 
judgments they received automating this selection process 
is planned as future work 
for inex the term vector y was derived from the 
topic by splitting phrases into individual words eliminating 
stopwords and negative terms those starting with - and 
applying a stemmer for example keyword field of topic 
 
 tree edit distance xml -image 
became the four-term query 
 tree edit distance xml 
where the operator within a quoted string stems the 
term that follows it 
our implementation of okapi bm is derived from the 
formula of robertson et al by setting parameters k 
and k ∞ given a term set q an element x is assigned 
the score 
 
t∈q 
w 
qt 
 k xt 
k xt 
 
where 
w 
 log 
d − dt 
dt ¢ 
d number of documents in the corpus 
dt number of documents containing t 
qt frequency that t occurs in the topic 
xt frequency that t occurs in x 
k k − b b · lx lavg 
lx length of x 
lavg average document length 
 
 
 
 
 
 
 
 
 
 
meanaverageprecision inex- 
k 
strict 
generalized 
sog 
figure impact of k on inex- mean average 
precision with b inex co topics 
prior to inex the inex topics and judgments 
were used to tune the b and k parameters and the impact 
of this tuning is discussed later in this section 
for the purposes of computing document-level statistics 
 d dt and lavg a document is defined to be an article 
these statistics are used for ranking all element types 
following the suggestion of kamps et al the retrieval 
results are filtered to eliminate very short elements those less 
than words in length 
the use of article statistics for all element types might 
be questioned this approach may be justified by 
viewing the collection as a set of articles to be searched using 
standard document-oriented techniques where only articles 
may be returned the score computed for an element is 
essentially the score it would receive if it were added to the 
collection as a new document ignoring the minor 
adjustments needed to the document-level statistics nonetheless 
we plan to examine this issue again in the future 
in our experience the performance of bm typically 
benefits from tuning the b and k parameters to the 
collection whenever training queries are available for this 
purpose prior to inex we trained the multitext system 
using the inex queries as a starting point we used 
the values b and k which perform well on 
trec adhoc collections and are used as default values in 
our system the results were surprising figure shows the 
result of varying k with b on the map values under 
three quantization functions in our experience optimal 
values for k are typically in the range to in this case 
large values are required for good performance between 
k and k map increases by over under 
the strict quantization similar improvements are seen 
under the generalized and sog quantizations in contrast our 
default value of b works well under all quantization 
functions figure after tuning over a wide range of 
values under several quantization functions we selected values 
of k and b for our inex experiments 
and these values are used for the experiments reported in 
section 
 
 
 
 
 
 
 
 
 
 
meanaverageprecision inex- 
b 
strict 
generalized 
sog 
figure impact of b on inex- mean average 
precision with k inex co topics 
 controlling overlap 
starting with an element ranking generated by the 
baseline method described in the previous section elements are 
re-ranked to control overlap by iteratively adjusting the scores 
of those elements containing or contained in higher ranking 
elements at a conceptual level re-ranking proceeds as 
follows 
 report the highest ranking element 
 adjust the scores of the unreported elements 
 repeat steps and until m elements are reported 
one approach to adjusting the scores of unreported elements 
in step might be based on the okapi bm scores of the 
involved elements for example assume a paragraph with 
score p is reported in step in step the section 
containing the paragraph might then have its score s lowered 
by an amount α · p to reflect the reduced contribution the 
paragraph should make to the section s score 
in a related context robertson et al argue strongly 
against the linear combination of okapi scores in this 
fashion that work considers the problem of assigning different 
weights to different document fields such as the title and 
body associated with web pages a common approach to 
this problem scores the title and body separately and 
generates a final score as a linear combination of the two 
robertson et al discuss the theoretical flaws in this approach and 
demonstrate experimentally that it can actually harm 
retrieval effectiveness instead they apply the weights at the 
term frequency level with an occurrence of a query term 
t in the title making a greater contribution to the score 
than an occurrence in the body in equation xt becomes 
α · yt α · zt where yt is the number of times t occurs in 
the title and zt is the number of times t occurs in the body 
translating this approach to our context the 
contribution of terms appearing in elements is dynamically reduced 
as they are reported the next section presents and 
analysis a simple re-ranking algorithm that follows this strategy 
the algorithm is evaluated experimentally in section one 
limitation of the algorithm is that the contribution of terms 
appearing in reported elements is reduced by the same 
factor regardless of the number of reported elements in which 
it appears in section the algorithm is extended to apply 
increasing weights lowering the score when a term appears 
in more than one reported element 
 re-ranking algorithm 
the re-ranking algorithm operates over xml trees such 
as the one appearing in figure input to the algorithm is 
a list of n elements ranked according to their initial bm 
scores during the initial ranking the xml tree is 
dynamically re-constructed to include only those nodes with 
nonzero bm scores so n may be considerably less than n 
output from the algorithm is a list of the top m elements 
ranked according to their adjusted scores 
an element is represented by the node x ∈ n at its root 
associated with this node are fields storing the length of 
element term frequencies and other information required 
by the re-ranking algorithm as follows 
x f - term frequency vector 
x g - term frequency adjustments 
x l - element length 
x score - current okapi bm score 
x reported - boolean flag initially false 
x children - set of child nodes 
x parent - parent node if one exists 
these fields are populated during the initial ranking process 
and updated as the algorithm progresses the vector x f 
contains term frequency information corresponding to each 
term in the query the vector x g is initially zero and is 
updated by the algorithm as elements are reported 
the score field contains the current bm score for the 
element which will change as the values in x g change the 
score is computed using equation with the xt value for 
each term determined by a combination of the values in x f 
and x g given a term t ∈ q let ft be the component of 
x f corresponding to t and let gt be the component of x g 
corresponding to t then 
xt ft − α · gt 
for processing by the re-ranking algorithm nodes are 
stored in priority queues ordered by decreasing score each 
priority queue pq supports three operations 
pq front - returns the node with greatest score 
pq add x - adds node x to the queue 
pq remove x - removes node x from the queue 
when implemented using standard data structures the front 
operation requires o time and the other operations 
require o log n time where n is the size of the queue 
the core of the re-ranking algorithm is presented in 
figure the algorithm takes as input the priority queue s 
containing the initial ranking and produces the top-m 
reranked nodes in the priority queue f after initializing f to 
be empty on line the algorithm loops m times over lines 
 transferring at least one node from s to f during each 
iteration at the start of each iteration the unreported node 
at the front of s has the greatest adjusted score and it is 
removed and added to f the algorithm then traverses the 
 f ← ∅ 
 for i ← to m do 
 x ← s front 
 s remove x 
 x reported ← true 
 f add x 
 
 foreach y ∈ x children do 
 down y 
 end do 
 
 if x is not a root node then 
 up x x parent 
 end if 
 end do 
figure re-ranking algorithm - as input the 
algorithm takes a priority queue s containing xml 
nodes ranked by their initial scores and returns 
its results in priority queue f ranked by adjusted 
scores 
 up x y ≡ 
 s remove y 
 y g ← y g x f − x g 
 recompute y score 
 s add y 
 if y is not a root node then 
 up x y parent 
 end if 
 
 down x ≡ 
 if not x reported then 
 s remove x 
 x g ← x f 
 recompute x score 
 if x score then 
 f add x 
 end if 
 x reported ← true 
 foreach y ∈ x children do 
 down y 
 end do 
 end if 
figure tree traversal routines called by the 
reranking algorithm 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
meanaverageprecision inex- 
xmlcumulatedgain xcg 
alpha 
map strict 
map generalized 
map sog 
xcg sog 
figure impact of α on xcg and inex- map 
 inex co topics assessment set i 
node s ancestors lines - and descendants lines - 
adjusting the scores of these nodes 
the tree traversal routines up and down are given in 
figure the up routine removes each ancestor node from s 
adjusts its term frequency values recomputes its score and 
adds it back into s the adjustment of the term frequency 
values line adds to y g only the previously unreported 
term occurrences in x re-computation of the score on line 
uses equations and the down routine performs a similar 
operation on each descendant however since the contents 
of each descendant are entirely contained in a reported 
element its final score may be computed and it is removed 
from s and added to f 
in order to determine the time complexity of the 
algorithm first note that a node may be an argument to down 
at most once thereafter the reported flag of its parent is 
true during each call to down a node may be moved from 
s to f requiring o log n time thus the total time for all 
calls to down is o n log n and we may temporarily ignore 
lines - of figure when considering the time complexity 
of the loop over lines - during each iteration of this loop 
a node and each of its ancestors are removed from a priority 
queue and then added back into a priority queue since a 
node may have at most h ancestors where h is the maximum 
height of any tree in the collection each of the m iterations 
requires o h log n time combining these observations 
produces an overall time complexity of o n mh log n 
in practice re-ranking an inex result set requires less 
than ms on a three-year-old desktop pc 
 evaluation 
none of the metrics described in section is a close fit 
with the view of overlap advocated by this paper 
nonetheless when taken together they provide insight into the 
behaviour of the re-ranking algorithm the inex evaluation 
packages inex eval and inex eval ng were used to 
compute values for the inex- and inex- metrics values 
for the xcg metrics were computed using software supplied 
by its inventors 
figure plots the three variants of inex- map metric 
together with the xcg metric values for these metrics 
 
 
 
 
 
 
 
 
 
 
 
 
meanaverageprecision inex- 
alpha 
strict overlap not considered 
strict overlap considered 
generalized overlap not considered 
generalized overlap considered 
figure impact of α on inex- map inex 
 co topics assessment set i 
are plotted for values of α between and recalling 
that the xcg metric is designed to penalize overlap while 
the inex- metric ignores overlap the conflict between 
the metrics is obvious the map values at one extreme 
 α and the xcg value at the other extreme α 
 represent retrieval performance comparable to the best 
systems at inex 
figure plots values of the inex- map metric for two 
quantizations with and without consideration of overlap 
once again conflict is apparent with the influence of α 
substantially lessened when overlap is considered 
 extended algorithm 
one limitation of the re-ranking algorithm is that a single 
weight α is used to adjust the scores of both the ancestors 
and descendants of reported elements an obvious extension 
is to use different weights in these two cases furthermore 
the same weight is used regardless of the number of times 
an element is contained in a reported element for example 
a paragraph may form part of a reported section and then 
form part of a reported article since the user may now 
have seen this paragraph twice its score should be further 
lowered by increasing the value of the weight 
motivated by these observations the re-ranking algorithm 
may be extended with a series of weights 
 β ≥ β ≥ β ≥ ≥ βm ≥ 
where βj is the weight applied to a node that has been a 
descendant of a reported node j times note that an upper 
bound on m is h the maximum height of any xml tree 
in the collection however in practice m is likely to be 
relatively small perhaps or 
figure presents replacements for the up and down 
routines of figure incorporating this series of weights one 
extra field is required in each node as follows 
x j - down count 
the value of x j is initially set to zero in all nodes and is 
incremented each time down is called with x as its argument 
when computing the score of node the value of x j selects 
 up x y ≡ 
 if not y reported then 
 s remove y 
 y g ← y g x f − x g 
 recompute y score 
 s add y 
 if y is not a root node then 
 up x y parent 
 end if 
 end if 
 
 down x ≡ 
 if x j m then 
 x j ← x j 
 if not x reported then 
 s remove x 
 recompute x score 
 s add x 
 end if 
 foreach y ∈ x children do 
 down y 
 end do 
 end if 
figure extended tree traversal routines 
the weight to be applied to the node by adjusting the value 
of xt in equation as follows 
xt βx j · ft − α · gt 
where ft and gt are the components of x f and x g 
corresponding to term t 
a few additional changes are required to extend up and 
down the up routine returns immediately line if its 
argument has already been reported since term frequencies 
have already been adjusted in its ancestors the down 
routine does not report its argument but instead recomputes 
its score and adds it back into s 
a node cannot be an argument to down more than m 
times which in turn implies an overall time complexity of 
o nm mh log n since m ≤ h and m ≤ n the time 
complexity is also o nh log n 
 concluding discussion 
when generating retrieval results over an xml collection 
some overlap in the results should be tolerated and may be 
beneficial for example when a highly exhaustive and fairly 
specific element contains a much smaller element 
both should be reported to the user and retrieval algorithms 
and evaluation metrics should respect this relationship the 
algorithm presented in this paper controls overlap by 
weighting the terms occurring in reported elements to reflect their 
reduced importance 
other approaches may also help to control overlap for 
example when xml retrieval results are presented to users 
it may be desirable to cluster structurally related elements 
together visually illustrating the relationships between them 
while this style of user interface may help a user cope with 
overlap the strategy presented in this paper continues to be 
applicable by determining the best elements to include in 
each cluster 
at waterloo we continue to develop and test our ideas 
for inex in particular we are investigating methods 
for learning the α and βj weights we are also re-evaluating 
our approach to document statistics and examining 
appropriate adjustments to the k parameter as term weights 
change 
 acknowledgments 
thanks to gabriella kazai and arjen de vries for 
providing an early version of their software for computing the xcg 
metric and thanks to phil tilker and stefan b¨uttcher for 
their help with the experimental evaluation in part 
funding for this project was provided by ibm canada through 
the national institute for software research 
 references 
 n bruno n koudas and d srivastava holistic twig 
joins optimal xml pattern matching in proceedings 
of the acm sigmod international conference 
on the management of data pages - madison 
wisconsin june 
 d carmel y s maarek m mandelbrod y mass 
and a soffer searching xml documents via xml 
fragments in proceedings of the th annual 
international acm sigir conference on research 
and development in information retrieval pages 
 - toronto canada 
 c l a clarke and p l tilker multitext 
experiments for inex in inex workshop 
proceedings published in lncs 
 a p de vries g kazai and m lalmas tolerance to 
irrelevance a user-effort oriented evaluation of 
retrieval systems without predefined retrieval unit in 
riao conference proceedings pages - 
avignon france april 
 d dehaan d toman m p consens and m t 
¨ozsu a comprehensive xquery to sql translation 
using dynamic interval encoding in proceedings of the 
 acm sigmod international conference on the 
management of data san diego june 
 n fuhr and k großjohann xirql a query 
language for information retrieval in xml documents 
in proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval pages - new orleans 
september 
 n fuhr m lalmas and s malik editors initiative 
for the evaluation of xml retrieval proceedings of 
the second workshop inex dagstuhl 
germany december 
 n fuhr m lalmas s malik and zolt´an szl´avik 
editors initiative for the evaluation of xml 
retrieval proceedings of the third workshop inex 
 dagstuhl germany december published 
as advances in xml information retrieval lecture 
notes in computer science volume springer 
 
 k j¨avelin and j kek¨al¨ainen cumulated gain-based 
evaluation of ir techniques acm transactions on 
information systems - 
 j kamps m de rijke and b sigurbj¨ornsson length 
normalization in xml retrieval in proceedings of the 
 th annual international acm sigir conference on 
research and development in information retrieval 
pages - sheffield uk july 
 g kazai m lalmas and a p de vries the overlap 
problem in content-oriented xml retrieval evaluation 
in proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval pages - sheffield uk 
july 
 g kazai m lalmas and a p de vries reliability 
tests for the xcg and inex- metrics in inex 
 workshop proceedings published in lncs 
 
 j kek¨al¨ainen m junkkari p arvola and t aalto 
trix - struggling with the overlap in inex 
 workshop proceedings published in lncs 
 
 s liu q zou and w w chu configurable 
indexing and ranking for xml information retrieval 
in proceedings of the th annual international acm 
sigir conference on research and development in 
information retrieval pages - sheffield uk 
july 
 y mass and m mandelbrod retrieving the most 
relevant xml components in inex workshop 
proceedings dagstuhl germany december 
 y mass and m mandelbrod component ranking and 
automatic query refinement for xml retrieval in 
inex workshop proceedings published in 
lncs 
 p ogilvie and j callan hierarchical language models 
for xml component retrieval in inex 
workshop proceedings published in lncs 
 
 j pehcevski j a thom and a vercoustre hybrid 
xml retrieval re-visited in inex workshop 
proceedings published in lncs 
 b piwowarski and m lalmas providing consistent 
and exhaustive relevance assessments for xml 
retrieval evaluation in proceedings of the th acm 
conference on information and knowledge 
management pages - washington dc 
november 
 s robertson h zaragoza and m taylor simple 
bm extension to multiple weighted fields in 
proceedings of the th acm conference on 
information and knowledge management pages 
 - washington dc november 
 s e robertson s walker and m beaulieu okapi at 
trec- automatic ad-hoc filtering vlc and 
interactive track in proceedings of the seventh text 
retrieval conference gaithersburg md november 
 
 a trotman and b sigurbj¨ornsson nexi now and 
next in inex workshop proceedings 
published in lncs 
 j vittaut b piwowarski and p gallinari an 
algebra for structured queries in bayesian networks in 
inex workshop proceedings published in 
lncs 
