automatic extraction of titles from general documents 
using machine learning 
yunhua hu 
computer science department 
xi an jiaotong university 
no xianning west road 
xi an china 
yunhuahu mail xjtu edu cn 
hang li yunbo cao 
microsoft research asia 
 f sigma center 
no zhichun road haidian 
beijing china 
 hangli yucao  microsoft com 
qinghua zheng 
computer science department 
xi an jiaotong university 
no xianning west road 
xi an china 
qhzheng mail xjtu edu cn 
dmitriy meyerzon 
microsoft corporation 
one microsoft way 
redmond wa 
usa 
dmitriym microsoft com 
abstract 
in this paper we propose a machine learning approach to title 
extraction from general documents by general documents we 
mean documents that can belong to any one of a number of 
specific genres including presentations book chapters technical 
papers brochures reports and letters previously methods have 
been proposed mainly for title extraction from research papers it 
has not been clear whether it could be possible to conduct 
automatic title extraction from general documents as a case study 
we consider extraction from office including word and 
powerpoint in our approach we annotate titles in sample 
documents for word and powerpoint respectively and take them 
as training data train machine learning models and perform title 
extraction using the trained models our method is unique in that 
we mainly utilize formatting information such as font size as 
features in the models it turns out that the use of formatting 
information can lead to quite accurate extraction from general 
documents precision and recall for title extraction from word is 
 and respectively and precision and recall for title 
extraction from powerpoint is and respectively in an 
experiment on intranet data other important new findings in this 
work include that we can train models in one domain and apply 
them to another domain and more surprisingly we can even train 
models in one language and apply them to another language 
moreover we can significantly improve search ranking results in 
document retrieval by using the extracted titles 
categories and subject descriptors 
h information storage and retrieval information search 
and retrieval - search process h information systems 
applications office automation - word processing d 
 software engineering metrics - complexity measures 
performance measures 
general terms 
algorithms experimentation performance 
 introduction 
metadata of documents is useful for many kinds of document 
processing such as search browsing and filtering ideally 
metadata is defined by the authors of documents and is then used 
by various systems however people seldom define document 
metadata by themselves even when they have convenient 
metadata definition tools thus how to automatically extract 
metadata from the bodies of documents turns out to be an 
important research issue 
methods for performing the task have been proposed however 
the focus was mainly on extraction from research papers for 
instance han et al proposed a machine learning based 
method to conduct extraction from research papers they 
formalized the problem as that of classification and employed 
support vector machines as the classifier they mainly used 
linguistic features in the model 
in this paper we consider metadata extraction from general 
documents by general documents we mean documents that may 
belong to any one of a number of specific genres general 
documents are more widely available in digital libraries intranets 
and the internet and thus investigation on extraction from them is 
sorely needed research papers usually have well-formed styles 
and noticeable characteristics in contrast the styles of general 
documents can vary greatly it has not been clarified whether a 
machine learning based approach can work well for this task 
there are many types of metadata title author date of creation 
etc as a case study we consider title extraction in this paper 
general documents can be in many different file formats 
microsoft office pdf ps etc as a case study we consider 
extraction from office including word and powerpoint 
we take a machine learning approach we annotate titles in 
sample documents for word and powerpoint respectively and 
take them as training data to train several types of models and 
perform title extraction using any one type of the trained models 
in the models we mainly utilize formatting information such as 
font size as features we employ the following models maximum 
entropy model perceptron with uneven margins maximum 
entropy markov model and voted perceptron 
in this paper we also investigate the following three problems 
which did not seem to have been examined previously 
 comparison between models among the models above which 
model performs best for title extraction 
 generality of model whether it is possible to train a model on 
one domain and apply it to another domain and whether it is 
possible to train a model in one language and apply it to another 
language 
 usefulness of extracted titles whether extracted titles can 
improve document processing such as search 
experimental results indicate that our approach works well for 
title extraction from general documents our method can 
significantly outperform the baselines one that always uses the 
first lines as titles and the other that always uses the lines in the 
largest font sizes as titles precision and recall for title extraction 
from word are and respectively and precision and 
recall for title extraction from powerpoint are and 
respectively it turns out that the use of format features is the key 
to successful title extraction 
 we have observed that perceptron based models perform 
better in terms of extraction accuracies we have empirically 
verified that the models trained with our approach are generic in 
the sense that they can be trained on one domain and applied to 
another and they can be trained in one language and applied to 
another we have found that using the extracted titles we can 
significantly improve precision of document retrieval by 
we conclude that we can indeed conduct reliable title extraction 
from general documents and use the extracted results to improve 
real applications 
the rest of the paper is organized as follows in section we 
introduce related work and in section we explain the 
motivation and problem setting of our work in section we 
describe our method of title extraction and in section we 
describe our method of document retrieval using extracted titles 
section gives our experimental results we make concluding 
remarks in section 
 related work 
 document metadata extraction 
methods have been proposed for performing automatic metadata 
extraction from documents however the main focus was on 
extraction from research papers 
the proposed methods fall into two categories the rule based 
approach and the machine learning based approach 
giuffrida et al for instance developed a rule-based system for 
automatically extracting metadata from research papers in 
postscript they used rules like titles are usually located on the 
upper portions of the first pages and they are usually in the largest 
font sizes liddy et al and yilmazel el al performed 
metadata extraction from educational materials using rule-based 
natural language processing technologies mao et al also 
conducted automatic metadata extraction from research papers 
using rules on formatting information 
the rule-based approach can achieve high performance however 
it also has disadvantages it is less adaptive and robust when 
compared with the machine learning approach 
han et al for instance conducted metadata extraction with 
the machine learning approach they viewed the problem as that 
of classifying the lines in a document into the categories of 
metadata and proposed using support vector machines as the 
classifier they mainly used linguistic information as features 
they reported high extraction accuracy from research papers in 
terms of precision and recall 
 information extraction 
metadata extraction can be viewed as an application of 
information extraction in which given a sequence of instances we 
identify a subsequence that represents information in which we 
are interested hidden markov model maximum entropy 
model maximum entropy markov model support 
vector machines conditional random field and voted 
perceptron are widely used information extraction models 
information extraction has been applied for instance to 
part-ofspeech tagging named entity recognition and table 
extraction 
 search using title information 
title information is useful for document retrieval 
in the system citeseer for instance giles et al managed to 
extract titles from research papers and make use of the extracted 
titles in metadata search of papers 
in web search the title fields i e file properties and anchor texts 
of web pages html documents can be viewed as  titles of the 
pages many search engines seem to utilize them for web page 
retrieval zhang et al found that web pages with 
well-defined metadata are more easily retrieved than those without 
well-defined metadata 
to the best of our knowledge no research has been conducted on 
using extracted titles from general documents e g office 
documents for search of the documents 
 
 motivation and problem 
setting 
we consider the issue of automatically extracting titles from 
general documents 
by general documents we mean documents that belong to one of 
any number of specific genres the documents can be 
presentations books book chapters technical papers brochures 
reports memos specifications letters announcements or resumes 
general documents are more widely available in digital libraries 
intranets and internet and thus investigation on title extraction 
from them is sorely needed 
figure shows an estimate on distributions of file formats on 
intranet and internet office and pdf are the main file 
formats on the intranet even on the internet the documents in the 
formats are still not negligible given its extremely large size in 
this paper without loss of generality we take office documents as 
an example 
figure distributions of file formats in internet and intranet 
for office documents users can define titles as file properties 
using a feature provided by office we found in an experiment 
however that users seldom use the feature and thus titles in file 
properties are usually very inaccurate that is to say titles in file 
properties are usually inconsistent with the  true titles in the file 
bodies that are created by the authors and are visible to readers 
we collected word and powerpoint documents from 
an intranet and the internet and examined how many titles in the 
file properties are correct we found that surprisingly the accuracy 
was only cf section for details a number of reasons 
can be considered for example if one creates a new file by 
copying an old file then the file property of the new file will also 
be copied from the old file 
in another experiment we found that google uses the titles in file 
properties of office documents in search and browsing but the 
titles are not very accurate we created queries to search word 
and powerpoint documents and examined the top results of 
each query returned by google we found that nearly all the titles 
presented in the search results were from the file properties of the 
documents however only of them were correct 
actually  true titles usually exist at the beginnings of the bodies 
of documents if we can accurately extract the titles from the 
bodies of documents then we can exploit reliable title information 
in document processing this is exactly the problem we address in 
this paper 
more specifically given a word document we are to extract the 
title from the top region of the first page given a powerpoint 
document we are to extract the title from the first slide a title 
sometimes consists of a main title and one or two subtitles we 
only consider extraction of the main title 
as baselines for title extraction we use that of always using the 
first lines as titles and that of always using the lines with largest 
font sizes as titles 
figure title extraction from word document 
figure title extraction from powerpoint document 
next we define a  specification for human judgments in title data 
annotation the annotated data will be used in training and testing 
of the title extraction methods 
summary of the specification the title of a document should be 
identified on the basis of common sense if there is no difficulty in 
the identification however there are many cases in which the 
identification is not easy there are some rules defined in the 
specification that guide identification for such cases the rules 
include a title is usually in consecutive lines in the same format 
a document can have no title titles in images are not 
considered a title should not contain words like  draft 
 
 whitepaper etc if it is difficult to determine which is the title 
select the one in the largest font size and if it is still difficult to 
determine which is the title select the first candidate the 
specification covers all the cases we have encountered in data 
annotation 
figures and show examples of office documents from which 
we conduct title extraction in figure  differences in win 
api implementations among windows operating systems is the 
title of the word document  microsoft windows on the top of 
this page is a picture and thus is ignored in figure  building 
competitive advantages through an agile infrastructure is the 
title of the powerpoint document 
we have developed a tool for annotation of titles by human 
annotators figure shows a snapshot of the tool 
figure title annotation tool 
 title extraction method 
 outline 
title extraction based on machine learning consists of training and 
extraction the same pre-processing step occurs before training 
and extraction 
during pre-processing from the top region of the first page of a 
word document or the first slide of a powerpoint document a 
number of units for processing are extracted if a line lines are 
separated by  return symbols only has a single format then the 
line will become a unit if a line has several parts and each of 
them has its own format then each part will become a unit each 
unit will be treated as an instance in learning a unit contains not 
only content information linguistic information but also 
formatting information the input to pre-processing is a document 
and the output of pre-processing is a sequence of units instances 
figure shows the units obtained from the document in figure 
figure example of units 
in learning the input is sequences of units where each sequence 
corresponds to a document we take labeled units labeled as 
title begin title end or other in the sequences as training data 
and construct models for identifying whether a unit is title begin 
title end or other we employ four types of models perceptron 
maximum entropy me perceptron markov model pmm and 
maximum entropy markov model memm 
in extraction the input is a sequence of units from one document 
we employ one type of model to identify whether a unit is 
title begin title end or other we then extract units from the unit 
labeled with  title begin to the unit labeled with  title end the 
result is the extracted title of the document 
the unique characteristic of our approach is that we mainly utilize 
formatting information for title extraction our assumption is that 
although general documents vary in styles their formats have 
certain patterns and we can learn and utilize the patterns for title 
extraction this is in contrast to the work by han et al in which 
only linguistic features are used for extraction from research 
papers 
 models 
the four models actually can be considered in the same metadata 
extraction framework that is why we apply them together to our 
current problem 
each input is a sequence of instances kxxx l together with a 
sequence of labels kyyy l ix and iy represents an instance 
and its label respectively ki l recall that an instance 
here represents a unit a label represents title begin title end or 
other here k is the number of units in a document 
in learning we train a model which can be generally denoted as a 
conditional probability distribution kk xxyyp ll where 
ix and iy denote random variables taking instance ix and label 
iy as values respectively ki l 
learning tool 
extraction tool 
 
 
 
nknnknn 
kk 
kk 
yyyxxx 
yyyxxx 
yyyxxx 
ll 
ll 
ll 
ll 
→ 
→ 
→ 
 maxarg mkmmkm xxyyp ll 
 kk xxyyp ll 
conditional 
distribution 
mkmm xxx l 
figure metadata extraction model 
we can make assumptions about the general model in order to 
make it simple enough for training 
 
for example we can assume that kyy l are independent of 
each other given kxx l thus we have 
 
 
 
 
kk 
kk 
xypxyp 
xxyyp 
l 
ll 
 
in this way we decompose the model into a number of classifiers 
we train the classifiers locally using the labeled data as the 
classifier we employ the perceptron or maximum entropy model 
we can also assume that the first order markov property holds for 
kyy l given kxx l thus we have 
 
 
 
 
kkk 
kk 
xyypxyp 
xxyyp 
− l 
ll 
again we obtain a number of classifiers however the classifiers 
are conditioned on the previous label when we employ the 
percepton or maximum entropy model as a classifier the models 
become a percepton markov model or maximum entropy markov 
model respectively that is to say the two models are more 
precise 
in extraction given a new sequence of instances we resort to one 
of the constructed models to assign a sequence of labels to the 
sequence of instances i e perform extraction 
for perceptron and me we assign labels locally and combine the 
results globally later using heuristics specifically we first 
identify the most likely title begin then we find the most likely 
title end within three units after the title begin finally we 
extract as a title the units between the title begin and the title end 
for pmm and memm we employ the viterbi algorithm to find 
the globally optimal label sequence 
in this paper for perceptron we actually employ an improved 
variant of it called perceptron with uneven margin this 
version of perceptron can work well especially when the number 
of positive instances and the number of negative instances differ 
greatly which is exactly the case in our problem 
we also employ an improved version of perceptron markov 
model in which the perceptron model is the so-called voted 
perceptron in addition in training the parameters of the 
model are updated globally rather than locally 
 features 
there are two types of features format features and linguistic 
features we mainly use the former the features are used for both 
the title-begin and the title-end classifiers 
 format features 
font size there are four binary features that represent the 
normalized font size of the unit recall that a unit has only one 
type of font 
if the font size of the unit is the largest in the document then the 
first feature will be otherwise if the font size is the smallest 
in the document then the fourth feature will be otherwise if 
the font size is above the average font size and not the largest in 
the document then the second feature will be otherwise if the 
font size is below the average font size and not the smallest the 
third feature will be otherwise 
it is necessary to conduct normalization on font sizes for 
example in one document the largest font size might be   pt 
while in another the smallest one might be   pt 
boldface this binary feature represents whether or not the 
current unit is in boldface 
alignment there are four binary features that respectively 
represent the location of the current unit  left  center  right 
and  unknown alignment 
the following format features with respect to  context play an 
important role in title extraction 
empty neighboring unit there are two binary features that 
represent respectively whether or not the previous unit and the 
current unit are blank lines 
font size change there are two binary features that represent 
respectively whether or not the font size of the previous unit and 
the font size of the next unit differ from that of the current unit 
alignment change there are two binary features that represent 
respectively whether or not the alignment of the previous unit and 
the alignment of the next unit differ from that of the current one 
same paragraph there are two binary features that represent 
respectively whether or not the previous unit and the next unit are 
in the same paragraph as the current unit 
 linguistic features 
the linguistic features are based on key words 
positive word this binary feature represents whether or not the 
current unit begins with one of the positive words the positive 
words include  title  subject  subject line for example in 
some documents the lines of titles and authors have the same 
formats however if lines begin with one of the positive words 
then it is likely that they are title lines 
negative word this binary feature represents whether or not the 
current unit begins with one of the negative words the negative 
words include  to  by  created by  updated by etc 
there are more negative words than positive words the above 
linguistic features are language dependent 
word count a title should not be too long we heuristically 
create four intervals and ∞ and define one 
feature for each interval if the number of words in a title falls into 
an interval then the corresponding feature will be otherwise 
ending character this feature represents whether the unit ends 
with    - or other special characters a title usually does not 
end with such a character 
 document retrieval method 
we describe our method of document retrieval using extracted 
titles 
typically in information retrieval a document is split into a 
number of fields including body title and anchor text a ranking 
function in search can use different weights for different fields of 
 
the document also titles are typically assigned high weights 
indicating that they are important for document retrieval as 
explained previously our experiment has shown that a significant 
number of documents actually have incorrect titles in the file 
properties and thus in addition of using them we use the extracted 
titles as one more field of the document by doing this we attempt 
to improve the overall precision 
in this paper we employ a modification of bm that allows field 
weighting as fields we make use of body title extracted 
title and anchor first for each term in the query we count the 
term frequency in each field of the document each field 
frequency is then weighted according to the corresponding weight 
parameter 
∑ 
f 
tfft tfwwtf 
similarly we compute the document length as a weighted sum of 
lengths of each field average document length in the corpus 
becomes the average of all weighted document lengths 
∑ 
f 
ff dlwwdl 
in our experiments we used bk weight for content 
was title was anchor was and extracted title was 
 
 experimental results 
 data sets and evaluation measures 
we used two data sets in our experiments 
first we downloaded and randomly selected word 
documents and powerpoint documents from an intranet of 
microsoft we call it ms hereafter 
second we downloaded and randomly selected word and 
powerpoint documents from the dotgov and dotcom domains on 
the internet respectively 
figure shows the distributions of the genres of the documents 
we see that the documents are indeed  general documents as we 
define them 
figure distributions of document genres 
third a data set in chinese was also downloaded from the internet 
it includes word documents and powerpoint documents 
in chinese 
we manually labeled the titles of all the documents on the basis 
of our specification 
not all the documents in the two data sets have titles table 
shows the percentages of the documents having titles we see that 
dotcom and dotgov have more powerpoint documents with titles 
than ms this might be because powerpoint documents published 
on the internet are more formal than those on the intranet 
table the portion of documents with titles 
domain 
type 
ms dotcom dotgov 
word 
powerpoint 
in our experiments we conducted evaluations on title extraction in 
terms of precision recall and f-measure the evaluation 
measures are defined as follows 
precision p a a b 
recall r a a c 
f-measure f pr p r 
here a b c and d are numbers of documents as those defined 
in table 
table contingence table with regard to title extraction 
is title is not title 
extracted a b 
not extracted c d 
 baselines 
we test the accuracies of the two baselines described in section 
 they are denoted as  largest font size and  first line 
respectively 
 accuracy of titles in file properties 
we investigate how many titles in the file properties of the 
documents are reliable we view the titles annotated by humans as 
true titles and test how many titles in the file properties can 
approximately match with the true titles we use edit distance to 
conduct the approximate match approximate match is only used 
in this evaluation this is because sometimes human annotated 
titles can be slightly different from the titles in file properties on 
the surface e g contain extra spaces 
given string a and string b 
if d or d la lb θ then string a string b 
d edit distance between string a and string b 
la length of string a 
lb length of string b 
θ 
∑ × 
 − 
 
 
t 
t 
n 
n 
wtf 
avwdl 
wdl 
bbk 
kwtf 
fbm log 
 
 
 
 
 
 
table accuracies of titles in file properties 
file type domain precision recall f 
ms 
dotcom word 
dotgov 
ms 
dotcom powerpoint 
dotgov 
 comparison with baselines 
we conducted title extraction from the first data set word and 
powerpoint in ms as the model we used perceptron 
we conduct -fold cross validation thus all the results reported 
here are those averaged over trials tables and show the 
results we see that perceptron significantly outperforms the 
baselines in the evaluation we use exact matching between the 
true titles annotated by humans and the extracted titles 
table accuracies of title extraction with word 
precision recall f 
model perceptron 
largest font size 
baselines 
first line 
table accuracies of title extraction with powerpoint 
precision recall f 
model perceptron 
largest font size 
baselines 
first line 
we see that the machine learning approach can achieve good 
performance in title extraction for word documents both 
precision and recall of the approach are percent higher than 
those of the baselines for powerpoint both precision and recall of 
the approach are percent higher than those of the baselines 
we conduct significance tests the results are shown in table 
here  largest denotes the baseline of using the largest font size 
 first denotes the baseline of using the first line the results 
indicate that the improvements of machine learning over baselines 
are statistically significant in the sense p-value 
table sign test results 
documents type sign test between p-value 
perceptron vs largest e- 
word 
perceptron vs first e- 
perceptron vs largest 
powerpoint 
perceptron vs first e- 
we see from the results that the two baselines can work well for 
title extraction suggesting that font size and position information 
are most useful features for title extraction however it is also 
obvious that using only these two features is not enough there 
are cases in which all the lines have the same font size i e the 
largest font size or cases in which the lines with the largest font 
size only contain general descriptions like  confidential  white 
paper etc for those cases the  largest font size method cannot 
work well for similar reasons the  first line method alone 
cannot work well either with the combination of different 
features evidence in title judgment perceptron can outperform 
largest and first 
we investigate the performance of solely using linguistic features 
we found that it does not work well it seems that the format 
features play important roles and the linguistic features are 
supplements 
figure an example word document 
figure an example powerpoint document 
we conducted an error analysis on the results of perceptron we 
found that the errors fell into three categories about one third 
of the errors were related to  hard cases in these documents the 
layouts of the first pages were difficult to understand even for 
humans figure and shows examples nearly one fourth of 
the errors were from the documents which do not have true titles 
but only contain bullets since we conduct extraction from the top 
regions it is difficult to get rid of these errors with the current 
approach confusions between main titles and subtitles were 
another type of error since we only labeled the main titles as 
titles the extractions of both titles were considered incorrect this 
type of error does little harm to document processing like search 
however 
 comparison between models 
to compare the performance of different machine learning models 
we conducted another experiment again we perform -fold cross 
 
validation on the first data set ms table shows the results 
of all the four models 
it turns out that perceptron and pmm perform the best followed 
by memm and me performs the worst in general the 
markovian models perform better than or as well as their classifier 
counterparts this seems to be because the markovian models are 
trained globally while the classifiers are trained locally the 
perceptron based models perform better than the me based 
counterparts this seems to be because the perceptron based 
models are created to make better classifications while me 
models are constructed for better prediction 
table comparison between different learning models for 
title extraction with word 
model precision recall f 
perceptron 
memm 
pmm 
me 
table comparison between different learning models for 
title extraction with powerpoint 
model precision recall f 
perceptron 
memm 
pmm 
me 
 domain adaptation 
we apply the model trained with the first data set ms to the 
second data set dotcom and dotgov tables - show the 
results 
table accuracies of title extraction with word in dotgov 
precision recall f 
model perceptron 
largest font size baselines 
first line 
table accuracies of title extraction with powerpoint in 
dotgov 
precision recall f 
model perceptron 
largest font size baselines 
first line 
table accuracies of title extraction with word in dotcom 
precisio 
n 
recall f 
model perceptron 
largest font size baselines 
first line 
table performance of powerpoint document title 
extraction in dotcom 
precisio 
n 
recall f 
model perceptron 
largest font size baselines 
first line 
from the results we see that the models can be adapted to 
different domains well there is almost no drop in accuracy the 
results indicate that the patterns of title formats exist across 
different domains and it is possible to construct a domain 
independent model by mainly using formatting information 
 language adaptation 
we apply the model trained with the data in english ms to the 
data set in chinese 
tables - show the results 
table accuracies of title extraction with word in chinese 
precision recall f 
model perceptron 
largest font size baselines 
first line 
table accuracies of title extraction with powerpoint in 
chinese 
precision recall f 
model perceptron 
largest font size baselines 
first line 
we see that the models can be adapted to a different language 
there are only small drops in accuracy obviously the linguistic 
features do not work for chinese but the effect of not using them 
is negligible the results indicate that the patterns of title formats 
exist across different languages 
from the domain adaptation and language adaptation results we 
conclude that the use of formatting information is the key to a 
successful extraction from general documents 
 search with extracted titles 
we performed experiments on using title extraction for document 
retrieval as a baseline we employed bm without using 
extracted titles the ranking mechanism was as described in 
section the weights were heuristically set we did not conduct 
optimization on the weights 
the evaluation was conducted on a corpus of m documents 
crawled from the intranet of microsoft using evaluation 
queries obtained from this intranet s search engine query logs 
queries were from the most popular set while queries other 
were chosen randomly users were asked to provide judgments of 
the degree of document relevance from a scale of to 
meaning detrimental - bad - fair - good and - excellent 
 
figure shows the results in the chart two sets of precision 
results were obtained by either considering good or excellent 
documents as relevant left bars with relevance threshold or 
by considering only excellent documents as relevant right bars 
with relevance threshold 
 
 
 
 
 
 
 
 
 
 
p  p  reciprocal p  p  reciprocal 
 
bm anchor title body 
bm anchor title body extractedtitle 
name all 
relevancethreshold data 
description 
figure search ranking results 
figure shows different document retrieval results with different 
ranking functions in terms of precision   precision   and 
reciprocal rank 
 blue bar - bm including the fields body title file 
property and anchor text 
 purple bar - bm including the fields body title file 
property anchor text and extracted title 
with the additional field of extracted title included in bm the 
precision   increased from to or by   thus 
it is safe to say that the use of extracted title can indeed improve 
the precision of document retrieval 
 conclusion 
in this paper we have investigated the problem of automatically 
extracting titles from general documents we have tried using a 
machine learning approach to address the problem 
previous work showed that the machine learning approach can 
work well for metadata extraction from research papers in this 
paper we showed that the approach can work for extraction from 
general documents as well our experimental results indicated that 
the machine learning approach can work significantly better than 
the baselines in title extraction from office documents previous 
work on metadata extraction mainly used linguistic features in 
documents while we mainly used formatting information it 
appeared that using formatting information is a key for 
successfully conducting title extraction from general documents 
we tried different machine learning models including perceptron 
maximum entropy maximum entropy markov model and voted 
perceptron we found that the performance of the perceptorn 
models was the best we applied models constructed in one 
domain to another domain and applied models trained in one 
language to another language we found that the accuracies did 
not drop substantially across different domains and across 
different languages indicating that the models were generic we 
also attempted to use the extracted titles in document retrieval we 
observed a significant improvement in document ranking 
performance for search when using extracted title information all 
the above investigations were not conducted in previous work and 
through our investigations we verified the generality and the 
significance of the title extraction approach 
 acknowledgements 
we thank chunyu wei and bojuan zhao for their work on data 
annotation we acknowledge jinzhu li for his assistance in 
conducting the experiments we thank ming zhou john chen 
jun xu and the anonymous reviewers of jcdl for their 
valuable comments on this paper 
 references 
 berger a l della pietra s a and della pietra v j a 
maximum entropy approach to natural language processing 
computational linguistics - 
 collins m discriminative training methods for hidden 
markov models theory and experiments with perceptron 
algorithms in proceedings of conference on empirical 
methods in natural language processing - 
 cortes c and vapnik v support-vector networks machine 
learning - 
 chieu h l and ng h t a maximum entropy approach to 
information extraction from semi-structured and free text in 
proceedings of the eighteenth national conference on 
artificial intelligence - 
 evans d k klavans j l and mckeown k r columbia 
newsblaster multilingual news summarization on the web 
in proceedings of human language technology conference 
north american chapter of the association for 
computational linguistics annual meeting - 
 ghahramani z and jordan m i factorial hidden markov 
models machine learning - 
 gheel j and anderson t data and metadata for finding and 
reminding in proceedings of the international 
conference on information visualization - 
 giles c l petinot y teregowda p b han h 
lawrence s rangaswamy a and pal n ebizsearch a 
niche search engine for e-business in proceedings of the 
 th annual international acm sigir conference on 
research and development in information retrieval 
 
 giuffrida g shek e c and yang j knowledge-based 
metadata extraction from postscript files in proceedings of 
the fifth acm conference on digital libraries - 
 han h giles c l manavoglu e zha h zhang z and 
fox e a automatic document metadata extraction using 
support vector machines in proceedings of the third 
acm ieee-cs joint conference on digital libraries - 
 
 kobayashi m and takeda k information retrieval on the 
web acm computing surveys - 
 lafferty j mccallum a and pereira f conditional 
random fields probabilistic models for segmenting and 
 
labeling sequence data in proceedings of the eighteenth 
international conference on machine learning - 
 
 li y zaragoza h herbrich r shawe-taylor j and 
kandola j s the perceptron algorithm with uneven margins 
in proceedings of the nineteenth international conference 
on machine learning - 
 liddy e d sutton s allen e harwell s corieri s 
yilmazel o ozgencil n e diekema a mccracken n 
and silverstein j automatic metadata generation 
evaluation in proceedings of the th annual international 
acm sigir conference on research and development in 
information retrieval - 
 littlefield a effective enterprise information retrieval 
across new content formats in proceedings of the seventh 
search engine conference 
http www infonortics com searchengines sh prog html 
 
 mao s kim j w and thoma g r a dynamic feature 
generation system for automated metadata extraction in 
preservation of digital materials in proceedings of the first 
international workshop on document image analysis for 
libraries - 
 mccallum a freitag d and pereira f maximum entropy 
markov models for information extraction and segmentation 
in proceedings of the seventeenth international conference 
on machine learning - 
 murphy l d digital document metadata in organizations 
roles analytical approaches and future research directions 
in proceedings of the thirty-first annual hawaii 
international conference on system sciences - 
 pinto d mccallum a wei x and croft w b table 
extraction using conditional random fields in proceedings of 
the th annual international acm sigir conference on 
research and development in information retrieval 
 
 ratnaparkhi a unsupervised statistical models for 
prepositional phrase attachment in proceedings of the 
seventeenth international conference on computational 
linguistics - 
 robertson s zaragoza h and taylor m simple bm 
extension to multiple weighted fields in proceedings of 
acm thirteenth conference on information and knowledge 
management - 
 yi j and sundaresan n metadata based web mining for 
relevance in proceedings of the international 
symposium on database engineering applications 
 
 yilmazel o finneran c m and liddy e d metaextract 
an nlp system to automatically assign metadata in 
proceedings of the joint acm ieee conference on 
digital libraries - 
 zhang j and dimitroff a internet search engines response 
to metadata dublin core implementation journal of 
information science - 
 zhang l pan y and zhang t recognising and using 
named entities focused named entity recognition using 
machine learning in proceedings of the th annual 
international acm sigir conference on research and 
development in information retrieval - 
 http dublincore org groups corporate seattle 
 
